[0m19:18:23.063261 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019AC1C87350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019AC1C873E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019AC1C872C0>]}


============================== 19:18:23.078978 | 3e6223ce-4b01-4562-86d1-22f746cd812b ==============================
[0m19:18:23.078978 [info ] [MainThread]: Running with dbt=1.8.7
[0m19:18:23.078978 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'logs', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt init my_project', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m19:18:23.125817 [warn ] [MainThread]: [ConfigFolderDirectory]: Unable to parse logging event dictionary. Failed to parse dir field: expected string or bytes-like object, got 'WindowsPath'.. Dictionary: {'dir': WindowsPath('C:/Users/lenovo/.dbt')}
[0m19:18:23.125817 [info ] [MainThread]: Creating dbt configuration folder at 
[0m19:18:23.141407 [debug] [MainThread]: Starter project path: C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\include\starter_project
[0m19:18:23.179218 [info ] [MainThread]: 
Your new dbt project "my_project" was created!

For more information on how to configure the profiles.yml file,
please consult the dbt documentation here:

  https://docs.getdbt.com/docs/configure-your-profile

One more thing:

Need help? Don't hesitate to reach out to us via GitHub issues or on Slack:

  https://community.getdbt.com/

Happy modeling!

[0m19:18:23.179218 [info ] [MainThread]: Setting up your profile.
[0m19:24:46.234643 [error] [MainThread]: Encountered an error:

[0m19:24:46.403931 [error] [MainThread]: Traceback (most recent call last):
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\cli\requires.py", line 138, in wrapper
    result, success = func(*args, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\cli\requires.py", line 101, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\cli\main.py", line 470, in init
    results = task.run()
              ^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\task\init.py", line 347, in run
    self.setup_profile(profile_name)
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\task\init.py", line 263, in setup_profile
    self.create_profile_from_target(adapter, profile_name=profile_name)
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\task\init.py", line 180, in create_profile_from_target
    self.create_profile_from_profile_template(profile_template, profile_name)
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\task\init.py", line 164, in create_profile_from_profile_template
    target = self.generate_target_from_input(prompts, initial_target)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\task\init.py", line 130, in generate_target_from_input
    target[key] = click.prompt(
                  ^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\click\termui.py", line 164, in prompt
    value = prompt_func(prompt)
            ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\click\termui.py", line 147, in prompt_func
    raise Abort() from None
click.exceptions.Abort

[0m19:24:46.450806 [debug] [MainThread]: Command `dbt init` failed at 19:24:46.435179 after 383.73 seconds
[0m19:24:46.466430 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019AC1BDE5A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019ACC38D310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019ACB0CA090>]}
[0m19:24:46.488574 [debug] [MainThread]: Flushing usage events
[0m12:57:55.790188 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000220F6CF8200>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000220F6CF9430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000220F6CF81D0>]}


============================== 12:57:55.790188 | 6147c368-7a04-4869-8757-8a403f7b24a0 ==============================
[0m12:57:55.790188 [info ] [MainThread]: Running with dbt=1.8.7
[0m12:57:55.790188 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'logs', 'version_check': 'True', 'profiles_dir': 'C:Userslenovodata-engineer-projectmy_projectprofiles.yml', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt debug --profiles-dir C:Userslenovodata-engineer-projectmy_projectprofiles.yml', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:57:55.928248 [info ] [MainThread]: dbt version: 1.8.7
[0m12:57:55.943838 [info ] [MainThread]: python version: 3.12.4
[0m12:57:55.943838 [info ] [MainThread]: python path: C:\Users\lenovo\data-engineer-project\.venv\Scripts\python.exe
[0m12:57:55.943838 [info ] [MainThread]: os info: Windows-10-10.0.19045-SP0
[0m12:57:55.943838 [info ] [MainThread]: Using profiles dir at C:Userslenovodata-engineer-projectmy_projectprofiles.yml
[0m12:57:55.943838 [info ] [MainThread]: Using profiles.yml file at C:Userslenovodata-engineer-projectmy_projectprofiles.yml\profiles.yml
[0m12:57:55.943838 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\lenovo\data-engineer-project\dbt_project.yml
[0m12:57:55.943838 [info ] [MainThread]: Configuration:
[0m12:57:55.943838 [info ] [MainThread]:   profiles.yml file [[31mERROR not found[0m]
[0m12:57:55.943838 [info ] [MainThread]:   dbt_project.yml file [[31mERROR not found[0m]
[0m12:57:55.943838 [info ] [MainThread]: Required dependencies:
[0m12:57:55.943838 [debug] [MainThread]: Executing "git --help"
[0m12:57:56.059818 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m12:57:56.059818 [debug] [MainThread]: STDERR: "b''"
[0m12:57:56.059818 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m12:57:56.059818 [info ] [MainThread]: Connection test skipped since no profile was found
[0m12:57:56.075398 [info ] [MainThread]: [31m2 checks failed:[0m
[0m12:57:56.075398 [info ] [MainThread]: dbt looked for a profiles.yml file in C:Userslenovodata-engineer-projectmy_projectprofiles.yml\profiles.yml, but did
not find one. For more information on configuring your profile, consult the
documentation:

https://docs.getdbt.com/docs/configure-your-profile


[0m12:57:56.075398 [info ] [MainThread]: Project loading failed for the following reason:
 project path <C:\Users\lenovo\data-engineer-project\dbt_project.yml> not found

[0m12:57:56.075398 [debug] [MainThread]: Command `dbt debug` failed at 12:57:56.075398 after 0.58 seconds
[0m12:57:56.075398 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000220F74EC710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000220F1552C60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000220F762DF10>]}
[0m12:57:56.075398 [debug] [MainThread]: Flushing usage events
[0m12:59:17.819728 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ED307D1280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ED30A83BF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ED33209310>]}


============================== 12:59:17.835345 | 274a19a0-77d6-48d2-bc43-d1718b8a0d5a ==============================
[0m12:59:17.835345 [info ] [MainThread]: Running with dbt=1.8.7
[0m12:59:17.835345 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'profiles.yml', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt debug --profiles-dir profiles.yml', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:59:17.888755 [info ] [MainThread]: dbt version: 1.8.7
[0m12:59:17.888755 [info ] [MainThread]: python version: 3.12.4
[0m12:59:17.904378 [info ] [MainThread]: python path: C:\Users\lenovo\data-engineer-project\.venv\Scripts\python.exe
[0m12:59:17.904378 [info ] [MainThread]: os info: Windows-10-10.0.19045-SP0
[0m12:59:17.904378 [info ] [MainThread]: Using profiles dir at profiles.yml
[0m12:59:17.904378 [info ] [MainThread]: Using profiles.yml file at profiles.yml\profiles.yml
[0m12:59:17.904378 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\lenovo\data-engineer-project\dbt_project.yml
[0m12:59:17.904378 [info ] [MainThread]: Configuration:
[0m12:59:17.920008 [info ] [MainThread]:   profiles.yml file [[31mERROR not found[0m]
[0m12:59:17.920008 [info ] [MainThread]:   dbt_project.yml file [[31mERROR not found[0m]
[0m12:59:17.920008 [info ] [MainThread]: Required dependencies:
[0m12:59:17.920008 [debug] [MainThread]: Executing "git --help"
[0m12:59:18.067179 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m12:59:18.067179 [debug] [MainThread]: STDERR: "b''"
[0m12:59:18.067179 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m12:59:18.073693 [info ] [MainThread]: Connection test skipped since no profile was found
[0m12:59:18.073693 [info ] [MainThread]: [31m2 checks failed:[0m
[0m12:59:18.073693 [info ] [MainThread]: dbt looked for a profiles.yml file in profiles.yml\profiles.yml, but did
not find one. For more information on configuring your profile, consult the
documentation:

https://docs.getdbt.com/docs/configure-your-profile


[0m12:59:18.073693 [info ] [MainThread]: Project loading failed for the following reason:
 project path <C:\Users\lenovo\data-engineer-project\dbt_project.yml> not found

[0m12:59:18.073693 [debug] [MainThread]: Command `dbt debug` failed at 12:59:18.073693 after 0.59 seconds
[0m12:59:18.073693 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ED331DFB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ED327B2300>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ED3302CE00>]}
[0m12:59:18.073693 [debug] [MainThread]: Flushing usage events
[0m13:26:37.614561 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025F6BE2A5A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025F6B467320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025F6C0F4B30>]}


============================== 13:26:37.630134 | 2a4b836f-3fd6-4a02-a12b-81de898cf04b ==============================
[0m13:26:37.630134 [info ] [MainThread]: Running with dbt=1.8.7
[0m13:26:37.630134 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt debug', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m13:26:37.745637 [info ] [MainThread]: dbt version: 1.8.7
[0m13:26:37.745637 [info ] [MainThread]: python version: 3.12.4
[0m13:26:37.745637 [info ] [MainThread]: python path: C:\Users\lenovo\data-engineer-project\.venv\Scripts\python.exe
[0m13:26:37.745637 [info ] [MainThread]: os info: Windows-10-10.0.19045-SP0
[0m13:26:45.056459 [info ] [MainThread]: Using profiles dir at C:\Users\lenovo\.dbt
[0m13:26:45.056459 [info ] [MainThread]: Using profiles.yml file at C:\Users\lenovo\.dbt\profiles.yml
[0m13:26:45.056459 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\lenovo\data-engineer-project\dbt_project.yml
[0m13:26:45.072073 [info ] [MainThread]: adapter type: bigquery
[0m13:26:45.072073 [info ] [MainThread]: adapter version: 1.8.3
[0m13:26:45.072073 [info ] [MainThread]: Configuration:
[0m13:26:45.072073 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m13:26:45.087705 [info ] [MainThread]:   dbt_project.yml file [[31mERROR not found[0m]
[0m13:26:45.087705 [info ] [MainThread]: Required dependencies:
[0m13:26:45.087705 [debug] [MainThread]: Executing "git --help"
[0m13:26:45.337347 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m13:26:45.337347 [debug] [MainThread]: STDERR: "b''"
[0m13:26:45.337347 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m13:26:45.337347 [info ] [MainThread]: Connection:
[0m13:26:45.337347 [info ] [MainThread]:   method: oauth
[0m13:26:45.337347 [info ] [MainThread]:   database: dataengineerproject-439609
[0m13:26:45.337347 [info ] [MainThread]:   execution_project: dataengineerproject-439609
[0m13:26:45.352988 [info ] [MainThread]:   schema: dp_lake
[0m13:26:45.352988 [info ] [MainThread]:   location: EU
[0m13:26:45.352988 [info ] [MainThread]:   priority: None
[0m13:26:45.352988 [info ] [MainThread]:   maximum_bytes_billed: None
[0m13:26:45.352988 [info ] [MainThread]:   impersonate_service_account: None
[0m13:26:45.352988 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m13:26:45.352988 [info ] [MainThread]:   job_retries: 1
[0m13:26:45.352988 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m13:26:45.352988 [info ] [MainThread]:   job_execution_timeout_seconds: 300
[0m13:26:45.352988 [info ] [MainThread]:   timeout_seconds: 300
[0m13:26:45.352988 [info ] [MainThread]:   client_id: None
[0m13:26:45.368615 [info ] [MainThread]:   token_uri: None
[0m13:26:45.368615 [info ] [MainThread]:   dataproc_region: None
[0m13:26:45.368615 [info ] [MainThread]:   dataproc_cluster_name: None
[0m13:26:45.368615 [info ] [MainThread]:   gcs_bucket: None
[0m13:26:45.368615 [info ] [MainThread]:   dataproc_batch: None
[0m13:26:45.368615 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m13:26:45.368615 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m13:26:45.368615 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:26:50.767425 [debug] [MainThread]: On debug: select 1 as id
[0m13:26:53.376305 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:dcb2c329-1671-4849-85cc-52a428d287a6&page=queryresults
[0m13:26:53.777340 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m13:26:53.777340 [info ] [MainThread]: [31m1 check failed:[0m
[0m13:26:53.777340 [info ] [MainThread]: Project loading failed for the following reason:
 project path <C:\Users\lenovo\data-engineer-project\dbt_project.yml> not found

[0m13:26:53.792672 [debug] [MainThread]: Command `dbt debug` failed at 13:26:53.792672 after 16.52 seconds
[0m13:26:53.792672 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m13:26:53.792672 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025F664F6ED0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025F76AA1D00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025F74108830>]}
[0m13:26:53.792672 [debug] [MainThread]: Flushing usage events
[0m13:43:18.356185 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F51FB8CE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F51F03170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F4F63B6B0>]}


============================== 13:43:18.356185 | c362ece3-3993-4ef0-b7cf-355e21ea87da ==============================
[0m13:43:18.356185 [info ] [MainThread]: Running with dbt=1.8.7
[0m13:43:18.371899 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt debug', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m13:43:18.440421 [info ] [MainThread]: dbt version: 1.8.7
[0m13:43:18.440421 [info ] [MainThread]: python version: 3.12.4
[0m13:43:18.440421 [info ] [MainThread]: python path: C:\Users\lenovo\data-engineer-project\.venv\Scripts\python.exe
[0m13:43:18.440421 [info ] [MainThread]: os info: Windows-10-10.0.19045-SP0
[0m13:43:21.432685 [info ] [MainThread]: Using profiles dir at C:\Users\lenovo\.dbt
[0m13:43:21.432685 [info ] [MainThread]: Using profiles.yml file at C:\Users\lenovo\.dbt\profiles.yml
[0m13:43:21.432685 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\lenovo\data-engineer-project\dbt_project.yml
[0m13:43:21.432685 [info ] [MainThread]: adapter type: bigquery
[0m13:43:21.432685 [info ] [MainThread]: adapter version: 1.8.3
[0m13:43:21.564165 [info ] [MainThread]: Configuration:
[0m13:43:21.564165 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m13:43:21.564165 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m13:43:21.579785 [info ] [MainThread]: Required dependencies:
[0m13:43:21.586299 [debug] [MainThread]: Executing "git --help"
[0m13:43:21.749095 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m13:43:21.749095 [debug] [MainThread]: STDERR: "b''"
[0m13:43:21.749095 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m13:43:21.749095 [info ] [MainThread]: Connection:
[0m13:43:21.749095 [info ] [MainThread]:   method: oauth
[0m13:43:21.764719 [info ] [MainThread]:   database: dataengineerproject-439609
[0m13:43:21.764719 [info ] [MainThread]:   execution_project: dataengineerproject-439609
[0m13:43:21.764719 [info ] [MainThread]:   schema: dp_lake
[0m13:43:21.764719 [info ] [MainThread]:   location: EU
[0m13:43:21.764719 [info ] [MainThread]:   priority: None
[0m13:43:21.764719 [info ] [MainThread]:   maximum_bytes_billed: None
[0m13:43:21.764719 [info ] [MainThread]:   impersonate_service_account: None
[0m13:43:21.764719 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m13:43:21.764719 [info ] [MainThread]:   job_retries: 1
[0m13:43:21.764719 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m13:43:21.764719 [info ] [MainThread]:   job_execution_timeout_seconds: 300
[0m13:43:21.764719 [info ] [MainThread]:   timeout_seconds: 300
[0m13:43:21.764719 [info ] [MainThread]:   client_id: None
[0m13:43:21.780347 [info ] [MainThread]:   token_uri: None
[0m13:43:21.780347 [info ] [MainThread]:   dataproc_region: None
[0m13:43:21.780347 [info ] [MainThread]:   dataproc_cluster_name: None
[0m13:43:21.786858 [info ] [MainThread]:   gcs_bucket: None
[0m13:43:21.786858 [info ] [MainThread]:   dataproc_batch: None
[0m13:43:21.786858 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m13:43:21.786858 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m13:43:21.786858 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:43:24.324472 [debug] [MainThread]: On debug: select 1 as id
[0m13:43:24.858360 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:59dcee23-6db7-472a-a33b-01820411433d&page=queryresults
[0m13:43:25.159560 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m13:43:25.159560 [info ] [MainThread]: [32mAll checks passed![0m
[0m13:43:25.159560 [debug] [MainThread]: Command `dbt debug` succeeded at 13:43:25.159560 after 7.12 seconds
[0m13:43:25.159560 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m13:43:25.159560 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F4FB9DA00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F51193B30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019F517D9CA0>]}
[0m13:43:25.159560 [debug] [MainThread]: Flushing usage events
[0m13:47:24.942849 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ED9F859340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ED9D6BB740>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EDA006BCE0>]}


============================== 13:47:24.958469 | 8bf6954e-b050-493c-b15b-1ab2d7a2edd6 ==============================
[0m13:47:24.958469 [info ] [MainThread]: Running with dbt=1.8.7
[0m13:47:24.958469 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt ls', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m13:47:28.514832 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8bf6954e-b050-493c-b15b-1ab2d7a2edd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EDA0194EC0>]}
[0m13:47:28.583875 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8bf6954e-b050-493c-b15b-1ab2d7a2edd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EDAA7CCBC0>]}
[0m13:47:28.583875 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m13:47:28.615123 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m13:47:28.615123 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m13:47:28.615123 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '8bf6954e-b050-493c-b15b-1ab2d7a2edd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EDA0195250>]}
[0m13:47:30.757598 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_project.example
[0m13:47:30.757598 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8bf6954e-b050-493c-b15b-1ab2d7a2edd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EDAA8407D0>]}
[0m13:47:31.143072 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8bf6954e-b050-493c-b15b-1ab2d7a2edd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EDAA5C1040>]}
[0m13:47:31.143072 [info ] [MainThread]: Found 484 macros
[0m13:47:31.143072 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8bf6954e-b050-493c-b15b-1ab2d7a2edd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EDAA94C6E0>]}
[0m13:47:31.143072 [warn ] [MainThread]: No nodes selected!
[0m13:47:31.143072 [debug] [MainThread]: Command `dbt ls` succeeded at 13:47:31.143072 after 6.75 seconds
[0m13:47:31.143072 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ED9FE8B470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001ED9F1E4110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EDA934E7E0>]}
[0m13:47:31.143072 [debug] [MainThread]: Flushing usage events
[0m13:48:05.545892 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000206C42ADC70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000206C6423440>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000206C62C2CC0>]}


============================== 13:48:05.561518 | 1e5f9685-4aef-45db-a8e0-f21b99131516 ==============================
[0m13:48:05.561518 [info ] [MainThread]: Running with dbt=1.8.7
[0m13:48:05.561518 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt ls -s products_normalized.sql', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m13:48:08.070800 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1e5f9685-4aef-45db-a8e0-f21b99131516', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000206C6665730>]}
[0m13:48:08.191839 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1e5f9685-4aef-45db-a8e0-f21b99131516', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000206CFF58BC0>]}
[0m13:48:08.191839 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m13:48:08.212085 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m13:48:08.511518 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:48:08.511518 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:48:08.511518 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_project.example
[0m13:48:08.533676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1e5f9685-4aef-45db-a8e0-f21b99131516', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000206D1557A10>]}
[0m13:48:08.680858 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1e5f9685-4aef-45db-a8e0-f21b99131516', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000206D17B49B0>]}
[0m13:48:08.680858 [info ] [MainThread]: Found 484 macros
[0m13:48:08.680858 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1e5f9685-4aef-45db-a8e0-f21b99131516', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000206C65457F0>]}
[0m13:48:08.680858 [warn ] [MainThread]: The selection criterion 'products_normalized.sql' does not match any enabled nodes
[0m13:48:08.680858 [warn ] [MainThread]: No nodes selected!
[0m13:48:08.680858 [debug] [MainThread]: Command `dbt ls` succeeded at 13:48:08.680858 after 3.39 seconds
[0m13:48:08.680858 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000206C42ADC70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000206C6AE1700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000206CEC4A2D0>]}
[0m13:48:08.680858 [debug] [MainThread]: Flushing usage events
[0m13:49:02.886865 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029A4A897590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029A4C61FDA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029A4C61F980>]}


============================== 13:49:02.902488 | d30340bf-5dd9-4d51-a04e-7ea015a0365e ==============================
[0m13:49:02.902488 [info ] [MainThread]: Running with dbt=1.8.7
[0m13:49:02.902488 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt ls -s models.1_lake', 'send_anonymous_usage_stats': 'True'}
[0m13:49:06.579558 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd30340bf-5dd9-4d51-a04e-7ea015a0365e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029A4D21CC80>]}
[0m13:49:06.664222 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd30340bf-5dd9-4d51-a04e-7ea015a0365e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029A552DAC90>]}
[0m13:49:06.664222 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m13:49:06.679871 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m13:49:07.118302 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:49:07.118302 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:49:07.118302 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_project.example
[0m13:49:07.128380 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd30340bf-5dd9-4d51-a04e-7ea015a0365e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029A57A485C0>]}
[0m13:49:07.328378 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd30340bf-5dd9-4d51-a04e-7ea015a0365e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029A576E0F80>]}
[0m13:49:07.328378 [info ] [MainThread]: Found 484 macros
[0m13:49:07.328378 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd30340bf-5dd9-4d51-a04e-7ea015a0365e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029A57A84950>]}
[0m13:49:07.328378 [warn ] [MainThread]: The selection criterion 'models.1_lake' does not match any enabled nodes
[0m13:49:07.328378 [warn ] [MainThread]: No nodes selected!
[0m13:49:07.328378 [debug] [MainThread]: Command `dbt ls` succeeded at 13:49:07.328378 after 4.78 seconds
[0m13:49:07.328378 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029A4D21F560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029A579FB4D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029A4D39E810>]}
[0m13:49:07.328378 [debug] [MainThread]: Flushing usage events
[0m13:49:21.327709 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AA3246A030>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AA324694C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AA324698E0>]}


============================== 13:49:21.343295 | 65df61f1-dd38-4e1e-8a68-e171f2d1ba5b ==============================
[0m13:49:21.343295 [info ] [MainThread]: Running with dbt=1.8.7
[0m13:49:21.343295 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt ls -s ./models/1_lake', 'send_anonymous_usage_stats': 'True'}
[0m13:49:23.580588 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '65df61f1-dd38-4e1e-8a68-e171f2d1ba5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AA3B850530>]}
[0m13:49:23.649643 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '65df61f1-dd38-4e1e-8a68-e171f2d1ba5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AA328A5790>]}
[0m13:49:23.665255 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m13:49:23.665255 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m13:49:23.950526 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:49:23.950526 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:49:23.950526 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_project.example
[0m13:49:23.950526 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '65df61f1-dd38-4e1e-8a68-e171f2d1ba5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AA3D5A3A70>]}
[0m13:49:24.082110 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '65df61f1-dd38-4e1e-8a68-e171f2d1ba5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AA3D698440>]}
[0m13:49:24.082110 [info ] [MainThread]: Found 484 macros
[0m13:49:24.082110 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '65df61f1-dd38-4e1e-8a68-e171f2d1ba5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AA3D71F2C0>]}
[0m13:49:24.082110 [warn ] [MainThread]: The selection criterion './models/1_lake' does not match any enabled nodes
[0m13:49:24.082110 [warn ] [MainThread]: No nodes selected!
[0m13:49:24.082110 [debug] [MainThread]: Command `dbt ls` succeeded at 13:49:24.082110 after 2.97 seconds
[0m13:49:24.082110 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AA3246A030>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AA3AD42AE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AA32DA7D70>]}
[0m13:49:24.082110 [debug] [MainThread]: Flushing usage events
[0m21:02:47.745394 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D4AD45DC70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D4AF88F2F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D4AF88D1F0>]}


============================== 21:02:47.761003 | 61f4ecfb-4bd6-4fac-a7f1-70fcfa70de83 ==============================
[0m21:02:47.761003 [info ] [MainThread]: Running with dbt=1.8.7
[0m21:02:47.761003 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt ls -s ./models/datahub/', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m21:02:51.055720 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '61f4ecfb-4bd6-4fac-a7f1-70fcfa70de83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D4B802B7D0>]}
[0m21:02:51.139878 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '61f4ecfb-4bd6-4fac-a7f1-70fcfa70de83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D4B821AD50>]}
[0m21:02:51.139878 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m21:02:51.155523 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m21:02:51.518119 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:02:51.518119 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:02:51.518119 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_project.example
[0m21:02:51.533691 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '61f4ecfb-4bd6-4fac-a7f1-70fcfa70de83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D4AF6070B0>]}
[0m21:02:51.702947 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '61f4ecfb-4bd6-4fac-a7f1-70fcfa70de83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D4BAB04410>]}
[0m21:02:51.702947 [info ] [MainThread]: Found 484 macros
[0m21:02:51.702947 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '61f4ecfb-4bd6-4fac-a7f1-70fcfa70de83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D4BA98AE10>]}
[0m21:02:51.702947 [warn ] [MainThread]: The selection criterion './models/datahub/' does not match any enabled nodes
[0m21:02:51.702947 [warn ] [MainThread]: No nodes selected!
[0m21:02:51.702947 [debug] [MainThread]: Command `dbt ls` succeeded at 21:02:51.702947 after 4.37 seconds
[0m21:02:51.702947 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D4AD45DC70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D4B0175CD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D4B01757C0>]}
[0m21:02:51.702947 [debug] [MainThread]: Flushing usage events
[0m21:03:18.721642 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BB6B4DB7A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BB6A5C9520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BB6A5C9BB0>]}


============================== 21:03:18.721642 | adb19239-a41f-4626-aea4-9302a5603ab4 ==============================
[0m21:03:18.721642 [info ] [MainThread]: Running with dbt=1.8.7
[0m21:03:18.721642 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt ls -s ./dbt_data_pipeline/models/datahub/', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m21:03:21.677742 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'adb19239-a41f-4626-aea4-9302a5603ab4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BB7710ED80>]}
[0m21:03:21.744739 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'adb19239-a41f-4626-aea4-9302a5603ab4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BB78521670>]}
[0m21:03:21.760385 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m21:03:21.760385 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m21:03:22.076343 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:03:22.076343 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:03:22.076343 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_project.example
[0m21:03:22.076343 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'adb19239-a41f-4626-aea4-9302a5603ab4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BB7870CB00>]}
[0m21:03:22.255709 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'adb19239-a41f-4626-aea4-9302a5603ab4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BB78AC4770>]}
[0m21:03:22.255934 [info ] [MainThread]: Found 484 macros
[0m21:03:22.257984 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'adb19239-a41f-4626-aea4-9302a5603ab4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BB788EFC20>]}
[0m21:03:22.257984 [warn ] [MainThread]: The selection criterion './dbt_data_pipeline/models/datahub/' does not match any enabled nodes
[0m21:03:22.257984 [warn ] [MainThread]: No nodes selected!
[0m21:03:22.266030 [debug] [MainThread]: Command `dbt ls` succeeded at 21:03:22.266030 after 3.78 seconds
[0m21:03:22.268069 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BB6B4DB7A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BB6DFDA330>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BB6DFDA8A0>]}
[0m21:03:22.268069 [debug] [MainThread]: Flushing usage events
[0m21:04:20.985947 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024864644BF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024866B69520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024866B69E50>]}


============================== 21:04:20.992458 | 46d8fd25-d5ed-4ad1-956f-d21193a3ead6 ==============================
[0m21:04:20.992458 [info ] [MainThread]: Running with dbt=1.8.7
[0m21:04:20.992458 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt ls -s C:Userslenovodata-engineer-projectdbt_data_pipelinemodelsdatahub', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:04:24.669389 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '46d8fd25-d5ed-4ad1-956f-d21193a3ead6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002487192BF50>]}
[0m21:04:24.802462 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '46d8fd25-d5ed-4ad1-956f-d21193a3ead6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002486FE68110>]}
[0m21:04:24.802462 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m21:04:24.869997 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m21:04:25.286686 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:04:25.286686 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:04:25.286686 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_project.example
[0m21:04:25.286686 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '46d8fd25-d5ed-4ad1-956f-d21193a3ead6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024871B5CAD0>]}
[0m21:04:25.540530 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '46d8fd25-d5ed-4ad1-956f-d21193a3ead6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024871F15400>]}
[0m21:04:25.540530 [info ] [MainThread]: Found 484 macros
[0m21:04:25.556160 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '46d8fd25-d5ed-4ad1-956f-d21193a3ead6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024871CB4F80>]}
[0m21:04:25.556160 [error] [MainThread]: Encountered an error:
Runtime Error
  'C' is not a valid method name
[0m21:04:25.571780 [debug] [MainThread]: Command `dbt ls` failed at 21:04:25.571780 after 4.87 seconds
[0m21:04:25.571780 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024864644BF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024871BF7DD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024871B5CEC0>]}
[0m21:04:25.571780 [debug] [MainThread]: Flushing usage events
[0m21:04:57.423480 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027159051EE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027157F445F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002715AC53170>]}


============================== 21:04:57.439102 | eb7ed361-372d-4d6f-8b07-5aec752dd114 ==============================
[0m21:04:57.439102 [info ] [MainThread]: Running with dbt=1.8.7
[0m21:04:57.439102 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt ls -s .dbt_data_pipelinemodelsdatahubdbt ls -s .dbt_data_pipelinemodelsdatahub', 'send_anonymous_usage_stats': 'True'}
[0m21:05:00.107954 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'eb7ed361-372d-4d6f-8b07-5aec752dd114', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027165DD50A0>]}
[0m21:05:00.230359 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'eb7ed361-372d-4d6f-8b07-5aec752dd114', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027163FEA960>]}
[0m21:05:00.230359 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m21:05:00.246006 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m21:05:00.709630 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:05:00.709630 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:05:00.725258 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_project.example
[0m21:05:00.731771 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'eb7ed361-372d-4d6f-8b07-5aec752dd114', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027166053FB0>]}
[0m21:05:00.925834 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'eb7ed361-372d-4d6f-8b07-5aec752dd114', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027165C388C0>]}
[0m21:05:00.925834 [info ] [MainThread]: Found 484 macros
[0m21:05:00.925834 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'eb7ed361-372d-4d6f-8b07-5aec752dd114', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027165FD2660>]}
[0m21:05:00.932351 [warn ] [MainThread]: The selection criterion '.dbt_data_pipelinemodelsdatahubdbt' does not match any enabled nodes
[0m21:05:00.932351 [warn ] [MainThread]: The selection criterion 'ls' does not match any enabled nodes
[0m21:05:00.932351 [warn ] [MainThread]: The selection criterion '.dbt_data_pipelinemodelsdatahub' does not match any enabled nodes
[0m21:05:00.932351 [warn ] [MainThread]: No nodes selected!
[0m21:05:00.932351 [debug] [MainThread]: Command `dbt ls` succeeded at 21:05:00.932351 after 3.71 seconds
[0m21:05:00.932351 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027157EF9C40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002715B627CE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027158965850>]}
[0m21:05:00.932351 [debug] [MainThread]: Flushing usage events
[0m21:05:17.347707 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002417EDBF440>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002417E711A60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002417E711160>]}


============================== 21:05:17.347707 | 1193ced1-245d-4132-b5e1-f66163d783c5 ==============================
[0m21:05:17.347707 [info ] [MainThread]: Running with dbt=1.8.7
[0m21:05:17.347707 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt ls', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m21:05:19.885430 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1193ced1-245d-4132-b5e1-f66163d783c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002417E711160>]}
[0m21:05:19.954459 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1193ced1-245d-4132-b5e1-f66163d783c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024106FE1FD0>]}
[0m21:05:19.954459 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m21:05:19.985730 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m21:05:20.289899 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:05:20.291968 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:05:20.291968 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_project.example
[0m21:05:20.300052 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1193ced1-245d-4132-b5e1-f66163d783c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024109652C60>]}
[0m21:05:20.424667 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1193ced1-245d-4132-b5e1-f66163d783c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024109794440>]}
[0m21:05:20.424667 [info ] [MainThread]: Found 484 macros
[0m21:05:20.424667 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1193ced1-245d-4132-b5e1-f66163d783c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024107469670>]}
[0m21:05:20.424667 [warn ] [MainThread]: No nodes selected!
[0m21:05:20.432913 [debug] [MainThread]: Command `dbt ls` succeeded at 21:05:20.432913 after 3.30 seconds
[0m21:05:20.432913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002417E5DBC20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002417EAE05C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002417EAE3BC0>]}
[0m21:05:20.432913 [debug] [MainThread]: Flushing usage events
[0m21:07:10.258940 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000211D2947EF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000211D226BD70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000211D0A64BC0>]}


============================== 21:07:10.274567 | 1142dead-1d34-436f-923f-f8272652c489 ==============================
[0m21:07:10.274567 [info ] [MainThread]: Running with dbt=1.8.7
[0m21:07:10.274567 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt ls', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:07:13.047226 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1142dead-1d34-436f-923f-f8272652c489', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000211D3244B90>]}
[0m21:07:13.131845 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1142dead-1d34-436f-923f-f8272652c489', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000211DBD2FE30>]}
[0m21:07:13.131845 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m21:07:13.163168 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m21:07:13.247791 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m21:07:13.247791 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '1142dead-1d34-436f-923f-f8272652c489', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000211DD8C7E90>]}
[0m21:07:14.864151 [error] [MainThread]: Encountered an error:
Compilation Error in model customers_staging (dbt_data_pipeline/models\datahub\customers_staging.sql)
  unexpected char '#' at 70
    line 4
      tags=["hourly"],  # Tag pour indiquer que ce modèle est mis à jour toutes les heures
[0m21:07:14.864151 [debug] [MainThread]: Command `dbt ls` failed at 21:07:14.864151 after 4.92 seconds
[0m21:07:14.864151 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000211D2947EF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000211DD9CCF20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000211DDBBF500>]}
[0m21:07:14.864151 [debug] [MainThread]: Flushing usage events
[0m21:10:04.025532 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000183B3A4DC70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000183B5ECF800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000183B2A31490>]}


============================== 21:10:04.035596 | 2a99e240-b94a-4156-9142-9f81514e8a5b ==============================
[0m21:10:04.035596 [info ] [MainThread]: Running with dbt=1.8.7
[0m21:10:04.035596 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt ls -s .models', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m21:10:08.392814 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2a99e240-b94a-4156-9142-9f81514e8a5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000183B2D59A30>]}
[0m21:10:08.493129 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2a99e240-b94a-4156-9142-9f81514e8a5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000183B422D610>]}
[0m21:10:08.493129 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m21:10:08.515245 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m21:10:08.609018 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m21:10:08.615535 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '2a99e240-b94a-4156-9142-9f81514e8a5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000183C1184110>]}
[0m21:10:11.016909 [error] [MainThread]: Encountered an error:
Compilation Error in model customers_staging (dbt_data_pipeline/models\datahub\customers_staging.sql)
  invalid syntax for function call expression
    line 2
      config(
[0m21:10:11.025071 [debug] [MainThread]: Command `dbt ls` failed at 21:10:11.025071 after 7.60 seconds
[0m21:10:11.027107 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000183B3A4DC70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000183C0F4EB70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000183B6745A00>]}
[0m21:10:11.027107 [debug] [MainThread]: Flushing usage events
[0m21:11:13.275656 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000196158BCBF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000196158BC9E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000196158BCC20>]}


============================== 21:11:13.275656 | 3a2944f9-d5cd-4dae-86ac-a83b70bc6d2b ==============================
[0m21:11:13.275656 [info ] [MainThread]: Running with dbt=1.8.7
[0m21:11:13.291301 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt ls -s ./models', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m21:11:16.740008 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3a2944f9-d5cd-4dae-86ac-a83b70bc6d2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000196203AC650>]}
[0m21:11:16.809081 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3a2944f9-d5cd-4dae-86ac-a83b70bc6d2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001961D868E90>]}
[0m21:11:16.809081 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m21:11:16.824774 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m21:11:16.871599 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m21:11:16.887274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '3a2944f9-d5cd-4dae-86ac-a83b70bc6d2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000196205C7BF0>]}
[0m21:11:18.590012 [error] [MainThread]: Encountered an error:
Compilation Error in model customers_staging (dbt_data_pipeline/models\datahub\customers_staging.sql)
  invalid syntax for function call expression
    line 2
      config(
[0m21:11:18.590012 [debug] [MainThread]: Command `dbt ls` failed at 21:11:18.590012 after 5.66 seconds
[0m21:11:18.590012 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019615994D10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001961EABF470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000196205E4C80>]}
[0m21:11:18.590012 [debug] [MainThread]: Flushing usage events
[0m21:15:11.980616 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D66F18FE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D6A6F3E00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D66F196A0>]}


============================== 21:15:11.987164 | d5ad22b4-e0af-4084-b6d4-030f2724b719 ==============================
[0m21:15:11.987164 [info ] [MainThread]: Running with dbt=1.8.7
[0m21:15:11.987164 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt compile -s customers_staging.sql', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:15:15.594412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd5ad22b4-e0af-4084-b6d4-030f2724b719', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D727B96D0>]}
[0m21:15:15.672559 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd5ad22b4-e0af-4084-b6d4-030f2724b719', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D73360410>]}
[0m21:15:15.672559 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m21:15:15.694687 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m21:15:15.757203 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m21:15:15.757203 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'd5ad22b4-e0af-4084-b6d4-030f2724b719', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D72DC18B0>]}
[0m21:15:17.737645 [error] [MainThread]: Encountered an error:
Compilation Error in model products_staging (dbt_data_pipeline/models\datahub\products_staging.sql)
  invalid syntax for function call expression
    line 2
      config(
[0m21:15:17.753314 [debug] [MainThread]: Command `dbt compile` failed at 21:15:17.753314 after 6.09 seconds
[0m21:15:17.753314 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D6A4AF3B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D64755610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021D75348440>]}
[0m21:15:17.753314 [debug] [MainThread]: Flushing usage events
[0m21:16:47.234845 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C6CB87D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C6CBA240>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C6CB8740>]}


============================== 21:16:47.250505 | 2ca24c1a-a9bf-4491-a7ff-286268072784 ==============================
[0m21:16:47.250505 [info ] [MainThread]: Running with dbt=1.8.7
[0m21:16:47.250505 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt compile -s customers_staging.sql', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m21:16:50.411375 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2ca24c1a-a9bf-4491-a7ff-286268072784', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9CF634BC0>]}
[0m21:16:50.490725 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2ca24c1a-a9bf-4491-a7ff-286268072784', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9CFFDBE00>]}
[0m21:16:50.490725 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m21:16:50.500776 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m21:16:50.563350 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m21:16:50.563350 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '2ca24c1a-a9bf-4491-a7ff-286268072784', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C653C3E0>]}
[0m21:16:52.796056 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_data_pipeline.customers_staging' (dbt_data_pipeline/models\datahub\customers_staging.sql) depends on a source named 'dp_lake.customers_normalized' which was not found
[0m21:16:52.796056 [debug] [MainThread]: Command `dbt compile` failed at 21:16:52.796056 after 5.87 seconds
[0m21:16:52.804093 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C6CDB0B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9C49EB320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9D013A930>]}
[0m21:16:52.804093 [debug] [MainThread]: Flushing usage events
[0m21:18:22.864985 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024BA16D8620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024BA168F200>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024BA168FDA0>]}


============================== 21:18:22.880612 | a079551b-0074-4b3f-8063-f569280abec3 ==============================
[0m21:18:22.880612 [info ] [MainThread]: Running with dbt=1.8.7
[0m21:18:22.880612 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt compile -s customers_staging.sql', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m21:18:26.385807 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a079551b-0074-4b3f-8063-f569280abec3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024BAA0C9880>]}
[0m21:18:26.463950 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a079551b-0074-4b3f-8063-f569280abec3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024BAB23A240>]}
[0m21:18:26.463950 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m21:18:26.486189 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m21:18:26.548713 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m21:18:26.548713 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'a079551b-0074-4b3f-8063-f569280abec3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024BACE57EF0>]}
[0m21:18:28.808319 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_project.example
[0m21:18:28.823935 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a079551b-0074-4b3f-8063-f569280abec3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024BAD118BC0>]}
[0m21:18:29.024498 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a079551b-0074-4b3f-8063-f569280abec3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024BACF271D0>]}
[0m21:18:29.040157 [info ] [MainThread]: Found 5 models, 4 data tests, 3 sources, 484 macros
[0m21:18:29.040157 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a079551b-0074-4b3f-8063-f569280abec3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024BACE75FD0>]}
[0m21:18:29.040157 [info ] [MainThread]: 
[0m21:18:29.040157 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m21:18:29.040157 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_lake'
[0m21:18:29.040157 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:18:32.396179 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a079551b-0074-4b3f-8063-f569280abec3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024BAD185BE0>]}
[0m21:18:32.396179 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:18:32.396179 [info ] [MainThread]: 
[0m21:18:32.429055 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.customers_staging
[0m21:18:32.429055 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.customers_staging'
[0m21:18:32.429055 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.customers_staging
[0m21:18:32.444684 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.customers_staging"
[0m21:18:32.460403 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.customers_staging
[0m21:18:32.464415 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.customers_staging
[0m21:18:32.464415 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:18:32.464415 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_lake' was properly closed.
[0m21:18:32.464415 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.customers_staging' was properly closed.
[0m21:18:32.464415 [debug] [MainThread]: Command end result
[0m21:18:32.511306 [info ] [MainThread]: Compiled node 'customers_staging' is:
-- Tag pour indiquer que ce modèle est mis à jour toutes les heures


-- Sélectionner uniquement les enregistrements ingérés au cours de la dernière heure
SELECT *
FROM `dataengineerproject-439609`.`dp_lake`.`customers_normalized`
WHERE _dp_ingestion_timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR)
[0m21:18:32.511306 [debug] [MainThread]: Command `dbt compile` succeeded at 21:18:32.511306 after 10.01 seconds
[0m21:18:32.511306 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024BA1311EB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024BA1F7AE40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024BA1F78140>]}
[0m21:18:32.511306 [debug] [MainThread]: Flushing usage events
[0m21:19:41.256932 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028245AB9100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000282422283E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028242229700>]}


============================== 21:19:41.272576 | bb2afb78-1bf8-406c-9c51-39e5d28ff60f ==============================
[0m21:19:41.272576 [info ] [MainThread]: Running with dbt=1.8.7
[0m21:19:41.272576 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt ls -s ./models', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m21:19:44.322920 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bb2afb78-1bf8-406c-9c51-39e5d28ff60f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002824ED27530>]}
[0m21:19:44.391923 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bb2afb78-1bf8-406c-9c51-39e5d28ff60f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028245C0F1A0>]}
[0m21:19:44.391923 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m21:19:44.407700 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m21:19:44.839709 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:19:44.839709 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:19:44.855339 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_project.example
[0m21:19:44.892678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bb2afb78-1bf8-406c-9c51-39e5d28ff60f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028245192DE0>]}
[0m21:19:45.124539 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bb2afb78-1bf8-406c-9c51-39e5d28ff60f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028250A426C0>]}
[0m21:19:45.140174 [info ] [MainThread]: Found 5 models, 4 data tests, 3 sources, 484 macros
[0m21:19:45.140174 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bb2afb78-1bf8-406c-9c51-39e5d28ff60f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000282507ADBB0>]}
[0m21:19:45.140174 [warn ] [MainThread]: The selection criterion './models' does not match any enabled nodes
[0m21:19:45.140174 [warn ] [MainThread]: No nodes selected!
[0m21:19:45.140174 [debug] [MainThread]: Command `dbt ls` succeeded at 21:19:45.140174 after 4.18 seconds
[0m21:19:45.140174 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002824595E480>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002823FB45610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002824E446060>]}
[0m21:19:45.140174 [debug] [MainThread]: Flushing usage events
[0m21:20:04.328708 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026CC3824E60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026CC3825100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026CC3824EC0>]}


============================== 21:20:04.328708 | 6c77ff84-4083-4fbe-8475-ec0c7611d93c ==============================
[0m21:20:04.328708 [info ] [MainThread]: Running with dbt=1.8.7
[0m21:20:04.344336 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt ls -s ./models/datahub', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m21:20:06.644429 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6c77ff84-4083-4fbe-8475-ec0c7611d93c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026CC3826D50>]}
[0m21:20:06.713549 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6c77ff84-4083-4fbe-8475-ec0c7611d93c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026CCCAFD0A0>]}
[0m21:20:06.713549 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m21:20:06.729239 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m21:20:07.107790 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:20:07.107790 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:20:07.114340 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_project.example
[0m21:20:07.161293 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6c77ff84-4083-4fbe-8475-ec0c7611d93c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026CCE35A0C0>]}
[0m21:20:07.361990 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6c77ff84-4083-4fbe-8475-ec0c7611d93c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026CCE65ED20>]}
[0m21:20:07.361990 [info ] [MainThread]: Found 5 models, 4 data tests, 3 sources, 484 macros
[0m21:20:07.361990 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6c77ff84-4083-4fbe-8475-ec0c7611d93c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026CCE306780>]}
[0m21:20:07.361990 [warn ] [MainThread]: The selection criterion './models/datahub' does not match any enabled nodes
[0m21:20:07.361990 [warn ] [MainThread]: No nodes selected!
[0m21:20:07.377565 [debug] [MainThread]: Command `dbt ls` succeeded at 21:20:07.377565 after 3.25 seconds
[0m21:20:07.377565 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026CC2ACFA10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026CC351C6B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026CCB92CF80>]}
[0m21:20:07.377565 [debug] [MainThread]: Flushing usage events
[0m21:20:37.269330 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002279702D160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022797B53170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000227997C42F0>]}


============================== 21:20:37.269330 | 3b9df862-f919-4d85-94c2-e820639b3111 ==============================
[0m21:20:37.269330 [info ] [MainThread]: Running with dbt=1.8.7
[0m21:20:37.269330 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt ls -s model.dbt_data_pipeline.', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m21:20:39.902801 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3b9df862-f919-4d85-94c2-e820639b3111', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000227A4A2BE60>]}
[0m21:20:39.976469 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3b9df862-f919-4d85-94c2-e820639b3111', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000227A328A960>]}
[0m21:20:39.976469 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m21:20:39.996802 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m21:20:40.441524 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:20:40.441524 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:20:40.461269 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_project.example
[0m21:20:40.525840 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3b9df862-f919-4d85-94c2-e820639b3111', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000227A4B26DB0>]}
[0m21:20:40.720043 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3b9df862-f919-4d85-94c2-e820639b3111', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000227A4E4B650>]}
[0m21:20:40.720043 [info ] [MainThread]: Found 5 models, 4 data tests, 3 sources, 484 macros
[0m21:20:40.720043 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3b9df862-f919-4d85-94c2-e820639b3111', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022799297470>]}
[0m21:20:40.726059 [warn ] [MainThread]: The selection criterion 'model.dbt_data_pipeline.' does not match any enabled nodes
[0m21:20:40.726059 [warn ] [MainThread]: No nodes selected!
[0m21:20:40.726059 [debug] [MainThread]: Command `dbt ls` succeeded at 21:20:40.726059 after 3.67 seconds
[0m21:20:40.726059 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022793FCABD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002279974FE60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002279974F080>]}
[0m21:20:40.726059 [debug] [MainThread]: Flushing usage events
[0m21:20:50.778831 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018FF7A8C830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018FF7A8CFE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018FF7A8D070>]}


============================== 21:20:50.794442 | 7cd975cf-b7d1-42b2-a5c6-30860adf2fc0 ==============================
[0m21:20:50.794442 [info ] [MainThread]: Running with dbt=1.8.7
[0m21:20:50.794442 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt ls -s model.dbt_data_pipeline', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m21:20:53.050704 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7cd975cf-b7d1-42b2-a5c6-30860adf2fc0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018FF83A5340>]}
[0m21:20:53.128902 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7cd975cf-b7d1-42b2-a5c6-30860adf2fc0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018FF78B3CB0>]}
[0m21:20:53.128902 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m21:20:53.151048 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m21:20:53.514144 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:20:53.514144 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:20:53.529759 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_project.example
[0m21:20:53.598792 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7cd975cf-b7d1-42b2-a5c6-30860adf2fc0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018F82E85F10>]}
[0m21:20:53.814583 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7cd975cf-b7d1-42b2-a5c6-30860adf2fc0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018F8318F800>]}
[0m21:20:53.814583 [info ] [MainThread]: Found 5 models, 4 data tests, 3 sources, 484 macros
[0m21:20:53.814583 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7cd975cf-b7d1-42b2-a5c6-30860adf2fc0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018F83073D70>]}
[0m21:20:53.830210 [warn ] [MainThread]: The selection criterion 'model.dbt_data_pipeline' does not match any enabled nodes
[0m21:20:53.830210 [warn ] [MainThread]: No nodes selected!
[0m21:20:53.830210 [debug] [MainThread]: Command `dbt ls` succeeded at 21:20:53.830210 after 3.25 seconds
[0m21:20:53.830210 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018FF82085C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018FF82085F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018FF4979700>]}
[0m21:20:53.830210 [debug] [MainThread]: Flushing usage events
[0m21:21:17.409614 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002807F517140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002807F517560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002807F5157F0>]}


============================== 21:21:17.409614 | 68ba8602-2e9d-419c-96b7-3ce281f2f1bb ==============================
[0m21:21:17.409614 [info ] [MainThread]: Running with dbt=1.8.7
[0m21:21:17.409614 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt ls -s dbt_data_pipeline/models/', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:21:20.368378 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '68ba8602-2e9d-419c-96b7-3ce281f2f1bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002807F944E30>]}
[0m21:21:20.430904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '68ba8602-2e9d-419c-96b7-3ce281f2f1bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002807E994DA0>]}
[0m21:21:20.446523 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m21:21:20.446523 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m21:21:20.900702 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:21:20.916384 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:21:20.916384 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_project.example
[0m21:21:20.985474 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '68ba8602-2e9d-419c-96b7-3ce281f2f1bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002800A4FEDE0>]}
[0m21:21:21.186193 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '68ba8602-2e9d-419c-96b7-3ce281f2f1bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002800A887050>]}
[0m21:21:21.201821 [info ] [MainThread]: Found 5 models, 4 data tests, 3 sources, 484 macros
[0m21:21:21.201821 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '68ba8602-2e9d-419c-96b7-3ce281f2f1bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002800A4FF9B0>]}
[0m21:21:21.201821 [debug] [MainThread]: Command `dbt ls` succeeded at 21:21:21.201821 after 4.05 seconds
[0m21:21:21.201821 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000280799DABD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002807F944B00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002807F944CE0>]}
[0m21:21:21.201821 [debug] [MainThread]: Flushing usage events
[0m22:33:38.575972 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D947F0C6E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D947E08500>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D947C8DC10>]}


============================== 22:33:38.586130 | 389762b5-4da8-4400-b86a-e0ec0d7f59b2 ==============================
[0m22:33:38.586130 [info ] [MainThread]: Running with dbt=1.8.7
[0m22:33:38.587130 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --profiles-dir C:\\Users\\lenovo\\.dbt', 'send_anonymous_usage_stats': 'True'}
[0m22:33:44.591138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '389762b5-4da8-4400-b86a-e0ec0d7f59b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D94FF1D550>]}
[0m22:33:44.724516 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '389762b5-4da8-4400-b86a-e0ec0d7f59b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D947038EF0>]}
[0m22:33:44.728532 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m22:33:44.772601 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m22:33:45.316371 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:33:45.317436 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:33:45.325527 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_project.example
[0m22:33:45.427660 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '389762b5-4da8-4400-b86a-e0ec0d7f59b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D94FF5AD50>]}
[0m22:33:45.709356 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '389762b5-4da8-4400-b86a-e0ec0d7f59b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D952E400B0>]}
[0m22:33:45.710356 [info ] [MainThread]: Found 5 models, 4 data tests, 3 sources, 484 macros
[0m22:33:45.711432 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '389762b5-4da8-4400-b86a-e0ec0d7f59b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D952DF7D40>]}
[0m22:33:45.715435 [info ] [MainThread]: 
[0m22:33:45.716437 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m22:33:45.724433 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m22:33:45.726436 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:33:50.051724 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_lake'
[0m22:33:50.052725 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:33:50.166264 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '389762b5-4da8-4400-b86a-e0ec0d7f59b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D945ACD700>]}
[0m22:33:50.167267 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:33:50.167267 [info ] [MainThread]: 
[0m22:33:50.175355 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.customers_staging
[0m22:33:50.176363 [info ] [Thread-1 (]: 1 of 5 START sql view model dp_lake.customers_staging .......................... [RUN]
[0m22:33:50.177362 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.customers_staging'
[0m22:33:50.178363 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.customers_staging
[0m22:33:50.192336 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.customers_staging"
[0m22:33:50.196064 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.customers_staging
[0m22:33:50.240068 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.customers_staging"
[0m22:33:50.249066 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m22:33:50.250067 [debug] [Thread-1 (]: On model.dbt_data_pipeline.customers_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.customers_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_lake`.`customers_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


-- Sélectionner uniquement les enregistrements ingérés au cours de la dernière heure
SELECT *
FROM `dataengineerproject-439609`.`dp_lake`.`customers_normalized`
WHERE _dp_ingestion_timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR);


[0m22:33:50.432595 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:8bfc9c79-42d1-4e33-8954-0af572dfbfe5&page=queryresults
[0m22:33:50.433599 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:8bfc9c79-42d1-4e33-8954-0af572dfbfe5&page=queryresults
[0m22:33:50.473728 [debug] [Thread-1 (]: Database Error in model customers_staging (dbt_data_pipeline/models\datahub\customers_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\customers_staging.sql
[0m22:33:50.475730 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '389762b5-4da8-4400-b86a-e0ec0d7f59b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D94771DB80>]}
[0m22:33:50.476733 [error] [Thread-1 (]: 1 of 5 ERROR creating sql view model dp_lake.customers_staging ................. [[31mERROR[0m in 0.30s]
[0m22:33:50.478731 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.customers_staging
[0m22:33:50.479736 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.my_first_dbt_model
[0m22:33:50.481733 [info ] [Thread-1 (]: 2 of 5 START sql table model dp_lake.my_first_dbt_model ........................ [RUN]
[0m22:33:50.482731 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_data_pipeline.customers_staging, now model.dbt_data_pipeline.my_first_dbt_model)
[0m22:33:50.483732 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.my_first_dbt_model
[0m22:33:50.488727 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.my_first_dbt_model"
[0m22:33:50.491392 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.my_first_dbt_model
[0m22:33:50.528394 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.my_first_dbt_model"
[0m22:33:50.532390 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:33:50.533389 [debug] [Thread-1 (]: On model.dbt_data_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.my_first_dbt_model"} */

  
    

    create or replace table `dataengineerproject-439609`.`dp_lake`.`my_first_dbt_model`
      
    
    

    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m22:33:50.706283 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:82aad3d7-1755-4a94-8204-d951bf3918d1&page=queryresults
[0m22:33:50.707296 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:82aad3d7-1755-4a94-8204-d951bf3918d1&page=queryresults
[0m22:33:50.713378 [debug] [Thread-1 (]: Database Error in model my_first_dbt_model (dbt_data_pipeline/models\example\my_first_dbt_model.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\example\my_first_dbt_model.sql
[0m22:33:50.714380 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '389762b5-4da8-4400-b86a-e0ec0d7f59b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9532FE450>]}
[0m22:33:50.716407 [error] [Thread-1 (]: 2 of 5 ERROR creating sql table model dp_lake.my_first_dbt_model ............... [[31mERROR[0m in 0.23s]
[0m22:33:50.717406 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.my_first_dbt_model
[0m22:33:50.718406 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.products_staging
[0m22:33:50.719382 [info ] [Thread-1 (]: 3 of 5 START sql view model dp_lake.products_staging ........................... [RUN]
[0m22:33:50.720416 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_data_pipeline.my_first_dbt_model, now model.dbt_data_pipeline.products_staging)
[0m22:33:50.721379 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.products_staging
[0m22:33:50.724486 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.products_staging"
[0m22:33:50.728489 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.products_staging
[0m22:33:50.731566 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.products_staging"
[0m22:33:50.735912 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:33:50.736967 [debug] [Thread-1 (]: On model.dbt_data_pipeline.products_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.products_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_lake`.`products_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


-- Sélectionner uniquement les enregistrements ingérés au cours de la dernière heure
SELECT *
FROM `dataengineerproject-439609`.`dp_lake`.`products_normalized`
WHERE _dp_ingestion_timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR);


[0m22:33:50.896052 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:ac425209-0f8e-4e52-991f-01e78951d598&page=queryresults
[0m22:33:50.897052 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:ac425209-0f8e-4e52-991f-01e78951d598&page=queryresults
[0m22:33:50.903121 [debug] [Thread-1 (]: Database Error in model products_staging (dbt_data_pipeline/models\datahub\products_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\products_staging.sql
[0m22:33:50.904120 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '389762b5-4da8-4400-b86a-e0ec0d7f59b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D953353680>]}
[0m22:33:50.905120 [error] [Thread-1 (]: 3 of 5 ERROR creating sql view model dp_lake.products_staging .................. [[31mERROR[0m in 0.18s]
[0m22:33:50.906119 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.products_staging
[0m22:33:50.907152 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.sales_staging
[0m22:33:50.908117 [info ] [Thread-1 (]: 4 of 5 START sql view model dp_lake.sales_staging .............................. [RUN]
[0m22:33:50.909119 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_data_pipeline.products_staging, now model.dbt_data_pipeline.sales_staging)
[0m22:33:50.910118 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.sales_staging
[0m22:33:50.916122 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.sales_staging"
[0m22:33:50.921119 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.sales_staging
[0m22:33:50.924120 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.sales_staging"
[0m22:33:50.927133 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:33:50.928145 [debug] [Thread-1 (]: On model.dbt_data_pipeline.sales_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.sales_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_lake`.`sales_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


-- Sélectionner uniquement les enregistrements ingérés au cours de la dernière heure
SELECT *
FROM `dataengineerproject-439609`.`dp_lake`.`sales_normalized`
WHERE _dp_ingestion_timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR);


[0m22:33:51.115600 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:1d49f254-0784-438a-a20a-043fa96134e6&page=queryresults
[0m22:33:51.116624 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:1d49f254-0784-438a-a20a-043fa96134e6&page=queryresults
[0m22:33:51.122705 [debug] [Thread-1 (]: Database Error in model sales_staging (dbt_data_pipeline/models\datahub\sales_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\sales_staging.sql
[0m22:33:51.123706 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '389762b5-4da8-4400-b86a-e0ec0d7f59b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D953374DD0>]}
[0m22:33:51.124707 [error] [Thread-1 (]: 4 of 5 ERROR creating sql view model dp_lake.sales_staging ..................... [[31mERROR[0m in 0.21s]
[0m22:33:51.125705 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.sales_staging
[0m22:33:51.126730 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.my_second_dbt_model
[0m22:33:51.127703 [info ] [Thread-1 (]: 5 of 5 SKIP relation dp_lake.my_second_dbt_model ............................... [[33mSKIP[0m]
[0m22:33:51.128704 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.my_second_dbt_model
[0m22:33:51.130701 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:33:51.130701 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m22:33:51.131701 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_lake' was properly closed.
[0m22:33:51.132701 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.sales_staging' was properly closed.
[0m22:33:51.132701 [info ] [MainThread]: 
[0m22:33:51.133701 [info ] [MainThread]: Finished running 4 view models, 1 table model in 0 hours 0 minutes and 5.42 seconds (5.42s).
[0m22:33:51.135701 [debug] [MainThread]: Command end result
[0m22:33:51.186541 [info ] [MainThread]: 
[0m22:33:51.188545 [info ] [MainThread]: [31mCompleted with 4 errors and 0 warnings:[0m
[0m22:33:51.189578 [info ] [MainThread]: 
[0m22:33:51.191662 [error] [MainThread]:   Database Error in model customers_staging (dbt_data_pipeline/models\datahub\customers_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\customers_staging.sql
[0m22:33:51.192662 [info ] [MainThread]: 
[0m22:33:51.193697 [error] [MainThread]:   Database Error in model my_first_dbt_model (dbt_data_pipeline/models\example\my_first_dbt_model.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\example\my_first_dbt_model.sql
[0m22:33:51.193697 [info ] [MainThread]: 
[0m22:33:51.194696 [error] [MainThread]:   Database Error in model products_staging (dbt_data_pipeline/models\datahub\products_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\products_staging.sql
[0m22:33:51.195773 [info ] [MainThread]: 
[0m22:33:51.196799 [error] [MainThread]:   Database Error in model sales_staging (dbt_data_pipeline/models\datahub\sales_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\sales_staging.sql
[0m22:33:51.197774 [info ] [MainThread]: 
[0m22:33:51.199775 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=4 SKIP=1 TOTAL=5
[0m22:33:51.202856 [debug] [MainThread]: Command `dbt run` failed at 22:33:51.201847 after 13.13 seconds
[0m22:33:51.203850 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D9475C0BF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D947790530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D947BE0380>]}
[0m22:33:51.203850 [debug] [MainThread]: Flushing usage events
[0m22:40:58.262382 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018C6B06DA60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018C6AE8B0E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018C6866B470>]}


============================== 22:40:58.284514 | 1ab941a6-a37a-42ee-ae2d-138796c8a31d ==============================
[0m22:40:58.284514 [info ] [MainThread]: Running with dbt=1.8.7
[0m22:40:58.284514 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'profiles_dir': 'C:/Users/lenovo/.dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --profiles-dir C:/Users/lenovo/.dbt', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m22:41:02.638112 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1ab941a6-a37a-42ee-ae2d-138796c8a31d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018C6B195580>]}
[0m22:41:02.722781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1ab941a6-a37a-42ee-ae2d-138796c8a31d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018C73CB78C0>]}
[0m22:41:02.722781 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m22:41:02.738406 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m22:41:03.290388 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:41:03.290388 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:41:03.290388 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_project.example
[0m22:41:03.359479 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1ab941a6-a37a-42ee-ae2d-138796c8a31d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018C75BAE720>]}
[0m22:41:03.606857 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1ab941a6-a37a-42ee-ae2d-138796c8a31d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018C75F3C470>]}
[0m22:41:03.606857 [info ] [MainThread]: Found 5 models, 4 data tests, 3 sources, 484 macros
[0m22:41:03.606857 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1ab941a6-a37a-42ee-ae2d-138796c8a31d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018C75CDE900>]}
[0m22:41:03.606857 [info ] [MainThread]: 
[0m22:41:03.606857 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m22:41:03.622290 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m22:41:03.622290 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:41:07.063638 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_lake'
[0m22:41:07.078982 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:41:07.216966 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1ab941a6-a37a-42ee-ae2d-138796c8a31d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018C75C34BF0>]}
[0m22:41:07.232592 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:41:07.232592 [info ] [MainThread]: 
[0m22:41:07.232592 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.customers_staging
[0m22:41:07.232592 [info ] [Thread-1 (]: 1 of 5 START sql view model dp_lake.customers_staging .......................... [RUN]
[0m22:41:07.232592 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.customers_staging'
[0m22:41:07.232592 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.customers_staging
[0m22:41:07.248215 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.customers_staging"
[0m22:41:07.263844 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.customers_staging
[0m22:41:07.317259 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.customers_staging"
[0m22:41:07.317259 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m22:41:07.317259 [debug] [Thread-1 (]: On model.dbt_data_pipeline.customers_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.customers_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_lake`.`customers_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


-- Sélectionner uniquement les enregistrements ingérés au cours de la dernière heure
SELECT *
FROM `dataengineerproject-439609`.`dp_lake`.`customers_normalized`
WHERE _dp_ingestion_timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR);


[0m22:41:07.501783 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:54647781-e3db-4ab6-9652-0dc3d2ec5727&page=queryresults
[0m22:41:07.501783 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:54647781-e3db-4ab6-9652-0dc3d2ec5727&page=queryresults
[0m22:41:07.533024 [debug] [Thread-1 (]: Database Error in model customers_staging (dbt_data_pipeline/models\datahub\customers_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\customers_staging.sql
[0m22:41:07.540775 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1ab941a6-a37a-42ee-ae2d-138796c8a31d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018C75FBC0E0>]}
[0m22:41:07.540775 [error] [Thread-1 (]: 1 of 5 ERROR creating sql view model dp_lake.customers_staging ................. [[31mERROR[0m in 0.31s]
[0m22:41:07.540775 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.customers_staging
[0m22:41:07.540775 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.my_first_dbt_model
[0m22:41:07.540775 [info ] [Thread-1 (]: 2 of 5 START sql table model dp_lake.my_first_dbt_model ........................ [RUN]
[0m22:41:07.540775 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_data_pipeline.customers_staging, now model.dbt_data_pipeline.my_first_dbt_model)
[0m22:41:07.540775 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.my_first_dbt_model
[0m22:41:07.556410 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.my_first_dbt_model"
[0m22:41:07.556410 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.my_first_dbt_model
[0m22:41:07.617322 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.my_first_dbt_model"
[0m22:41:07.632949 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:41:07.632949 [debug] [Thread-1 (]: On model.dbt_data_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.my_first_dbt_model"} */

  
    

    create or replace table `dataengineerproject-439609`.`dp_lake`.`my_first_dbt_model`
      
    
    

    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m22:41:07.801881 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:9a3e9136-48cf-417e-957c-2142ec9c1e2d&page=queryresults
[0m22:41:07.801881 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:9a3e9136-48cf-417e-957c-2142ec9c1e2d&page=queryresults
[0m22:41:07.817507 [debug] [Thread-1 (]: Database Error in model my_first_dbt_model (dbt_data_pipeline/models\example\my_first_dbt_model.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\example\my_first_dbt_model.sql
[0m22:41:07.817507 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1ab941a6-a37a-42ee-ae2d-138796c8a31d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018C763FE300>]}
[0m22:41:07.817507 [error] [Thread-1 (]: 2 of 5 ERROR creating sql table model dp_lake.my_first_dbt_model ............... [[31mERROR[0m in 0.28s]
[0m22:41:07.817507 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.my_first_dbt_model
[0m22:41:07.817507 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.products_staging
[0m22:41:07.833133 [info ] [Thread-1 (]: 3 of 5 START sql view model dp_lake.products_staging ........................... [RUN]
[0m22:41:07.833133 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_data_pipeline.my_first_dbt_model, now model.dbt_data_pipeline.products_staging)
[0m22:41:07.833133 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.products_staging
[0m22:41:07.833133 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.products_staging"
[0m22:41:07.833133 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.products_staging
[0m22:41:07.848761 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.products_staging"
[0m22:41:07.848761 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:41:07.848761 [debug] [Thread-1 (]: On model.dbt_data_pipeline.products_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.products_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_lake`.`products_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


-- Sélectionner uniquement les enregistrements ingérés au cours de la dernière heure
SELECT *
FROM `dataengineerproject-439609`.`dp_lake`.`products_normalized`
WHERE _dp_ingestion_timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR);


[0m22:41:08.033479 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:2d192f6d-0f8a-4a52-99e1-b7588b601f89&page=queryresults
[0m22:41:08.049178 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:2d192f6d-0f8a-4a52-99e1-b7588b601f89&page=queryresults
[0m22:41:08.049178 [debug] [Thread-1 (]: Database Error in model products_staging (dbt_data_pipeline/models\datahub\products_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\products_staging.sql
[0m22:41:08.049178 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1ab941a6-a37a-42ee-ae2d-138796c8a31d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018C76452270>]}
[0m22:41:08.064734 [error] [Thread-1 (]: 3 of 5 ERROR creating sql view model dp_lake.products_staging .................. [[31mERROR[0m in 0.22s]
[0m22:41:08.064734 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.products_staging
[0m22:41:08.064734 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.sales_staging
[0m22:41:08.064734 [info ] [Thread-1 (]: 4 of 5 START sql view model dp_lake.sales_staging .............................. [RUN]
[0m22:41:08.064734 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_data_pipeline.products_staging, now model.dbt_data_pipeline.sales_staging)
[0m22:41:08.064734 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.sales_staging
[0m22:41:08.080356 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.sales_staging"
[0m22:41:08.086880 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.sales_staging
[0m22:41:08.086880 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.sales_staging"
[0m22:41:08.086880 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:41:08.102522 [debug] [Thread-1 (]: On model.dbt_data_pipeline.sales_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.sales_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_lake`.`sales_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


-- Sélectionner uniquement les enregistrements ingérés au cours de la dernière heure
SELECT *
FROM `dataengineerproject-439609`.`dp_lake`.`sales_normalized`
WHERE _dp_ingestion_timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR);


[0m22:41:08.302886 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:def02cfb-a46b-4de3-b392-7e9c427c5f06&page=queryresults
[0m22:41:08.302886 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:def02cfb-a46b-4de3-b392-7e9c427c5f06&page=queryresults
[0m22:41:08.318538 [debug] [Thread-1 (]: Database Error in model sales_staging (dbt_data_pipeline/models\datahub\sales_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\sales_staging.sql
[0m22:41:08.318538 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1ab941a6-a37a-42ee-ae2d-138796c8a31d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018C76472930>]}
[0m22:41:08.318538 [error] [Thread-1 (]: 4 of 5 ERROR creating sql view model dp_lake.sales_staging ..................... [[31mERROR[0m in 0.25s]
[0m22:41:08.318538 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.sales_staging
[0m22:41:08.318538 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.my_second_dbt_model
[0m22:41:08.318538 [info ] [Thread-1 (]: 5 of 5 SKIP relation dp_lake.my_second_dbt_model ............................... [[33mSKIP[0m]
[0m22:41:08.334136 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.my_second_dbt_model
[0m22:41:08.334136 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:41:08.334136 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m22:41:08.349766 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_lake' was properly closed.
[0m22:41:08.349766 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.sales_staging' was properly closed.
[0m22:41:08.349766 [info ] [MainThread]: 
[0m22:41:08.349766 [info ] [MainThread]: Finished running 4 view models, 1 table model in 0 hours 0 minutes and 4.74 seconds (4.74s).
[0m22:41:08.349766 [debug] [MainThread]: Command end result
[0m22:41:08.584511 [info ] [MainThread]: 
[0m22:41:08.587524 [info ] [MainThread]: [31mCompleted with 4 errors and 0 warnings:[0m
[0m22:41:08.587524 [info ] [MainThread]: 
[0m22:41:08.587524 [error] [MainThread]:   Database Error in model customers_staging (dbt_data_pipeline/models\datahub\customers_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\customers_staging.sql
[0m22:41:08.587524 [info ] [MainThread]: 
[0m22:41:08.603167 [error] [MainThread]:   Database Error in model my_first_dbt_model (dbt_data_pipeline/models\example\my_first_dbt_model.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\example\my_first_dbt_model.sql
[0m22:41:08.603167 [info ] [MainThread]: 
[0m22:41:08.603167 [error] [MainThread]:   Database Error in model products_staging (dbt_data_pipeline/models\datahub\products_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\products_staging.sql
[0m22:41:08.622712 [info ] [MainThread]: 
[0m22:41:08.638345 [error] [MainThread]:   Database Error in model sales_staging (dbt_data_pipeline/models\datahub\sales_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\sales_staging.sql
[0m22:41:08.638345 [info ] [MainThread]: 
[0m22:41:08.638345 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=4 SKIP=1 TOTAL=5
[0m22:41:08.638345 [debug] [MainThread]: Command `dbt run` failed at 22:41:08.638345 after 10.73 seconds
[0m22:41:08.638345 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018C6A07A960>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018C6AC7FB00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018C6AD400E0>]}
[0m22:41:08.638345 [debug] [MainThread]: Flushing usage events
[0m22:44:02.579256 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002266599B530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022664AC9AF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000226680477A0>]}


============================== 22:44:02.589299 | b9aa099c-59e9-4285-8f9a-4476cd26cca8 ==============================
[0m22:44:02.589299 [info ] [MainThread]: Running with dbt=1.8.7
[0m22:44:02.592258 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:/Users/lenovo/.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --profiles-dir C:/Users/lenovo/.dbt', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m22:44:07.082520 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b9aa099c-59e9-4285-8f9a-4476cd26cca8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022671686300>]}
[0m22:44:07.406519 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b9aa099c-59e9-4285-8f9a-4476cd26cca8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000226703D86E0>]}
[0m22:44:07.408520 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m22:44:07.442518 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m22:44:08.999005 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:44:09.001008 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:44:09.008007 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_project.example
[0m22:44:09.097396 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b9aa099c-59e9-4285-8f9a-4476cd26cca8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002267041AD80>]}
[0m22:44:09.620738 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b9aa099c-59e9-4285-8f9a-4476cd26cca8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002267324D130>]}
[0m22:44:09.623831 [info ] [MainThread]: Found 5 models, 4 data tests, 3 sources, 484 macros
[0m22:44:09.624827 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b9aa099c-59e9-4285-8f9a-4476cd26cca8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002267302C200>]}
[0m22:44:09.628923 [info ] [MainThread]: 
[0m22:44:09.632017 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m22:44:09.644743 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m22:44:09.649854 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:44:13.272315 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_lake'
[0m22:44:13.273318 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:44:13.387013 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b9aa099c-59e9-4285-8f9a-4476cd26cca8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022665F5DB80>]}
[0m22:44:13.388013 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:44:13.389017 [info ] [MainThread]: 
[0m22:44:13.397184 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.customers_staging
[0m22:44:13.399188 [info ] [Thread-1 (]: 1 of 5 START sql view model dp_lake.customers_staging .......................... [RUN]
[0m22:44:13.400189 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.customers_staging'
[0m22:44:13.401283 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.customers_staging
[0m22:44:13.416595 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.customers_staging"
[0m22:44:13.420469 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.customers_staging
[0m22:44:13.471893 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.customers_staging"
[0m22:44:13.474968 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m22:44:13.475969 [debug] [Thread-1 (]: On model.dbt_data_pipeline.customers_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.customers_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_lake`.`customers_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


-- Sélectionner uniquement les enregistrements ingérés au cours de la dernière heure
SELECT *
FROM `dataengineerproject-439609`.`dp_lake`.`customers_normalized`
WHERE _dp_ingestion_timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR);


[0m22:44:13.654235 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:e43c895c-e0d8-4642-8333-b4b4f7d626e5&page=queryresults
[0m22:44:13.656234 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:e43c895c-e0d8-4642-8333-b4b4f7d626e5&page=queryresults
[0m22:44:13.691412 [debug] [Thread-1 (]: Database Error in model customers_staging (dbt_data_pipeline/models\datahub\customers_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\customers_staging.sql
[0m22:44:13.698411 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b9aa099c-59e9-4285-8f9a-4476cd26cca8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022673293CE0>]}
[0m22:44:13.700491 [error] [Thread-1 (]: 1 of 5 ERROR creating sql view model dp_lake.customers_staging ................. [[31mERROR[0m in 0.29s]
[0m22:44:13.706706 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.customers_staging
[0m22:44:13.709707 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.my_first_dbt_model
[0m22:44:13.715930 [info ] [Thread-1 (]: 2 of 5 START sql table model dp_lake.my_first_dbt_model ........................ [RUN]
[0m22:44:13.719932 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_data_pipeline.customers_staging, now model.dbt_data_pipeline.my_first_dbt_model)
[0m22:44:13.723112 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.my_first_dbt_model
[0m22:44:13.739399 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.my_first_dbt_model"
[0m22:44:13.747765 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.my_first_dbt_model
[0m22:44:13.800951 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.my_first_dbt_model"
[0m22:44:13.803953 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:44:13.805021 [debug] [Thread-1 (]: On model.dbt_data_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.my_first_dbt_model"} */

  
    

    create or replace table `dataengineerproject-439609`.`dp_lake`.`my_first_dbt_model`
      
    
    

    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m22:44:13.969327 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:6a7be4b1-d01c-4fe4-ad44-d606ab32b974&page=queryresults
[0m22:44:13.970329 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:6a7be4b1-d01c-4fe4-ad44-d606ab32b974&page=queryresults
[0m22:44:13.978329 [debug] [Thread-1 (]: Database Error in model my_first_dbt_model (dbt_data_pipeline/models\example\my_first_dbt_model.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\example\my_first_dbt_model.sql
[0m22:44:13.979393 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b9aa099c-59e9-4285-8f9a-4476cd26cca8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002267376F0E0>]}
[0m22:44:13.980398 [error] [Thread-1 (]: 2 of 5 ERROR creating sql table model dp_lake.my_first_dbt_model ............... [[31mERROR[0m in 0.26s]
[0m22:44:13.983427 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.my_first_dbt_model
[0m22:44:13.985498 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.products_staging
[0m22:44:13.986500 [info ] [Thread-1 (]: 3 of 5 START sql view model dp_lake.products_staging ........................... [RUN]
[0m22:44:13.988501 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_data_pipeline.my_first_dbt_model, now model.dbt_data_pipeline.products_staging)
[0m22:44:13.988501 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.products_staging
[0m22:44:13.992611 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.products_staging"
[0m22:44:13.997880 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.products_staging
[0m22:44:14.002986 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.products_staging"
[0m22:44:14.006064 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:44:14.007102 [debug] [Thread-1 (]: On model.dbt_data_pipeline.products_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.products_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_lake`.`products_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


-- Sélectionner uniquement les enregistrements ingérés au cours de la dernière heure
SELECT *
FROM `dataengineerproject-439609`.`dp_lake`.`products_normalized`
WHERE _dp_ingestion_timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR);


[0m22:44:14.157492 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:7e42ddbc-1114-4ade-8427-f6d196b2517a&page=queryresults
[0m22:44:14.158491 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:7e42ddbc-1114-4ade-8427-f6d196b2517a&page=queryresults
[0m22:44:14.165596 [debug] [Thread-1 (]: Database Error in model products_staging (dbt_data_pipeline/models\datahub\products_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\products_staging.sql
[0m22:44:14.166713 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b9aa099c-59e9-4285-8f9a-4476cd26cca8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000226737AC920>]}
[0m22:44:14.167717 [error] [Thread-1 (]: 3 of 5 ERROR creating sql view model dp_lake.products_staging .................. [[31mERROR[0m in 0.18s]
[0m22:44:14.169718 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.products_staging
[0m22:44:14.171718 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.sales_staging
[0m22:44:14.174719 [info ] [Thread-1 (]: 4 of 5 START sql view model dp_lake.sales_staging .............................. [RUN]
[0m22:44:14.178316 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_data_pipeline.products_staging, now model.dbt_data_pipeline.sales_staging)
[0m22:44:14.180289 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.sales_staging
[0m22:44:14.185375 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.sales_staging"
[0m22:44:14.190374 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.sales_staging
[0m22:44:14.198514 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.sales_staging"
[0m22:44:14.202576 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:44:14.203616 [debug] [Thread-1 (]: On model.dbt_data_pipeline.sales_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.sales_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_lake`.`sales_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


-- Sélectionner uniquement les enregistrements ingérés au cours de la dernière heure
SELECT *
FROM `dataengineerproject-439609`.`dp_lake`.`sales_normalized`
WHERE _dp_ingestion_timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR);


[0m22:44:14.373593 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:b34f8f29-c7cc-435f-9b26-be89e1c379bc&page=queryresults
[0m22:44:14.374595 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:b34f8f29-c7cc-435f-9b26-be89e1c379bc&page=queryresults
[0m22:44:14.383766 [debug] [Thread-1 (]: Database Error in model sales_staging (dbt_data_pipeline/models\datahub\sales_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\sales_staging.sql
[0m22:44:14.384783 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b9aa099c-59e9-4285-8f9a-4476cd26cca8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000226737E6F60>]}
[0m22:44:14.385771 [error] [Thread-1 (]: 4 of 5 ERROR creating sql view model dp_lake.sales_staging ..................... [[31mERROR[0m in 0.21s]
[0m22:44:14.388769 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.sales_staging
[0m22:44:14.389769 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.my_second_dbt_model
[0m22:44:14.391807 [info ] [Thread-1 (]: 5 of 5 SKIP relation dp_lake.my_second_dbt_model ............................... [[33mSKIP[0m]
[0m22:44:14.392812 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.my_second_dbt_model
[0m22:44:14.396897 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:44:14.397916 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m22:44:14.398891 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_lake' was properly closed.
[0m22:44:14.398959 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.sales_staging' was properly closed.
[0m22:44:14.400977 [info ] [MainThread]: 
[0m22:44:14.402963 [info ] [MainThread]: Finished running 4 view models, 1 table model in 0 hours 0 minutes and 4.77 seconds (4.77s).
[0m22:44:14.406057 [debug] [MainThread]: Command end result
[0m22:44:14.466382 [info ] [MainThread]: 
[0m22:44:14.468472 [info ] [MainThread]: [31mCompleted with 4 errors and 0 warnings:[0m
[0m22:44:14.470471 [info ] [MainThread]: 
[0m22:44:14.472550 [error] [MainThread]:   Database Error in model customers_staging (dbt_data_pipeline/models\datahub\customers_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\customers_staging.sql
[0m22:44:14.473550 [info ] [MainThread]: 
[0m22:44:14.474555 [error] [MainThread]:   Database Error in model my_first_dbt_model (dbt_data_pipeline/models\example\my_first_dbt_model.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\example\my_first_dbt_model.sql
[0m22:44:14.477662 [info ] [MainThread]: 
[0m22:44:14.479663 [error] [MainThread]:   Database Error in model products_staging (dbt_data_pipeline/models\datahub\products_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\products_staging.sql
[0m22:44:14.481663 [info ] [MainThread]: 
[0m22:44:14.483757 [error] [MainThread]:   Database Error in model sales_staging (dbt_data_pipeline/models\datahub\sales_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\sales_staging.sql
[0m22:44:14.486783 [info ] [MainThread]: 
[0m22:44:14.487847 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=4 SKIP=1 TOTAL=5
[0m22:44:14.490887 [debug] [MainThread]: Command `dbt run` failed at 22:44:14.490887 after 12.33 seconds
[0m22:44:14.491849 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022667C40140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000226681BACF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002266771BFB0>]}
[0m22:44:14.492925 [debug] [MainThread]: Flushing usage events
[0m22:57:35.611867 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000256AFA877A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000256B339ACF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000256B2B5F6B0>]}


============================== 22:57:35.627499 | 58c32cf2-c2cc-48d9-9603-0bbeef29ec5c ==============================
[0m22:57:35.627499 [info ] [MainThread]: Running with dbt=1.8.7
[0m22:57:35.627499 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:/Users/lenovo/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run --profiles-dir C:/Users/lenovo/.dbt', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m22:57:39.018970 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '58c32cf2-c2cc-48d9-9603-0bbeef29ec5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000256BBFF7EC0>]}
[0m22:57:39.088097 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '58c32cf2-c2cc-48d9-9603-0bbeef29ec5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000256BC6D62A0>]}
[0m22:57:39.088097 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m22:57:39.103666 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m22:57:39.589088 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:57:39.589088 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:57:39.589088 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_project.example
[0m22:57:39.642505 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '58c32cf2-c2cc-48d9-9603-0bbeef29ec5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000256BE1FBFE0>]}
[0m22:57:39.941230 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '58c32cf2-c2cc-48d9-9603-0bbeef29ec5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000256BE28A660>]}
[0m22:57:39.949275 [info ] [MainThread]: Found 5 models, 4 data tests, 3 sources, 484 macros
[0m22:57:39.951313 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '58c32cf2-c2cc-48d9-9603-0bbeef29ec5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000256BE1FADB0>]}
[0m22:57:39.951313 [info ] [MainThread]: 
[0m22:57:39.951313 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m22:57:39.969633 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m22:57:39.971660 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:57:42.468141 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_lake'
[0m22:57:42.468141 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:57:42.590662 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '58c32cf2-c2cc-48d9-9603-0bbeef29ec5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000256BE18CF80>]}
[0m22:57:42.590662 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:57:42.590662 [info ] [MainThread]: 
[0m22:57:42.606300 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.customers_staging
[0m22:57:42.606300 [info ] [Thread-1 (]: 1 of 5 START sql view model dp_lake.customers_staging .......................... [RUN]
[0m22:57:42.606300 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.customers_staging'
[0m22:57:42.606300 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.customers_staging
[0m22:57:42.621931 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.customers_staging"
[0m22:57:42.621931 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.customers_staging
[0m22:57:42.668837 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.customers_staging"
[0m22:57:42.668837 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m22:57:42.668837 [debug] [Thread-1 (]: On model.dbt_data_pipeline.customers_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.customers_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_lake`.`customers_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


-- Sélectionner uniquement les enregistrements ingérés au cours de la dernière heure
SELECT *
FROM `dataengineerproject-439609`.`dp_lake`.`customers_normalized`
WHERE _dp_ingestion_timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR);


[0m22:57:42.891457 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:843b6059-76c9-4025-807a-79bc7f5ec9d2&page=queryresults
[0m22:57:42.891457 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:843b6059-76c9-4025-807a-79bc7f5ec9d2&page=queryresults
[0m22:57:42.922724 [debug] [Thread-1 (]: Database Error in model customers_staging (dbt_data_pipeline/models\datahub\customers_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\customers_staging.sql
[0m22:57:42.922724 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '58c32cf2-c2cc-48d9-9603-0bbeef29ec5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000256B2D59DF0>]}
[0m22:57:42.922724 [error] [Thread-1 (]: 1 of 5 ERROR creating sql view model dp_lake.customers_staging ................. [[31mERROR[0m in 0.32s]
[0m22:57:42.922724 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.customers_staging
[0m22:57:42.922724 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.my_first_dbt_model
[0m22:57:42.922724 [info ] [Thread-1 (]: 2 of 5 START sql table model dp_lake.my_first_dbt_model ........................ [RUN]
[0m22:57:42.922724 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_data_pipeline.customers_staging, now model.dbt_data_pipeline.my_first_dbt_model)
[0m22:57:42.922724 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.my_first_dbt_model
[0m22:57:42.938354 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.my_first_dbt_model"
[0m22:57:42.938354 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.my_first_dbt_model
[0m22:57:42.991774 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.my_first_dbt_model"
[0m22:57:42.991774 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:57:42.991774 [debug] [Thread-1 (]: On model.dbt_data_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.my_first_dbt_model"} */

  
    

    create or replace table `dataengineerproject-439609`.`dp_lake`.`my_first_dbt_model`
      
    
    

    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m22:57:43.154586 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:4a73bee1-1bdf-4d1f-b3b5-9b90e708d841&page=queryresults
[0m22:57:43.154586 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:4a73bee1-1bdf-4d1f-b3b5-9b90e708d841&page=queryresults
[0m22:57:43.154586 [debug] [Thread-1 (]: Database Error in model my_first_dbt_model (dbt_data_pipeline/models\example\my_first_dbt_model.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\example\my_first_dbt_model.sql
[0m22:57:43.154586 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '58c32cf2-c2cc-48d9-9603-0bbeef29ec5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000256BE981430>]}
[0m22:57:43.154586 [error] [Thread-1 (]: 2 of 5 ERROR creating sql table model dp_lake.my_first_dbt_model ............... [[31mERROR[0m in 0.23s]
[0m22:57:43.170216 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.my_first_dbt_model
[0m22:57:43.170216 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.products_staging
[0m22:57:43.170216 [info ] [Thread-1 (]: 3 of 5 START sql view model dp_lake.products_staging ........................... [RUN]
[0m22:57:43.170216 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_data_pipeline.my_first_dbt_model, now model.dbt_data_pipeline.products_staging)
[0m22:57:43.170216 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.products_staging
[0m22:57:43.186632 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.products_staging"
[0m22:57:43.192142 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.products_staging
[0m22:57:43.192142 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.products_staging"
[0m22:57:43.192142 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:57:43.192142 [debug] [Thread-1 (]: On model.dbt_data_pipeline.products_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.products_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_lake`.`products_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


-- Sélectionner uniquement les enregistrements ingérés au cours de la dernière heure
SELECT *
FROM `dataengineerproject-439609`.`dp_lake`.`products_normalized`
WHERE _dp_ingestion_timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR);


[0m22:57:43.339345 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:114f3909-66e4-413f-bc09-8d685be0d7e6&page=queryresults
[0m22:57:43.339345 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:114f3909-66e4-413f-bc09-8d685be0d7e6&page=queryresults
[0m22:57:43.354973 [debug] [Thread-1 (]: Database Error in model products_staging (dbt_data_pipeline/models\datahub\products_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\products_staging.sql
[0m22:57:43.354973 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '58c32cf2-c2cc-48d9-9603-0bbeef29ec5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000256BE9D3C80>]}
[0m22:57:43.354973 [error] [Thread-1 (]: 3 of 5 ERROR creating sql view model dp_lake.products_staging .................. [[31mERROR[0m in 0.18s]
[0m22:57:43.354973 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.products_staging
[0m22:57:43.354973 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.sales_staging
[0m22:57:43.354973 [info ] [Thread-1 (]: 4 of 5 START sql view model dp_lake.sales_staging .............................. [RUN]
[0m22:57:43.354973 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_data_pipeline.products_staging, now model.dbt_data_pipeline.sales_staging)
[0m22:57:43.354973 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.sales_staging
[0m22:57:43.370602 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.sales_staging"
[0m22:57:43.370602 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.sales_staging
[0m22:57:43.370602 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.sales_staging"
[0m22:57:43.386239 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:57:43.386239 [debug] [Thread-1 (]: On model.dbt_data_pipeline.sales_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.sales_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_lake`.`sales_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


-- Sélectionner uniquement les enregistrements ingérés au cours de la dernière heure
SELECT *
FROM `dataengineerproject-439609`.`dp_lake`.`sales_normalized`
WHERE _dp_ingestion_timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR);


[0m22:57:43.539578 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:bd8ea8d6-ba76-4783-af36-32906caa5a5f&page=queryresults
[0m22:57:43.539578 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:bd8ea8d6-ba76-4783-af36-32906caa5a5f&page=queryresults
[0m22:57:43.539578 [debug] [Thread-1 (]: Database Error in model sales_staging (dbt_data_pipeline/models\datahub\sales_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\sales_staging.sql
[0m22:57:43.539578 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '58c32cf2-c2cc-48d9-9603-0bbeef29ec5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000256BE9FAE40>]}
[0m22:57:43.539578 [error] [Thread-1 (]: 4 of 5 ERROR creating sql view model dp_lake.sales_staging ..................... [[31mERROR[0m in 0.18s]
[0m22:57:43.539578 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.sales_staging
[0m22:57:43.539578 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.my_second_dbt_model
[0m22:57:43.539578 [info ] [Thread-1 (]: 5 of 5 SKIP relation dp_lake.my_second_dbt_model ............................... [[33mSKIP[0m]
[0m22:57:43.539578 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.my_second_dbt_model
[0m22:57:43.555183 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:57:43.555183 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m22:57:43.555183 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_lake' was properly closed.
[0m22:57:43.555183 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.sales_staging' was properly closed.
[0m22:57:43.555183 [info ] [MainThread]: 
[0m22:57:43.555183 [info ] [MainThread]: Finished running 4 view models, 1 table model in 0 hours 0 minutes and 3.60 seconds (3.60s).
[0m22:57:43.555183 [debug] [MainThread]: Command end result
[0m22:57:43.608598 [info ] [MainThread]: 
[0m22:57:43.608598 [info ] [MainThread]: [31mCompleted with 4 errors and 0 warnings:[0m
[0m22:57:43.608598 [info ] [MainThread]: 
[0m22:57:43.608598 [error] [MainThread]:   Database Error in model customers_staging (dbt_data_pipeline/models\datahub\customers_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\customers_staging.sql
[0m22:57:43.608598 [info ] [MainThread]: 
[0m22:57:43.608598 [error] [MainThread]:   Database Error in model my_first_dbt_model (dbt_data_pipeline/models\example\my_first_dbt_model.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\example\my_first_dbt_model.sql
[0m22:57:43.608598 [info ] [MainThread]: 
[0m22:57:43.608598 [error] [MainThread]:   Database Error in model products_staging (dbt_data_pipeline/models\datahub\products_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\products_staging.sql
[0m22:57:43.624246 [info ] [MainThread]: 
[0m22:57:43.624246 [error] [MainThread]:   Database Error in model sales_staging (dbt_data_pipeline/models\datahub\sales_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\sales_staging.sql
[0m22:57:43.624246 [info ] [MainThread]: 
[0m22:57:43.624246 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=4 SKIP=1 TOTAL=5
[0m22:57:43.624246 [debug] [MainThread]: Command `dbt run` failed at 22:57:43.624246 after 8.43 seconds
[0m22:57:43.624246 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000256B28CBA70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000256B33CD4C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000256B34CF470>]}
[0m22:57:43.624246 [debug] [MainThread]: Flushing usage events
[0m22:59:23.625265 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CBDD1950A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CBDC43F920>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CBDD194F20>]}


============================== 22:59:23.635275 | efe0e81f-37e3-488a-aaf2-8b473e830263 ==============================
[0m22:59:23.635275 [info ] [MainThread]: Running with dbt=1.8.7
[0m22:59:23.635275 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': 'C:/Users/lenovo/.dbt', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run --profiles-dir C:/Users/lenovo/.dbt', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m22:59:32.261467 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'efe0e81f-37e3-488a-aaf2-8b473e830263', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CBDD1D5610>]}
[0m22:59:32.484916 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'efe0e81f-37e3-488a-aaf2-8b473e830263', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CBE7C97E60>]}
[0m22:59:32.486961 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m22:59:32.547869 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m22:59:33.862039 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:59:33.864039 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:59:33.890436 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_project.example
[0m22:59:34.129834 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'efe0e81f-37e3-488a-aaf2-8b473e830263', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CBE7D581A0>]}
[0m22:59:34.804009 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'efe0e81f-37e3-488a-aaf2-8b473e830263', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CBE7FACF80>]}
[0m22:59:34.809007 [info ] [MainThread]: Found 5 models, 4 data tests, 3 sources, 484 macros
[0m22:59:34.812008 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'efe0e81f-37e3-488a-aaf2-8b473e830263', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CBE7F5EE70>]}
[0m22:59:34.827255 [info ] [MainThread]: 
[0m22:59:34.943108 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m22:59:34.974182 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m22:59:34.977176 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:59:41.508562 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_lake'
[0m22:59:41.509564 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:59:41.635634 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'efe0e81f-37e3-488a-aaf2-8b473e830263', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CBE7C96ED0>]}
[0m22:59:41.636633 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:59:41.637632 [info ] [MainThread]: 
[0m22:59:41.649272 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.customers_staging
[0m22:59:41.650272 [info ] [Thread-1 (]: 1 of 5 START sql view model dp_lake.customers_staging .......................... [RUN]
[0m22:59:41.652286 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.customers_staging'
[0m22:59:41.653272 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.customers_staging
[0m22:59:41.667031 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.customers_staging"
[0m22:59:41.672167 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.customers_staging
[0m22:59:41.727213 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.customers_staging"
[0m22:59:41.732216 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m22:59:41.733260 [debug] [Thread-1 (]: On model.dbt_data_pipeline.customers_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.customers_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_lake`.`customers_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


-- Sélectionner uniquement les enregistrements ingérés au cours de la dernière heure
SELECT *
FROM `dataengineerproject-439609`.`dp_lake`.`customers_normalized`
WHERE _dp_ingestion_timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR);


[0m22:59:42.007686 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:923d03c0-6a27-40a1-b446-e19c5b5b4281&page=queryresults
[0m22:59:42.009673 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:923d03c0-6a27-40a1-b446-e19c5b5b4281&page=queryresults
[0m22:59:42.040343 [debug] [Thread-1 (]: Database Error in model customers_staging (dbt_data_pipeline/models\datahub\customers_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\customers_staging.sql
[0m22:59:42.042346 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'efe0e81f-37e3-488a-aaf2-8b473e830263', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CBE8028050>]}
[0m22:59:42.043343 [error] [Thread-1 (]: 1 of 5 ERROR creating sql view model dp_lake.customers_staging ................. [[31mERROR[0m in 0.39s]
[0m22:59:42.045316 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.customers_staging
[0m22:59:42.046451 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.my_first_dbt_model
[0m22:59:42.048456 [info ] [Thread-1 (]: 2 of 5 START sql table model dp_lake.my_first_dbt_model ........................ [RUN]
[0m22:59:42.050453 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_data_pipeline.customers_staging, now model.dbt_data_pipeline.my_first_dbt_model)
[0m22:59:42.051452 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.my_first_dbt_model
[0m22:59:42.057452 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.my_first_dbt_model"
[0m22:59:42.060452 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.my_first_dbt_model
[0m22:59:42.104502 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.my_first_dbt_model"
[0m22:59:42.110508 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:59:42.111550 [debug] [Thread-1 (]: On model.dbt_data_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.my_first_dbt_model"} */

  
    

    create or replace table `dataengineerproject-439609`.`dp_lake`.`my_first_dbt_model`
      
    
    

    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m22:59:42.303327 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:51d0e232-de0a-440e-9c9e-7ce150a4828f&page=queryresults
[0m22:59:42.304326 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:51d0e232-de0a-440e-9c9e-7ce150a4828f&page=queryresults
[0m22:59:42.309349 [debug] [Thread-1 (]: Database Error in model my_first_dbt_model (dbt_data_pipeline/models\example\my_first_dbt_model.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\example\my_first_dbt_model.sql
[0m22:59:42.310321 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'efe0e81f-37e3-488a-aaf2-8b473e830263', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CBE849EDE0>]}
[0m22:59:42.311350 [error] [Thread-1 (]: 2 of 5 ERROR creating sql table model dp_lake.my_first_dbt_model ............... [[31mERROR[0m in 0.26s]
[0m22:59:42.313066 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.my_first_dbt_model
[0m22:59:42.315389 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.products_staging
[0m22:59:42.316393 [info ] [Thread-1 (]: 3 of 5 START sql view model dp_lake.products_staging ........................... [RUN]
[0m22:59:42.318393 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_data_pipeline.my_first_dbt_model, now model.dbt_data_pipeline.products_staging)
[0m22:59:42.320398 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.products_staging
[0m22:59:42.324426 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.products_staging"
[0m22:59:42.327055 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.products_staging
[0m22:59:42.330804 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.products_staging"
[0m22:59:42.332810 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:59:42.333812 [debug] [Thread-1 (]: On model.dbt_data_pipeline.products_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.products_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_lake`.`products_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


-- Sélectionner uniquement les enregistrements ingérés au cours de la dernière heure
SELECT *
FROM `dataengineerproject-439609`.`dp_lake`.`products_normalized`
WHERE _dp_ingestion_timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR);


[0m22:59:42.532594 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:beae4ccd-97d6-43d3-a5c9-aaa2bb88d01e&page=queryresults
[0m22:59:42.533597 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:beae4ccd-97d6-43d3-a5c9-aaa2bb88d01e&page=queryresults
[0m22:59:42.538589 [debug] [Thread-1 (]: Database Error in model products_staging (dbt_data_pipeline/models\datahub\products_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\products_staging.sql
[0m22:59:42.539589 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'efe0e81f-37e3-488a-aaf2-8b473e830263', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CBE84EBE00>]}
[0m22:59:42.540590 [error] [Thread-1 (]: 3 of 5 ERROR creating sql view model dp_lake.products_staging .................. [[31mERROR[0m in 0.22s]
[0m22:59:42.541593 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.products_staging
[0m22:59:42.542625 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.sales_staging
[0m22:59:42.543617 [info ] [Thread-1 (]: 4 of 5 START sql view model dp_lake.sales_staging .............................. [RUN]
[0m22:59:42.544589 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_data_pipeline.products_staging, now model.dbt_data_pipeline.sales_staging)
[0m22:59:42.546251 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.sales_staging
[0m22:59:42.551861 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.sales_staging"
[0m22:59:42.554331 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.sales_staging
[0m22:59:42.557341 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.sales_staging"
[0m22:59:42.560341 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:59:42.561340 [debug] [Thread-1 (]: On model.dbt_data_pipeline.sales_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.sales_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_lake`.`sales_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


-- Sélectionner uniquement les enregistrements ingérés au cours de la dernière heure
SELECT *
FROM `dataengineerproject-439609`.`dp_lake`.`sales_normalized`
WHERE _dp_ingestion_timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR);


[0m22:59:42.726142 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:b8ef235e-daa9-40ac-9df2-231b6bf76b35&page=queryresults
[0m22:59:42.727132 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:b8ef235e-daa9-40ac-9df2-231b6bf76b35&page=queryresults
[0m22:59:42.734349 [debug] [Thread-1 (]: Database Error in model sales_staging (dbt_data_pipeline/models\datahub\sales_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\sales_staging.sql
[0m22:59:42.735349 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'efe0e81f-37e3-488a-aaf2-8b473e830263', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CBE8513230>]}
[0m22:59:42.736349 [error] [Thread-1 (]: 4 of 5 ERROR creating sql view model dp_lake.sales_staging ..................... [[31mERROR[0m in 0.19s]
[0m22:59:42.737349 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.sales_staging
[0m22:59:42.738387 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.my_second_dbt_model
[0m22:59:42.739348 [info ] [Thread-1 (]: 5 of 5 SKIP relation dp_lake.my_second_dbt_model ............................... [[33mSKIP[0m]
[0m22:59:42.740367 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.my_second_dbt_model
[0m22:59:42.742348 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:59:42.743348 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m22:59:42.743348 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_lake' was properly closed.
[0m22:59:42.744380 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.sales_staging' was properly closed.
[0m22:59:42.745373 [info ] [MainThread]: 
[0m22:59:42.746994 [info ] [MainThread]: Finished running 4 view models, 1 table model in 0 hours 0 minutes and 7.80 seconds (7.80s).
[0m22:59:42.748998 [debug] [MainThread]: Command end result
[0m22:59:42.793807 [info ] [MainThread]: 
[0m22:59:42.794808 [info ] [MainThread]: [31mCompleted with 4 errors and 0 warnings:[0m
[0m22:59:42.798095 [info ] [MainThread]: 
[0m22:59:42.800093 [error] [MainThread]:   Database Error in model customers_staging (dbt_data_pipeline/models\datahub\customers_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\customers_staging.sql
[0m22:59:42.802090 [info ] [MainThread]: 
[0m22:59:42.804091 [error] [MainThread]:   Database Error in model my_first_dbt_model (dbt_data_pipeline/models\example\my_first_dbt_model.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\example\my_first_dbt_model.sql
[0m22:59:42.805089 [info ] [MainThread]: 
[0m22:59:42.806090 [error] [MainThread]:   Database Error in model products_staging (dbt_data_pipeline/models\datahub\products_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\products_staging.sql
[0m22:59:42.807090 [info ] [MainThread]: 
[0m22:59:42.808089 [error] [MainThread]:   Database Error in model sales_staging (dbt_data_pipeline/models\datahub\sales_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\sales_staging.sql
[0m22:59:42.809280 [info ] [MainThread]: 
[0m22:59:42.810392 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=4 SKIP=1 TOTAL=5
[0m22:59:42.815600 [debug] [MainThread]: Command `dbt run` failed at 22:59:42.815600 after 19.74 seconds
[0m22:59:42.816597 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CBDD068BF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CBDC43FCE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CBE5E67230>]}
[0m22:59:42.817597 [debug] [MainThread]: Flushing usage events
[0m23:04:19.219421 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027051A0BDA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027051A0BCE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000270523E5640>]}


============================== 23:04:19.235060 | 600a0bdb-8c82-4f78-8797-eea72e7913ca ==============================
[0m23:04:19.235060 [info ] [MainThread]: Running with dbt=1.8.7
[0m23:04:19.235060 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': 'C:/Users/lenovo/.dbt', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --profiles-dir C:/Users/lenovo/.dbt', 'send_anonymous_usage_stats': 'True'}
[0m23:04:22.029658 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '600a0bdb-8c82-4f78-8797-eea72e7913ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002705D04B560>]}
[0m23:04:22.092163 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '600a0bdb-8c82-4f78-8797-eea72e7913ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000270501ED940>]}
[0m23:04:22.092163 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m23:04:22.114334 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m23:04:22.493350 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:04:22.493350 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:04:22.515042 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_project.example
[0m23:04:22.561980 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '600a0bdb-8c82-4f78-8797-eea72e7913ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002705D27DE50>]}
[0m23:04:22.746992 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '600a0bdb-8c82-4f78-8797-eea72e7913ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002705D4AC500>]}
[0m23:04:22.746992 [info ] [MainThread]: Found 5 models, 4 data tests, 3 sources, 484 macros
[0m23:04:22.746992 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '600a0bdb-8c82-4f78-8797-eea72e7913ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002705B896600>]}
[0m23:04:22.746992 [info ] [MainThread]: 
[0m23:04:22.762611 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m23:04:22.762611 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m23:04:22.762611 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:04:25.293291 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_lake'
[0m23:04:25.308916 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:04:25.409340 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '600a0bdb-8c82-4f78-8797-eea72e7913ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027050251790>]}
[0m23:04:25.409340 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:04:25.409340 [info ] [MainThread]: 
[0m23:04:25.424717 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.customers_staging
[0m23:04:25.424717 [info ] [Thread-1 (]: 1 of 5 START sql view model dp_lake.customers_staging .......................... [RUN]
[0m23:04:25.424717 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.customers_staging'
[0m23:04:25.424717 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.customers_staging
[0m23:04:25.446855 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.customers_staging"
[0m23:04:25.446855 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.customers_staging
[0m23:04:25.493789 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.customers_staging"
[0m23:04:25.493789 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m23:04:25.493789 [debug] [Thread-1 (]: On model.dbt_data_pipeline.customers_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.customers_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_lake`.`customers_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


-- Sélectionner uniquement les enregistrements ingérés au cours de la dernière heure
SELECT *
FROM `dataengineerproject-439609`.`dp_lake`.`customers_normalized`
WHERE _dp_ingestion_timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR);


[0m23:04:25.694429 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:c3f3feb2-2107-4e7c-a3b2-bb061a7fb7ca&page=queryresults
[0m23:04:25.694429 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:c3f3feb2-2107-4e7c-a3b2-bb061a7fb7ca&page=queryresults
[0m23:04:25.725660 [debug] [Thread-1 (]: Database Error in model customers_staging (dbt_data_pipeline/models\datahub\customers_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\customers_staging.sql
[0m23:04:25.725660 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '600a0bdb-8c82-4f78-8797-eea72e7913ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002705D47E150>]}
[0m23:04:25.725660 [error] [Thread-1 (]: 1 of 5 ERROR creating sql view model dp_lake.customers_staging ................. [[31mERROR[0m in 0.30s]
[0m23:04:25.725660 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.customers_staging
[0m23:04:25.725660 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.my_first_dbt_model
[0m23:04:25.725660 [info ] [Thread-1 (]: 2 of 5 START sql table model dp_lake.my_first_dbt_model ........................ [RUN]
[0m23:04:25.725660 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_data_pipeline.customers_staging, now model.dbt_data_pipeline.my_first_dbt_model)
[0m23:04:25.725660 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.my_first_dbt_model
[0m23:04:25.741240 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.my_first_dbt_model"
[0m23:04:25.741240 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.my_first_dbt_model
[0m23:04:25.779027 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.my_first_dbt_model"
[0m23:04:25.779027 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:04:25.779027 [debug] [Thread-1 (]: On model.dbt_data_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.my_first_dbt_model"} */

  
    

    create or replace table `dataengineerproject-439609`.`dp_lake`.`my_first_dbt_model`
      
    
    

    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m23:04:25.948391 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:1ba31ab6-275c-4068-b0b0-44c15636ca4a&page=queryresults
[0m23:04:25.948391 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:1ba31ab6-275c-4068-b0b0-44c15636ca4a&page=queryresults
[0m23:04:25.948391 [debug] [Thread-1 (]: Database Error in model my_first_dbt_model (dbt_data_pipeline/models\example\my_first_dbt_model.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\example\my_first_dbt_model.sql
[0m23:04:25.964031 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '600a0bdb-8c82-4f78-8797-eea72e7913ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002705D9720C0>]}
[0m23:04:25.964031 [error] [Thread-1 (]: 2 of 5 ERROR creating sql table model dp_lake.my_first_dbt_model ............... [[31mERROR[0m in 0.24s]
[0m23:04:25.964031 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.my_first_dbt_model
[0m23:04:25.964031 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.products_staging
[0m23:04:25.964031 [info ] [Thread-1 (]: 3 of 5 START sql view model dp_lake.products_staging ........................... [RUN]
[0m23:04:25.964031 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_data_pipeline.my_first_dbt_model, now model.dbt_data_pipeline.products_staging)
[0m23:04:25.964031 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.products_staging
[0m23:04:25.964031 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.products_staging"
[0m23:04:25.964031 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.products_staging
[0m23:04:25.979655 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.products_staging"
[0m23:04:25.979655 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:04:25.979655 [debug] [Thread-1 (]: On model.dbt_data_pipeline.products_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.products_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_lake`.`products_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


-- Sélectionner uniquement les enregistrements ingérés au cours de la dernière heure
SELECT *
FROM `dataengineerproject-439609`.`dp_lake`.`products_normalized`
WHERE _dp_ingestion_timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR);


[0m23:04:26.127077 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:1bc0c289-70be-49f5-937e-ab404c6823d3&page=queryresults
[0m23:04:26.127077 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:1bc0c289-70be-49f5-937e-ab404c6823d3&page=queryresults
[0m23:04:26.142076 [debug] [Thread-1 (]: Database Error in model products_staging (dbt_data_pipeline/models\datahub\products_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\products_staging.sql
[0m23:04:26.142076 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '600a0bdb-8c82-4f78-8797-eea72e7913ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002705D9BB590>]}
[0m23:04:26.142076 [error] [Thread-1 (]: 3 of 5 ERROR creating sql view model dp_lake.products_staging .................. [[31mERROR[0m in 0.18s]
[0m23:04:26.148593 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.products_staging
[0m23:04:26.148593 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.sales_staging
[0m23:04:26.148593 [info ] [Thread-1 (]: 4 of 5 START sql view model dp_lake.sales_staging .............................. [RUN]
[0m23:04:26.148593 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_data_pipeline.products_staging, now model.dbt_data_pipeline.sales_staging)
[0m23:04:26.148593 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.sales_staging
[0m23:04:26.148593 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.sales_staging"
[0m23:04:26.148593 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.sales_staging
[0m23:04:26.148593 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.sales_staging"
[0m23:04:26.164274 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:04:26.164274 [debug] [Thread-1 (]: On model.dbt_data_pipeline.sales_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.sales_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_lake`.`sales_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


-- Sélectionner uniquement les enregistrements ingérés au cours de la dernière heure
SELECT *
FROM `dataengineerproject-439609`.`dp_lake`.`sales_normalized`
WHERE _dp_ingestion_timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR);


[0m23:04:26.327025 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:0413cd15-12fc-4566-b1f3-2b4ab90f0069&page=queryresults
[0m23:04:26.327025 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:0413cd15-12fc-4566-b1f3-2b4ab90f0069&page=queryresults
[0m23:04:26.351230 [debug] [Thread-1 (]: Database Error in model sales_staging (dbt_data_pipeline/models\datahub\sales_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\sales_staging.sql
[0m23:04:26.351230 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '600a0bdb-8c82-4f78-8797-eea72e7913ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002705D9DC920>]}
[0m23:04:26.351230 [error] [Thread-1 (]: 4 of 5 ERROR creating sql view model dp_lake.sales_staging ..................... [[31mERROR[0m in 0.20s]
[0m23:04:26.351230 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.sales_staging
[0m23:04:26.359290 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.my_second_dbt_model
[0m23:04:26.361338 [info ] [Thread-1 (]: 5 of 5 SKIP relation dp_lake.my_second_dbt_model ............................... [[33mSKIP[0m]
[0m23:04:26.361338 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.my_second_dbt_model
[0m23:04:26.369376 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:04:26.371412 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m23:04:26.371412 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_lake' was properly closed.
[0m23:04:26.371412 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.sales_staging' was properly closed.
[0m23:04:26.371412 [info ] [MainThread]: 
[0m23:04:26.371412 [info ] [MainThread]: Finished running 4 view models, 1 table model in 0 hours 0 minutes and 3.61 seconds (3.61s).
[0m23:04:26.381624 [debug] [MainThread]: Command end result
[0m23:04:26.452650 [info ] [MainThread]: 
[0m23:04:26.452650 [info ] [MainThread]: [31mCompleted with 4 errors and 0 warnings:[0m
[0m23:04:26.462848 [info ] [MainThread]: 
[0m23:04:26.462848 [error] [MainThread]:   Database Error in model customers_staging (dbt_data_pipeline/models\datahub\customers_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\customers_staging.sql
[0m23:04:26.462848 [info ] [MainThread]: 
[0m23:04:26.462848 [error] [MainThread]:   Database Error in model my_first_dbt_model (dbt_data_pipeline/models\example\my_first_dbt_model.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\example\my_first_dbt_model.sql
[0m23:04:26.470880 [info ] [MainThread]: 
[0m23:04:26.472909 [error] [MainThread]:   Database Error in model products_staging (dbt_data_pipeline/models\datahub\products_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\products_staging.sql
[0m23:04:26.472909 [info ] [MainThread]: 
[0m23:04:26.472909 [error] [MainThread]:   Database Error in model sales_staging (dbt_data_pipeline/models\datahub\sales_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\sales_staging.sql
[0m23:04:26.472909 [info ] [MainThread]: 
[0m23:04:26.472909 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=4 SKIP=1 TOTAL=5
[0m23:04:26.483118 [debug] [MainThread]: Command `dbt run` failed at 23:04:26.483118 after 7.59 seconds
[0m23:04:26.483118 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027051C37E00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027051F62870>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027052363AA0>]}
[0m23:04:26.483118 [debug] [MainThread]: Flushing usage events
[0m07:45:40.747416 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000169B9D88C80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000169B9187E90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000169B92EF800>]}


============================== 07:45:40.753923 | 0473b5dc-df72-4a5b-ab73-e95a9a1df66c ==============================
[0m07:45:40.753923 [info ] [MainThread]: Running with dbt=1.8.7
[0m07:45:40.753923 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'profiles_dir': 'C:/Users/lenovo/.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run --profiles-dir C:/Users/lenovo/.dbt', 'send_anonymous_usage_stats': 'True'}
[0m07:45:45.086543 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0473b5dc-df72-4a5b-ab73-e95a9a1df66c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000169B9EE50D0>]}
[0m07:45:45.151498 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0473b5dc-df72-4a5b-ab73-e95a9a1df66c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000169C26D3A40>]}
[0m07:45:45.167075 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m07:45:45.182697 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m07:45:45.966176 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:45:45.981820 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:45:45.987838 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_project.example
[0m07:45:46.034727 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0473b5dc-df72-4a5b-ab73-e95a9a1df66c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000169C4AAAF00>]}
[0m07:45:46.304443 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0473b5dc-df72-4a5b-ab73-e95a9a1df66c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000169C4CFD400>]}
[0m07:45:46.304443 [info ] [MainThread]: Found 5 models, 4 data tests, 3 sources, 484 macros
[0m07:45:46.304443 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0473b5dc-df72-4a5b-ab73-e95a9a1df66c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000169C49E7260>]}
[0m07:45:46.320031 [info ] [MainThread]: 
[0m07:45:46.320031 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m07:45:46.320031 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m07:45:46.320031 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:45:49.131534 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_lake'
[0m07:45:49.131534 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:45:49.238690 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0473b5dc-df72-4a5b-ab73-e95a9a1df66c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000169C4A77D10>]}
[0m07:45:49.238690 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m07:45:49.254328 [info ] [MainThread]: 
[0m07:45:49.254328 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.customers_staging
[0m07:45:49.254328 [info ] [Thread-1 (]: 1 of 5 START sql view model dp_lake.customers_staging .......................... [RUN]
[0m07:45:49.254328 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.customers_staging'
[0m07:45:49.254328 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.customers_staging
[0m07:45:49.269953 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.customers_staging"
[0m07:45:49.269953 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.customers_staging
[0m07:45:49.316820 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.customers_staging"
[0m07:45:49.316820 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m07:45:49.316820 [debug] [Thread-1 (]: On model.dbt_data_pipeline.customers_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.customers_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_lake`.`customers_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


-- Sélectionner uniquement les enregistrements ingérés au cours de la dernière heure
SELECT *
FROM `dataengineerproject-439609`.`dp_lake`.`customers_normalized`
WHERE _dp_ingestion_timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR);


[0m07:45:49.539048 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:24a49913-6751-4293-a4bc-03144b5c920d&page=queryresults
[0m07:45:49.539048 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:24a49913-6751-4293-a4bc-03144b5c920d&page=queryresults
[0m07:45:49.632799 [debug] [Thread-1 (]: Database Error in model customers_staging (dbt_data_pipeline/models\datahub\customers_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\customers_staging.sql
[0m07:45:49.639336 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0473b5dc-df72-4a5b-ab73-e95a9a1df66c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000169C2EFDFA0>]}
[0m07:45:49.639336 [error] [Thread-1 (]: 1 of 5 ERROR creating sql view model dp_lake.customers_staging ................. [[31mERROR[0m in 0.38s]
[0m07:45:49.639336 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.customers_staging
[0m07:45:49.639336 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.my_first_dbt_model
[0m07:45:49.639336 [info ] [Thread-1 (]: 2 of 5 START sql table model dp_lake.my_first_dbt_model ........................ [RUN]
[0m07:45:49.639336 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_data_pipeline.customers_staging, now model.dbt_data_pipeline.my_first_dbt_model)
[0m07:45:49.639336 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.my_first_dbt_model
[0m07:45:49.639336 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.my_first_dbt_model"
[0m07:45:49.639336 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.my_first_dbt_model
[0m07:45:49.686217 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.my_first_dbt_model"
[0m07:45:49.686217 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:45:49.686217 [debug] [Thread-1 (]: On model.dbt_data_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.my_first_dbt_model"} */

  
    

    create or replace table `dataengineerproject-439609`.`dp_lake`.`my_first_dbt_model`
      
    
    

    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m07:45:49.940651 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:6f3d326a-2365-475a-bb57-939d1aa45d8a&page=queryresults
[0m07:45:49.940651 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:6f3d326a-2365-475a-bb57-939d1aa45d8a&page=queryresults
[0m07:45:49.956290 [debug] [Thread-1 (]: Database Error in model my_first_dbt_model (dbt_data_pipeline/models\example\my_first_dbt_model.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\example\my_first_dbt_model.sql
[0m07:45:49.956290 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0473b5dc-df72-4a5b-ab73-e95a9a1df66c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000169C51EFCB0>]}
[0m07:45:49.956290 [error] [Thread-1 (]: 2 of 5 ERROR creating sql table model dp_lake.my_first_dbt_model ............... [[31mERROR[0m in 0.32s]
[0m07:45:49.956290 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.my_first_dbt_model
[0m07:45:49.956290 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.products_staging
[0m07:45:49.956290 [info ] [Thread-1 (]: 3 of 5 START sql view model dp_lake.products_staging ........................... [RUN]
[0m07:45:49.956290 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_data_pipeline.my_first_dbt_model, now model.dbt_data_pipeline.products_staging)
[0m07:45:49.956290 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.products_staging
[0m07:45:49.956290 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.products_staging"
[0m07:45:49.971910 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.products_staging
[0m07:45:49.971910 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.products_staging"
[0m07:45:49.971910 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:45:49.971910 [debug] [Thread-1 (]: On model.dbt_data_pipeline.products_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.products_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_lake`.`products_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


-- Sélectionner uniquement les enregistrements ingérés au cours de la dernière heure
SELECT *
FROM `dataengineerproject-439609`.`dp_lake`.`products_normalized`
WHERE _dp_ingestion_timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR);


[0m07:45:50.188348 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:4789a5c2-0283-4407-9c84-1fdeac7533f9&page=queryresults
[0m07:45:50.188348 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:4789a5c2-0283-4407-9c84-1fdeac7533f9&page=queryresults
[0m07:45:50.188348 [debug] [Thread-1 (]: Database Error in model products_staging (dbt_data_pipeline/models\datahub\products_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\products_staging.sql
[0m07:45:50.188348 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0473b5dc-df72-4a5b-ab73-e95a9a1df66c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000169C523BEF0>]}
[0m07:45:50.188348 [error] [Thread-1 (]: 3 of 5 ERROR creating sql view model dp_lake.products_staging .................. [[31mERROR[0m in 0.23s]
[0m07:45:50.188348 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.products_staging
[0m07:45:50.188348 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.sales_staging
[0m07:45:50.188348 [info ] [Thread-1 (]: 4 of 5 START sql view model dp_lake.sales_staging .............................. [RUN]
[0m07:45:50.188348 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_data_pipeline.products_staging, now model.dbt_data_pipeline.sales_staging)
[0m07:45:50.188348 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.sales_staging
[0m07:45:50.203963 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.sales_staging"
[0m07:45:50.203963 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.sales_staging
[0m07:45:50.203963 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.sales_staging"
[0m07:45:50.203963 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:45:50.203963 [debug] [Thread-1 (]: On model.dbt_data_pipeline.sales_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.sales_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_lake`.`sales_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


-- Sélectionner uniquement les enregistrements ingérés au cours de la dernière heure
SELECT *
FROM `dataengineerproject-439609`.`dp_lake`.`sales_normalized`
WHERE _dp_ingestion_timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR);


[0m07:45:50.458345 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:314c7e01-1f0d-45e5-81d3-a2f30de58792&page=queryresults
[0m07:45:50.458345 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:314c7e01-1f0d-45e5-81d3-a2f30de58792&page=queryresults
[0m07:45:50.458345 [debug] [Thread-1 (]: Database Error in model sales_staging (dbt_data_pipeline/models\datahub\sales_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\sales_staging.sql
[0m07:45:50.458345 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0473b5dc-df72-4a5b-ab73-e95a9a1df66c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000169C5263440>]}
[0m07:45:50.458345 [error] [Thread-1 (]: 4 of 5 ERROR creating sql view model dp_lake.sales_staging ..................... [[31mERROR[0m in 0.27s]
[0m07:45:50.473320 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.sales_staging
[0m07:45:50.473320 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.my_second_dbt_model
[0m07:45:50.473320 [info ] [Thread-1 (]: 5 of 5 SKIP relation dp_lake.my_second_dbt_model ............................... [[33mSKIP[0m]
[0m07:45:50.473320 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.my_second_dbt_model
[0m07:45:50.473320 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:45:50.473320 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m07:45:50.473320 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_lake' was properly closed.
[0m07:45:50.473320 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.sales_staging' was properly closed.
[0m07:45:50.473320 [info ] [MainThread]: 
[0m07:45:50.473320 [info ] [MainThread]: Finished running 4 view models, 1 table model in 0 hours 0 minutes and 4.15 seconds (4.15s).
[0m07:45:50.473320 [debug] [MainThread]: Command end result
[0m07:45:50.520184 [info ] [MainThread]: 
[0m07:45:50.520184 [info ] [MainThread]: [31mCompleted with 4 errors and 0 warnings:[0m
[0m07:45:50.520184 [info ] [MainThread]: 
[0m07:45:50.520184 [error] [MainThread]:   Database Error in model customers_staging (dbt_data_pipeline/models\datahub\customers_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\customers_staging.sql
[0m07:45:50.520184 [info ] [MainThread]: 
[0m07:45:50.535823 [error] [MainThread]:   Database Error in model my_first_dbt_model (dbt_data_pipeline/models\example\my_first_dbt_model.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\example\my_first_dbt_model.sql
[0m07:45:50.535823 [info ] [MainThread]: 
[0m07:45:50.535823 [error] [MainThread]:   Database Error in model products_staging (dbt_data_pipeline/models\datahub\products_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\products_staging.sql
[0m07:45:50.535823 [info ] [MainThread]: 
[0m07:45:50.535823 [error] [MainThread]:   Database Error in model sales_staging (dbt_data_pipeline/models\datahub\sales_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\sales_staging.sql
[0m07:45:50.542335 [info ] [MainThread]: 
[0m07:45:50.542335 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=4 SKIP=1 TOTAL=5
[0m07:45:50.542335 [debug] [MainThread]: Command `dbt run` failed at 07:45:50.542335 after 10.24 seconds
[0m07:45:50.542335 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000169B96432C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000169B9AE0980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000169B9EE5160>]}
[0m07:45:50.542335 [debug] [MainThread]: Flushing usage events
[0m07:50:08.999123 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB38960D70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB38A20B00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB38D45640>]}


============================== 07:50:09.021258 | 1d1eb3e1-d151-4fa5-a0e2-b86fc4931966 ==============================
[0m07:50:09.021258 [info ] [MainThread]: Running with dbt=1.8.7
[0m07:50:09.021258 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run -s products_staging.sql', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m07:50:13.441232 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1d1eb3e1-d151-4fa5-a0e2-b86fc4931966', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB39275760>]}
[0m07:50:13.553645 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1d1eb3e1-d151-4fa5-a0e2-b86fc4931966', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB38408C80>]}
[0m07:50:13.553645 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m07:50:13.584890 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m07:50:14.280272 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:50:14.280272 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:50:14.295875 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.my_project.example
[0m07:50:14.364976 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1d1eb3e1-d151-4fa5-a0e2-b86fc4931966', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB386F4200>]}
[0m07:50:14.665817 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1d1eb3e1-d151-4fa5-a0e2-b86fc4931966', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB440AC9B0>]}
[0m07:50:14.665817 [info ] [MainThread]: Found 5 models, 4 data tests, 3 sources, 484 macros
[0m07:50:14.665817 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1d1eb3e1-d151-4fa5-a0e2-b86fc4931966', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB4407AA80>]}
[0m07:50:14.681436 [info ] [MainThread]: 
[0m07:50:14.681436 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m07:50:14.681436 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m07:50:14.681436 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:50:18.122388 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_lake'
[0m07:50:18.122388 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:50:18.306313 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1d1eb3e1-d151-4fa5-a0e2-b86fc4931966', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB43DEABA0>]}
[0m07:50:18.306313 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m07:50:18.306313 [info ] [MainThread]: 
[0m07:50:18.321955 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.products_staging
[0m07:50:18.321955 [info ] [Thread-1 (]: 1 of 1 START sql view model dp_lake.products_staging ........................... [RUN]
[0m07:50:18.321955 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.products_staging'
[0m07:50:18.321955 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.products_staging
[0m07:50:18.337573 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.products_staging"
[0m07:50:18.337573 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.products_staging
[0m07:50:18.406577 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.products_staging"
[0m07:50:18.406577 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m07:50:18.406577 [debug] [Thread-1 (]: On model.dbt_data_pipeline.products_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.products_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_lake`.`products_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


-- Sélectionner uniquement les enregistrements ingérés au cours de la dernière heure
SELECT *
FROM `dataengineerproject-439609`.`dp_lake`.`products_normalized`
WHERE _dp_ingestion_timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR);


[0m07:50:18.607137 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:a59bc355-888c-4d95-8491-1af27c3a7ba8&page=queryresults
[0m07:50:18.607137 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:EU:a59bc355-888c-4d95-8491-1af27c3a7ba8&page=queryresults
[0m07:50:18.638403 [debug] [Thread-1 (]: Database Error in model products_staging (dbt_data_pipeline/models\datahub\products_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\products_staging.sql
[0m07:50:18.638403 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1d1eb3e1-d151-4fa5-a0e2-b86fc4931966', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB440C3590>]}
[0m07:50:18.638403 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model dp_lake.products_staging .................. [[31mERROR[0m in 0.32s]
[0m07:50:18.638403 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.products_staging
[0m07:50:18.638403 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:50:18.654026 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m07:50:18.654026 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_lake' was properly closed.
[0m07:50:18.654026 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.products_staging' was properly closed.
[0m07:50:18.654026 [info ] [MainThread]: 
[0m07:50:18.654026 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 3.97 seconds (3.97s).
[0m07:50:18.654026 [debug] [MainThread]: Command end result
[0m07:50:18.723058 [info ] [MainThread]: 
[0m07:50:18.723058 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m07:50:18.723058 [info ] [MainThread]: 
[0m07:50:18.723058 [error] [MainThread]:   Database Error in model products_staging (dbt_data_pipeline/models\datahub\products_staging.sql)
  Not found: Dataset dataengineerproject-439609:dp_lake was not found in location EU
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\products_staging.sql
[0m07:50:18.723058 [info ] [MainThread]: 
[0m07:50:18.723058 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m07:50:18.738675 [debug] [MainThread]: Command `dbt run` failed at 07:50:18.738675 after 10.22 seconds
[0m07:50:18.738675 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB38F6A5A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB388EACF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB388E91F0>]}
[0m07:50:18.738675 [debug] [MainThread]: Flushing usage events
[0m08:31:56.368852 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000272A859B170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000272AA7FF5C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000272AA7FFC20>]}


============================== 08:31:56.368852 | da5db889-7a09-452f-a1d5-fc9a332e8737 ==============================
[0m08:31:56.368852 [info ] [MainThread]: Running with dbt=1.8.7
[0m08:31:56.368852 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run -s products_staging.sql', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m08:32:00.371299 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'da5db889-7a09-452f-a1d5-fc9a332e8737', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000272B39B6120>]}
[0m08:32:00.455928 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'da5db889-7a09-452f-a1d5-fc9a332e8737', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000272B36003E0>]}
[0m08:32:00.455928 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m08:32:00.471573 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m08:32:00.621337 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m08:32:00.621337 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m08:32:00.621337 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'da5db889-7a09-452f-a1d5-fc9a332e8737', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000272B5DED0D0>]}
[0m08:32:02.407912 [error] [MainThread]: Encountered an error:
Compilation Error in model customers_staging (dbt_data_pipeline/models\datahub\customers_staging.sql)
  expected token ',', got 'tags'
    line 6
      tags=["hourly"]
[0m08:32:02.407912 [debug] [MainThread]: Command `dbt run` failed at 08:32:02.407912 after 6.46 seconds
[0m08:32:02.407912 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000272A859B170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000272AA872FC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000272B5CAB530>]}
[0m08:32:02.407912 [debug] [MainThread]: Flushing usage events
[0m08:32:23.289977 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014A2C69B2C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014A2E83B980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014A2E839340>]}


============================== 08:32:23.289977 | f9854708-e78e-4529-892f-10b7dd635533 ==============================
[0m08:32:23.289977 [info ] [MainThread]: Running with dbt=1.8.7
[0m08:32:23.289977 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run -s products_staging.sql', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m08:32:26.731217 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f9854708-e78e-4529-892f-10b7dd635533', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014A2EDFBFE0>]}
[0m08:32:26.821248 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f9854708-e78e-4529-892f-10b7dd635533', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014A2E143DD0>]}
[0m08:32:26.821248 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m08:32:26.841565 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m08:32:27.000712 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m08:32:27.000712 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m08:32:27.000712 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'f9854708-e78e-4529-892f-10b7dd635533', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014A2E8B0710>]}
[0m08:32:29.475727 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.data_engineer_project.datahub
- models.data_engineer_project.dataproducts
- models.data_engineer_project.datalake
[0m08:32:29.491384 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f9854708-e78e-4529-892f-10b7dd635533', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014A39E84110>]}
[0m08:32:29.691901 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f9854708-e78e-4529-892f-10b7dd635533', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014A3A003080>]}
[0m08:32:29.691901 [info ] [MainThread]: Found 5 models, 4 data tests, 3 sources, 484 macros
[0m08:32:29.691901 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f9854708-e78e-4529-892f-10b7dd635533', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014A39DD9250>]}
[0m08:32:29.691901 [info ] [MainThread]: 
[0m08:32:29.691901 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:32:29.691901 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m08:32:29.691901 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:32:33.108612 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609, now create_dataengineerproject-439609_dp_lake_dp_hub)
[0m08:32:33.108612 [debug] [ThreadPool]: Creating schema "database: "dataengineerproject-439609"
schema: "dp_lake_dp_hub"
"
[0m08:32:33.123589 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:32:33.123589 [debug] [ThreadPool]: On create_dataengineerproject-439609_dp_lake_dp_hub: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "connection_name": "create_dataengineerproject-439609_dp_lake_dp_hub"} */
create schema if not exists `dataengineerproject-439609`.`dp_lake_dp_hub`
  
[0m08:32:33.926576 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:a412eb37-0913-44a1-aeb5-36ec4a5b377a&page=queryresults
[0m08:32:35.578357 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_lake'
[0m08:32:35.578357 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:32:35.716936 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_lake, now list_dataengineerproject-439609_dp_lake_dp_hub)
[0m08:32:35.716936 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:32:35.986332 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f9854708-e78e-4529-892f-10b7dd635533', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014A39F895E0>]}
[0m08:32:35.986332 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m08:32:35.986332 [info ] [MainThread]: 
[0m08:32:35.986332 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.products_staging
[0m08:32:35.986332 [info ] [Thread-1 (]: 1 of 1 START sql view model dp_lake_dp_hub.products_staging .................... [RUN]
[0m08:32:35.986332 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.products_staging'
[0m08:32:36.001969 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.products_staging
[0m08:32:36.001969 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.products_staging"
[0m08:32:36.017593 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.products_staging
[0m08:32:36.048846 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.products_staging"
[0m08:32:36.048846 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m08:32:36.048846 [debug] [Thread-1 (]: On model.dbt_data_pipeline.products_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.products_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_lake_dp_hub`.`products_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


-- Sélectionner uniquement les enregistrements ingérés au cours de la dernière heure
SELECT *
FROM `dataengineerproject-439609`.`dp_lake`.`products_normalized`
WHERE _dp_ingestion_timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR);


[0m08:32:37.005260 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:4be6c0b9-2829-4aa4-b753-c305b8dda552&page=queryresults
[0m08:32:37.321431 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f9854708-e78e-4529-892f-10b7dd635533', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014A3808A360>]}
[0m08:32:37.337091 [info ] [Thread-1 (]: 1 of 1 OK created sql view model dp_lake_dp_hub.products_staging ............... [[32mCREATE VIEW (0 processed)[0m in 1.34s]
[0m08:32:37.337091 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.products_staging
[0m08:32:37.337091 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:32:37.337091 [debug] [MainThread]: Connection 'create_dataengineerproject-439609_dp_lake_dp_hub' was properly closed.
[0m08:32:37.337091 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_lake_dp_hub' was properly closed.
[0m08:32:37.337091 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.products_staging' was properly closed.
[0m08:32:37.337091 [info ] [MainThread]: 
[0m08:32:37.337091 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 7.65 seconds (7.65s).
[0m08:32:37.337091 [debug] [MainThread]: Command end result
[0m08:32:37.383900 [info ] [MainThread]: 
[0m08:32:37.390449 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:32:37.390449 [info ] [MainThread]: 
[0m08:32:37.390449 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m08:32:37.390449 [debug] [MainThread]: Command `dbt run` succeeded at 08:32:37.390449 after 14.37 seconds
[0m08:32:37.390449 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014A2EC95640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014A2EC96ED0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014A2F0491C0>]}
[0m08:32:37.390449 [debug] [MainThread]: Flushing usage events
[0m08:38:04.113165 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022A871D3350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022A86E1E8A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022A8771BC50>]}


============================== 08:38:04.128811 | ce524a46-205a-4b5b-af3d-b77900a75803 ==============================
[0m08:38:04.128811 [info ] [MainThread]: Running with dbt=1.8.7
[0m08:38:04.128811 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt compile -s products_staging.sql', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m08:38:07.667397 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ce524a46-205a-4b5b-af3d-b77900a75803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022A87AE5160>]}
[0m08:38:07.735901 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ce524a46-205a-4b5b-af3d-b77900a75803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022A87718C80>]}
[0m08:38:07.735901 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m08:38:07.751514 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m08:38:08.236428 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:38:08.236428 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:38:08.236428 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.data_engineer_project.datalake
- models.data_engineer_project.dataproducts
- models.data_engineer_project.datahub
[0m08:38:08.320662 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ce524a46-205a-4b5b-af3d-b77900a75803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022A9265C140>]}
[0m08:38:08.536998 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ce524a46-205a-4b5b-af3d-b77900a75803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022A926A39B0>]}
[0m08:38:08.536998 [info ] [MainThread]: Found 5 models, 4 data tests, 3 sources, 484 macros
[0m08:38:08.536998 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ce524a46-205a-4b5b-af3d-b77900a75803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022A90B7AD50>]}
[0m08:38:08.552623 [info ] [MainThread]: 
[0m08:38:08.552623 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:38:08.552623 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_lake_dp_hub'
[0m08:38:08.552623 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:38:11.728814 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_lake_dp_hub, now list_dataengineerproject-439609_dp_lake)
[0m08:38:11.728814 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:38:11.861011 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ce524a46-205a-4b5b-af3d-b77900a75803', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022A90B59C40>]}
[0m08:38:11.861011 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m08:38:11.861011 [info ] [MainThread]: 
[0m08:38:11.876013 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.products_staging
[0m08:38:11.876013 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.products_staging'
[0m08:38:11.876013 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.products_staging
[0m08:38:11.876013 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.products_staging"
[0m08:38:11.891639 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.products_staging
[0m08:38:11.891639 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.products_staging
[0m08:38:11.891639 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:38:11.891639 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_lake' was properly closed.
[0m08:38:11.891639 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.products_staging' was properly closed.
[0m08:38:11.891639 [debug] [MainThread]: Command end result
[0m08:38:11.929443 [info ] [MainThread]: Compiled node 'products_staging' is:
-- Tag pour indiquer que ce modèle est mis à jour toutes les heures


-- Sélectionner uniquement les enregistrements ingérés au cours de la dernière heure
SELECT *
FROM `dataengineerproject-439609`.`dp_lake`.`products_normalized`
WHERE _dp_ingestion_timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR)
[0m08:38:11.929443 [debug] [MainThread]: Command `dbt compile` succeeded at 08:38:11.929443 after 8.25 seconds
[0m08:38:11.929443 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022A877C1EB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022A87968530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022A87969130>]}
[0m08:38:11.929443 [debug] [MainThread]: Flushing usage events
[0m08:39:06.503488 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016770F6B020>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016772E53DA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000167736170E0>]}


============================== 08:39:06.503488 | 883022c2-e5da-4119-a8e1-90e16e21cb5d ==============================
[0m08:39:06.503488 [info ] [MainThread]: Running with dbt=1.8.7
[0m08:39:06.503488 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt compile -s products_staging.sql', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m08:39:10.033136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '883022c2-e5da-4119-a8e1-90e16e21cb5d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016772AC7650>]}
[0m08:39:10.155552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '883022c2-e5da-4119-a8e1-90e16e21cb5d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001677E357710>]}
[0m08:39:10.155552 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m08:39:10.171197 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m08:39:10.650508 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m08:39:10.650508 [debug] [MainThread]: Partial parsing: updated file: dbt_data_pipeline://dbt_data_pipeline/models\datahub\products_staging.sql
[0m08:39:11.000785 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.data_engineer_project.dataproducts
- models.data_engineer_project.datalake
- models.data_engineer_project.datahub
[0m08:39:11.016471 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '883022c2-e5da-4119-a8e1-90e16e21cb5d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001677E7ECAD0>]}
[0m08:39:11.217038 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '883022c2-e5da-4119-a8e1-90e16e21cb5d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001677E8B0A10>]}
[0m08:39:11.217038 [info ] [MainThread]: Found 5 models, 4 data tests, 3 sources, 484 macros
[0m08:39:11.217038 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '883022c2-e5da-4119-a8e1-90e16e21cb5d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001677E584CB0>]}
[0m08:39:11.217038 [info ] [MainThread]: 
[0m08:39:11.217038 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:39:11.232651 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_lake'
[0m08:39:11.232651 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:39:14.123782 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_lake, now list_dataengineerproject-439609_dp_lake_dp_hub)
[0m08:39:14.123782 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:39:14.302822 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '883022c2-e5da-4119-a8e1-90e16e21cb5d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001677E8C1A90>]}
[0m08:39:14.302822 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m08:39:14.302822 [info ] [MainThread]: 
[0m08:39:14.309334 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.products_staging
[0m08:39:14.309334 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.products_staging'
[0m08:39:14.309334 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.products_staging
[0m08:39:14.325028 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.products_staging"
[0m08:39:14.325028 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.products_staging
[0m08:39:14.325028 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.products_staging
[0m08:39:14.325028 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:39:14.325028 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_lake_dp_hub' was properly closed.
[0m08:39:14.325028 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.products_staging' was properly closed.
[0m08:39:14.325028 [debug] [MainThread]: Command end result
[0m08:39:14.387469 [info ] [MainThread]: Compiled node 'products_staging' is:
-- Tag pour indiquer que ce modèle est mis à jour toutes les heures


-- Sélectionner uniquement les enregistrements ingérés au cours de la dernière heure
SELECT *
FROM `dataengineerproject-439609`.`dp_lake`.`products_normalized`
WHERE _dp_ingestion_timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR)
[0m08:39:14.387469 [debug] [MainThread]: Command `dbt compile` succeeded at 08:39:14.387469 after 8.18 seconds
[0m08:39:14.387469 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016773833140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000167735F3200>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016773919580>]}
[0m08:39:14.387469 [debug] [MainThread]: Flushing usage events
[0m08:39:28.220817 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B52C9F4C50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B52E5AC980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B52F394530>]}


============================== 08:39:28.220817 | 9e53cdac-7e40-4311-84dc-d5c023d4baa1 ==============================
[0m08:39:28.220817 [info ] [MainThread]: Running with dbt=1.8.7
[0m08:39:28.220817 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run -s products_staging.sql', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m08:39:30.648876 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9e53cdac-7e40-4311-84dc-d5c023d4baa1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B538393200>]}
[0m08:39:30.722312 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9e53cdac-7e40-4311-84dc-d5c023d4baa1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B537DCBAA0>]}
[0m08:39:30.722312 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m08:39:30.742655 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m08:39:31.109510 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:39:31.109510 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:39:31.125079 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.data_engineer_project.datahub
- models.data_engineer_project.dataproducts
- models.data_engineer_project.datalake
[0m08:39:31.178519 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9e53cdac-7e40-4311-84dc-d5c023d4baa1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B5380C6360>]}
[0m08:39:31.379138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9e53cdac-7e40-4311-84dc-d5c023d4baa1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B53A39C500>]}
[0m08:39:31.379138 [info ] [MainThread]: Found 5 models, 4 data tests, 3 sources, 484 macros
[0m08:39:31.379138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9e53cdac-7e40-4311-84dc-d5c023d4baa1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B53A411880>]}
[0m08:39:31.379138 [info ] [MainThread]: 
[0m08:39:31.379138 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:39:31.379138 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m08:39:31.379138 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:39:33.482731 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_lake'
[0m08:39:33.482731 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:39:33.651003 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_lake, now list_dataengineerproject-439609_dp_lake_dp_hub)
[0m08:39:33.651003 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:39:33.751981 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9e53cdac-7e40-4311-84dc-d5c023d4baa1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B53A4DE2D0>]}
[0m08:39:33.751981 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m08:39:33.751981 [info ] [MainThread]: 
[0m08:39:33.767665 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.products_staging
[0m08:39:33.767665 [info ] [Thread-1 (]: 1 of 1 START sql view model dp_lake.products_staging ........................... [RUN]
[0m08:39:33.767665 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.products_staging'
[0m08:39:33.767665 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.products_staging
[0m08:39:33.783245 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.products_staging"
[0m08:39:33.783245 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.products_staging
[0m08:39:33.814531 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.products_staging"
[0m08:39:33.814531 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m08:39:33.830118 [debug] [Thread-1 (]: On model.dbt_data_pipeline.products_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.products_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_lake`.`products_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


-- Sélectionner uniquement les enregistrements ingérés au cours de la dernière heure
SELECT *
FROM `dataengineerproject-439609`.`dp_lake`.`products_normalized`
WHERE _dp_ingestion_timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR);


[0m08:39:34.154296 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:990fc6d2-da1f-48a8-a425-0840588ceb1e&page=queryresults
[0m08:39:34.385728 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e53cdac-7e40-4311-84dc-d5c023d4baa1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B5387F9640>]}
[0m08:39:34.385728 [info ] [Thread-1 (]: 1 of 1 OK created sql view model dp_lake.products_staging ...................... [[32mCREATE VIEW (0 processed)[0m in 0.62s]
[0m08:39:34.385728 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.products_staging
[0m08:39:34.385728 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:39:34.385728 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m08:39:34.385728 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_lake_dp_hub' was properly closed.
[0m08:39:34.385728 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.products_staging' was properly closed.
[0m08:39:34.401342 [info ] [MainThread]: 
[0m08:39:34.401342 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 3.01 seconds (3.01s).
[0m08:39:34.401342 [debug] [MainThread]: Command end result
[0m08:39:34.448213 [info ] [MainThread]: 
[0m08:39:34.448213 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:39:34.448213 [info ] [MainThread]: 
[0m08:39:34.454723 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m08:39:34.454723 [debug] [MainThread]: Command `dbt run` succeeded at 08:39:34.454723 after 6.45 seconds
[0m08:39:34.454723 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B52F6CB740>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B52F51DBE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B538899DF0>]}
[0m08:39:34.454723 [debug] [MainThread]: Flushing usage events
[0m08:42:40.570374 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D40E4CB290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D40D41D520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D410669550>]}


============================== 08:42:40.585966 | 76addc88-4165-4d22-acb7-b17bf92db114 ==============================
[0m08:42:40.585966 [info ] [MainThread]: Running with dbt=1.8.7
[0m08:42:40.585966 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run -s products_staging.sql', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m08:42:44.597940 [error] [MainThread]: Encountered an error:
Runtime Error
  Credentials in profile "dbt_data_pipeline", target "dev" invalid: Runtime Error
    Must specify schema
[0m08:42:44.599972 [debug] [MainThread]: Command `dbt run` failed at 08:42:44.599972 after 4.31 seconds
[0m08:42:44.599972 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D40E4CB290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D419B084A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D419A03170>]}
[0m08:42:44.599972 [debug] [MainThread]: Flushing usage events
[0m08:44:18.796821 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022D4AE37620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022D4AE36B10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022D4A9BF200>]}


============================== 08:44:18.812440 | 2241fb26-f287-4f24-b6d2-43497a6a5ab2 ==============================
[0m08:44:18.812440 [info ] [MainThread]: Running with dbt=1.8.7
[0m08:44:18.812440 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run -s products_staging.sql', 'send_anonymous_usage_stats': 'True'}
[0m08:44:21.822261 [error] [MainThread]: Encountered an error:
Runtime Error
  Credentials in profile "dbt_data_pipeline", target "dev" invalid: Runtime Error
    Must specify schema
[0m08:44:21.822261 [debug] [MainThread]: Command `dbt run` failed at 08:44:21.822261 after 3.34 seconds
[0m08:44:21.822261 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022D4AE075C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022D5307A660>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022D55B6C8F0>]}
[0m08:44:21.822261 [debug] [MainThread]: Flushing usage events
[0m08:51:02.385882 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024A9D6A3170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024A9DD4F440>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024A9DD4C8F0>]}


============================== 08:51:02.385882 | f4d6650c-d396-4597-b09a-82d1aeca132c ==============================
[0m08:51:02.385882 [info ] [MainThread]: Running with dbt=1.8.7
[0m08:51:02.385882 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run -s products_staging.sql', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m08:51:05.882561 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f4d6650c-d396-4597-b09a-82d1aeca132c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024AA86FC110>]}
[0m08:51:05.951640 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f4d6650c-d396-4597-b09a-82d1aeca132c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024AA883BDA0>]}
[0m08:51:05.951640 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m08:51:05.982838 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m08:51:06.130054 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m08:51:06.130054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'f4d6650c-d396-4597-b09a-82d1aeca132c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024A9DD4FE00>]}
[0m08:51:08.205948 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_data_pipeline.datalake
- models.dbt_data_pipeline.dataproducts
[0m08:51:08.237248 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f4d6650c-d396-4597-b09a-82d1aeca132c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024AA8D32390>]}
[0m08:51:08.437843 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f4d6650c-d396-4597-b09a-82d1aeca132c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024AA8D642F0>]}
[0m08:51:08.437843 [info ] [MainThread]: Found 5 models, 4 data tests, 3 sources, 484 macros
[0m08:51:08.437843 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f4d6650c-d396-4597-b09a-82d1aeca132c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024AA8D49EB0>]}
[0m08:51:08.437843 [info ] [MainThread]: 
[0m08:51:08.437843 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:51:08.437843 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m08:51:08.453468 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:51:11.482146 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_lake'
[0m08:51:11.482146 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:51:11.613747 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_lake, now list_dataengineerproject-439609_dp_lake_dp_hub)
[0m08:51:11.613747 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:51:11.783249 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f4d6650c-d396-4597-b09a-82d1aeca132c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024AA8BCB590>]}
[0m08:51:11.783249 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m08:51:11.783249 [info ] [MainThread]: 
[0m08:51:11.798242 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.products_staging
[0m08:51:11.798242 [info ] [Thread-1 (]: 1 of 1 START sql view model dp_lake_dp_hub.products_staging .................... [RUN]
[0m08:51:11.798242 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.products_staging'
[0m08:51:11.798242 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.products_staging
[0m08:51:11.813879 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.products_staging"
[0m08:51:11.813879 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.products_staging
[0m08:51:11.845114 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.products_staging"
[0m08:51:11.860740 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m08:51:11.860740 [debug] [Thread-1 (]: On model.dbt_data_pipeline.products_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.products_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_lake_dp_hub`.`products_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


-- Sélectionner uniquement les enregistrements ingérés au cours de la dernière heure
SELECT *
FROM `dataengineerproject-439609`.`dp_lake`.`products_normalized`
WHERE _dp_ingestion_timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR);


[0m08:51:12.199833 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:9b4c1f2e-79d6-466b-acc3-d0ae7fd3e551&page=queryresults
[0m08:51:12.516021 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f4d6650c-d396-4597-b09a-82d1aeca132c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024AA6DD9B80>]}
[0m08:51:12.516021 [info ] [Thread-1 (]: 1 of 1 OK created sql view model dp_lake_dp_hub.products_staging ............... [[32mCREATE VIEW (0 processed)[0m in 0.72s]
[0m08:51:12.516021 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.products_staging
[0m08:51:12.531641 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:51:12.531641 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m08:51:12.531641 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_lake_dp_hub' was properly closed.
[0m08:51:12.531641 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.products_staging' was properly closed.
[0m08:51:12.531641 [info ] [MainThread]: 
[0m08:51:12.531641 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 4.09 seconds (4.09s).
[0m08:51:12.531641 [debug] [MainThread]: Command end result
[0m08:51:12.569458 [info ] [MainThread]: 
[0m08:51:12.569458 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:51:12.569458 [info ] [MainThread]: 
[0m08:51:12.569458 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m08:51:12.569458 [debug] [MainThread]: Command `dbt run` succeeded at 08:51:12.569458 after 10.55 seconds
[0m08:51:12.569458 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024A9D6A3170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024AA6DEA6C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024A9CCD55B0>]}
[0m08:51:12.569458 [debug] [MainThread]: Flushing usage events
[0m08:54:11.111614 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000197301BB260>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001972F2A9760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000197329670B0>]}


============================== 08:54:11.127241 | 72dbb2d5-7e26-41f3-b21a-6805fbc3d3e5 ==============================
[0m08:54:11.127241 [info ] [MainThread]: Running with dbt=1.8.7
[0m08:54:11.127241 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/path/to/your/.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt debug --profiles-dir /path/to/your/.dbt', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m08:54:11.210885 [info ] [MainThread]: dbt version: 1.8.7
[0m08:54:11.210885 [info ] [MainThread]: python version: 3.12.4
[0m08:54:11.210885 [info ] [MainThread]: python path: C:\Users\lenovo\data-engineer-project\.venv\Scripts\python.exe
[0m08:54:11.210885 [info ] [MainThread]: os info: Windows-10-10.0.19045-SP0
[0m08:54:11.210885 [info ] [MainThread]: Using profiles dir at /path/to/your/.dbt
[0m08:54:11.210885 [info ] [MainThread]: Using profiles.yml file at /path/to/your/.dbt\profiles.yml
[0m08:54:11.210885 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\lenovo\data-engineer-project\dbt_project.yml
[0m08:54:11.411451 [info ] [MainThread]: Configuration:
[0m08:54:11.427071 [info ] [MainThread]:   profiles.yml file [[31mERROR not found[0m]
[0m08:54:11.433584 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m08:54:11.433584 [info ] [MainThread]: Required dependencies:
[0m08:54:11.433584 [debug] [MainThread]: Executing "git --help"
[0m08:54:11.665346 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m08:54:11.665346 [debug] [MainThread]: STDERR: "b''"
[0m08:54:11.665346 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m08:54:11.665346 [info ] [MainThread]: Connection test skipped since no profile was found
[0m08:54:11.665346 [info ] [MainThread]: [31m1 check failed:[0m
[0m08:54:11.665346 [info ] [MainThread]: dbt looked for a profiles.yml file in /path/to/your/.dbt\profiles.yml, but did
not find one. For more information on configuring your profile, consult the
documentation:

https://docs.getdbt.com/docs/configure-your-profile


[0m08:54:11.680971 [debug] [MainThread]: Command `dbt debug` failed at 08:54:11.680971 after 0.97 seconds
[0m08:54:11.680971 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019732BBCD40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019732B43920>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000197322E6480>]}
[0m08:54:11.680971 [debug] [MainThread]: Flushing usage events
[0m08:54:33.664622 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000260FBFEC2F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000260F9DDB020>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000260FC6A2CF0>]}


============================== 08:54:33.664622 | e529d8ff-39ca-4ec8-9204-d80a46871ef6 ==============================
[0m08:54:33.664622 [info ] [MainThread]: Running with dbt=1.8.7
[0m08:54:33.664622 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt debug --profiles-dir C:\\Users\\lenovo\\.dbt', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m08:54:33.711501 [info ] [MainThread]: dbt version: 1.8.7
[0m08:54:33.711501 [info ] [MainThread]: python version: 3.12.4
[0m08:54:33.711501 [info ] [MainThread]: python path: C:\Users\lenovo\data-engineer-project\.venv\Scripts\python.exe
[0m08:54:33.711501 [info ] [MainThread]: os info: Windows-10-10.0.19045-SP0
[0m08:54:36.652515 [info ] [MainThread]: Using profiles dir at C:\Users\lenovo\.dbt
[0m08:54:36.652515 [info ] [MainThread]: Using profiles.yml file at C:\Users\lenovo\.dbt\profiles.yml
[0m08:54:36.652515 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\lenovo\data-engineer-project\dbt_project.yml
[0m08:54:36.799777 [info ] [MainThread]: Configuration:
[0m08:54:36.799777 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m08:54:36.799777 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m08:54:36.799777 [info ] [MainThread]: Required dependencies:
[0m08:54:36.799777 [debug] [MainThread]: Executing "git --help"
[0m08:54:36.969129 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m08:54:36.984716 [debug] [MainThread]: STDERR: "b''"
[0m08:54:36.984716 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m08:54:36.984716 [info ] [MainThread]: Connection test skipped since no profile was found
[0m08:54:36.984716 [info ] [MainThread]: [31m1 check failed:[0m
[0m08:54:36.984716 [info ] [MainThread]: Profile loading failed for the following reason:
Runtime Error
  Credentials in profile "dbt_data_pipeline", target "dev" invalid: Runtime Error
    Must specify schema


[0m08:54:36.984716 [debug] [MainThread]: Command `dbt debug` failed at 08:54:36.984716 after 3.54 seconds
[0m08:54:36.984716 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000260FC70E870>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000260FC73A3F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000260FC8B5F70>]}
[0m08:54:36.984716 [debug] [MainThread]: Flushing usage events
[0m08:57:24.514890 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026A43CE01A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026A41FBB230>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026A427C21E0>]}


============================== 08:57:24.521399 | 034c273f-f3a5-448d-a3c0-c1281606665e ==============================
[0m08:57:24.521399 [info ] [MainThread]: Running with dbt=1.8.7
[0m08:57:24.521399 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug --profiles-dir C:\\Users\\lenovo\\.dbt', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m08:57:24.568326 [info ] [MainThread]: dbt version: 1.8.7
[0m08:57:24.583911 [info ] [MainThread]: python version: 3.12.4
[0m08:57:24.583911 [info ] [MainThread]: python path: C:\Users\lenovo\data-engineer-project\.venv\Scripts\python.exe
[0m08:57:24.583911 [info ] [MainThread]: os info: Windows-10-10.0.19045-SP0
[0m08:57:27.142274 [info ] [MainThread]: Using profiles dir at C:\Users\lenovo\.dbt
[0m08:57:27.142274 [info ] [MainThread]: Using profiles.yml file at C:\Users\lenovo\.dbt\profiles.yml
[0m08:57:27.157838 [info ] [MainThread]: Using dbt_project.yml file at C:\Users\lenovo\data-engineer-project\dbt_project.yml
[0m08:57:27.157838 [info ] [MainThread]: adapter type: bigquery
[0m08:57:27.157838 [info ] [MainThread]: adapter version: 1.8.3
[0m08:57:27.258226 [info ] [MainThread]: Configuration:
[0m08:57:27.258226 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m08:57:27.258226 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m08:57:27.273773 [info ] [MainThread]: Required dependencies:
[0m08:57:27.273773 [debug] [MainThread]: Executing "git --help"
[0m08:57:27.473878 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m08:57:27.489536 [debug] [MainThread]: STDERR: "b''"
[0m08:57:27.489536 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m08:57:27.489536 [info ] [MainThread]: Connection:
[0m08:57:27.489536 [info ] [MainThread]:   method: oauth
[0m08:57:27.489536 [info ] [MainThread]:   database: dataengineerproject-439609
[0m08:57:27.489536 [info ] [MainThread]:   execution_project: dataengineerproject-439609
[0m08:57:27.489536 [info ] [MainThread]:   schema: dp_default
[0m08:57:27.489536 [info ] [MainThread]:   location: europe-west9
[0m08:57:27.489536 [info ] [MainThread]:   priority: None
[0m08:57:27.489536 [info ] [MainThread]:   maximum_bytes_billed: None
[0m08:57:27.489536 [info ] [MainThread]:   impersonate_service_account: None
[0m08:57:27.489536 [info ] [MainThread]:   job_retry_deadline_seconds: None
[0m08:57:27.505127 [info ] [MainThread]:   job_retries: 1
[0m08:57:27.505127 [info ] [MainThread]:   job_creation_timeout_seconds: None
[0m08:57:27.505127 [info ] [MainThread]:   job_execution_timeout_seconds: 300
[0m08:57:27.505127 [info ] [MainThread]:   timeout_seconds: 300
[0m08:57:27.505127 [info ] [MainThread]:   client_id: None
[0m08:57:27.505127 [info ] [MainThread]:   token_uri: None
[0m08:57:27.505127 [info ] [MainThread]:   dataproc_region: None
[0m08:57:27.505127 [info ] [MainThread]:   dataproc_cluster_name: None
[0m08:57:27.505127 [info ] [MainThread]:   gcs_bucket: None
[0m08:57:27.505127 [info ] [MainThread]:   dataproc_batch: None
[0m08:57:27.505127 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m08:57:27.505127 [debug] [MainThread]: Acquiring new bigquery connection 'debug'
[0m08:57:27.505127 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:57:30.032593 [debug] [MainThread]: On debug: select 1 as id
[0m08:57:33.738996 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:ae086dc4-29d9-4799-b92a-5c3dbe2dacd4&page=queryresults
[0m08:57:33.945135 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m08:57:33.945135 [info ] [MainThread]: [32mAll checks passed![0m
[0m08:57:33.960780 [debug] [MainThread]: Command `dbt debug` succeeded at 08:57:33.960780 after 9.71 seconds
[0m08:57:33.960780 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m08:57:33.960780 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026A43CE01A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026A4DBB3350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026A4CA2BC80>]}
[0m08:57:33.960780 [debug] [MainThread]: Flushing usage events
[0m08:57:44.966993 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014AB4E24D40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014AB7C7BAD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014AB7C783B0>]}


============================== 08:57:44.973507 | 7c635124-6637-4f7a-9d43-27a2f6e55eef ==============================
[0m08:57:44.973507 [info ] [MainThread]: Running with dbt=1.8.7
[0m08:57:44.973507 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run -s products_staging.sql', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m08:57:47.595360 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7c635124-6637-4f7a-9d43-27a2f6e55eef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014AC26ABE60>]}
[0m08:57:47.657857 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7c635124-6637-4f7a-9d43-27a2f6e55eef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014ABFC20740>]}
[0m08:57:47.657857 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m08:57:47.679997 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m08:57:47.811633 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m08:57:47.811633 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m08:57:47.811633 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '7c635124-6637-4f7a-9d43-27a2f6e55eef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014AC27A4080>]}
[0m08:57:49.960954 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_data_pipeline.dataproducts
- models.dbt_data_pipeline.datalake
[0m08:57:49.983087 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7c635124-6637-4f7a-9d43-27a2f6e55eef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014AC2A6AC60>]}
[0m08:57:50.161556 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7c635124-6637-4f7a-9d43-27a2f6e55eef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014AC2C32660>]}
[0m08:57:50.161556 [info ] [MainThread]: Found 5 models, 4 data tests, 3 sources, 484 macros
[0m08:57:50.161556 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7c635124-6637-4f7a-9d43-27a2f6e55eef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014AC29A37D0>]}
[0m08:57:50.161556 [info ] [MainThread]: 
[0m08:57:50.161556 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m08:57:50.177139 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m08:57:50.177139 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:57:52.564276 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609, now create_dataengineerproject-439609_dp_default_dp_hub)
[0m08:57:52.564276 [debug] [ThreadPool]: Creating schema "database: "dataengineerproject-439609"
schema: "dp_default_dp_hub"
"
[0m08:57:52.586388 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:57:52.586388 [debug] [ThreadPool]: On create_dataengineerproject-439609_dp_default_dp_hub: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "connection_name": "create_dataengineerproject-439609_dp_default_dp_hub"} */
create schema if not exists `dataengineerproject-439609`.`dp_default_dp_hub`
  
[0m08:57:53.522408 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:291585aa-59f0-40d2-8eea-6467cb51a888&page=queryresults
[0m08:57:56.560719 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_default_dp_hub'
[0m08:57:56.560719 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:57:56.692639 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_default_dp_hub, now list_dataengineerproject-439609_dp_default)
[0m08:57:56.692639 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m08:57:57.177025 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7c635124-6637-4f7a-9d43-27a2f6e55eef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014AC2CB6540>]}
[0m08:57:57.177025 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m08:57:57.177025 [info ] [MainThread]: 
[0m08:57:57.192033 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.products_staging
[0m08:57:57.192033 [info ] [Thread-1 (]: 1 of 1 START sql view model dp_default_dp_hub.products_staging ................. [RUN]
[0m08:57:57.192033 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.products_staging'
[0m08:57:57.192033 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.products_staging
[0m08:57:57.198548 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.products_staging"
[0m08:57:57.198548 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.products_staging
[0m08:57:57.229864 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.products_staging"
[0m08:57:57.229864 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m08:57:57.245465 [debug] [Thread-1 (]: On model.dbt_data_pipeline.products_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.products_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_default_dp_hub`.`products_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


-- Sélectionner uniquement les enregistrements ingérés au cours de la dernière heure
SELECT *
FROM `dataengineerproject-439609`.`dp_lake`.`products_normalized`
WHERE _dp_ingestion_timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR);


[0m08:57:57.995735 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:d3f4f40f-0e95-41a5-a82d-763ff7b68c22&page=queryresults
[0m08:57:58.318884 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7c635124-6637-4f7a-9d43-27a2f6e55eef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014AC0CB9A90>]}
[0m08:57:58.318884 [info ] [Thread-1 (]: 1 of 1 OK created sql view model dp_default_dp_hub.products_staging ............ [[32mCREATE VIEW (0 processed)[0m in 1.13s]
[0m08:57:58.318884 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.products_staging
[0m08:57:58.318884 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:57:58.318884 [debug] [MainThread]: Connection 'create_dataengineerproject-439609_dp_default_dp_hub' was properly closed.
[0m08:57:58.318884 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_default' was properly closed.
[0m08:57:58.318884 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.products_staging' was properly closed.
[0m08:57:58.318884 [info ] [MainThread]: 
[0m08:57:58.318884 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 8.16 seconds (8.16s).
[0m08:57:58.318884 [debug] [MainThread]: Command end result
[0m08:57:58.365753 [info ] [MainThread]: 
[0m08:57:58.365753 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:57:58.365753 [info ] [MainThread]: 
[0m08:57:58.365753 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m08:57:58.365753 [debug] [MainThread]: Command `dbt run` succeeded at 08:57:58.365753 after 13.65 seconds
[0m08:57:58.365753 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014AB7CCCC80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014AB7B1E480>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014AB729E540>]}
[0m08:57:58.365753 [debug] [MainThread]: Flushing usage events
[0m09:04:15.223036 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A779E8EC00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A77A9D3170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A77A8DCD70>]}


============================== 09:04:15.223036 | b4d3ff50-7280-4551-9524-a7ee68c4154d ==============================
[0m09:04:15.223036 [info ] [MainThread]: Running with dbt=1.8.7
[0m09:04:15.223036 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt run -s products_staging.sql', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m09:04:18.768267 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b4d3ff50-7280-4551-9524-a7ee68c4154d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A70565C650>]}
[0m09:04:18.868634 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b4d3ff50-7280-4551-9524-a7ee68c4154d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A779C34DA0>]}
[0m09:04:18.868634 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m09:04:18.884215 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m09:04:19.015803 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m09:04:19.015803 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m09:04:19.015803 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'b4d3ff50-7280-4551-9524-a7ee68c4154d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A70589D5E0>]}
[0m09:04:21.135371 [error] [MainThread]: Encountered an error:

[0m09:04:21.319941 [error] [MainThread]: Traceback (most recent call last):
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\cli\requires.py", line 138, in wrapper
    result, success = func(*args, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\cli\requires.py", line 101, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\cli\requires.py", line 218, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\cli\requires.py", line 247, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\cli\requires.py", line 294, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\cli\requires.py", line 320, in wrapper
    ctx.obj["manifest"] = parse_manifest(
                          ^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\parser\manifest.py", line 1898, in parse_manifest
    manifest = ManifestLoader.get_full_manifest(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\parser\manifest.py", line 330, in get_full_manifest
    manifest = loader.load()
               ^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\parser\manifest.py", line 452, in load
    self.parse_project(
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\parser\manifest.py", line 729, in parse_project
    parser.parse_file(block, dct=dct)
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\parser\schemas.py", line 190, in parse_file
    self.generic_test_parser.parse_versioned_tests(versioned_test_block)
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\parser\schema_generic_tests.py", line 396, in parse_versioned_tests
    self.parse_tests(block)
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\parser\schema_generic_tests.py", line 389, in parse_tests
    self.parse_column_tests(block, column, None)
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\parser\schema_generic_tests.py", line 80, in parse_column_tests
    self.parse_test(block, data_test, column, version)
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\parser\schema_generic_tests.py", line 385, in parse_test
    self.parse_node(block)
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\parser\schema_generic_tests.py", line 323, in parse_node
    node = self.parse_generic_test(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\parser\schema_generic_tests.py", line 214, in parse_generic_test
    node = self.create_test_node(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\parser\schema_generic_tests.py", line 134, in create_test_node
    GenericTestNode.validate(dct)
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt_common\dataclass_schema.py", line 95, in validate
    json_schema = cls.json_schema()
                  ^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt_common\dataclass_schema.py", line 89, in json_schema
    json_schema_obj = build_json_schema(cls)
                      ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\mashumaro\jsonschema\builder.py", line 45, in build_json_schema
    schema = get_schema(instance, context, with_dialect_uri=with_dialect_uri)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\mashumaro\jsonschema\schema.py", line 268, in get_schema
    schema = schema_creator(instance, ctx)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\mashumaro\jsonschema\schema.py", line 353, in on_dataclass
    for f_name, f_type, has_default, f_default in instance.fields():
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\mashumaro\jsonschema\schema.py", line 188, in fields
    f_default = _default(f_type, f_default, self.get_self_config())
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\mashumaro\jsonschema\schema.py", line 296, in _default
    return CC(f_value).to_dict()["x"]
           ^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 2, in __mashumaro_to_dict__
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\mashumaro\core\meta\code\builder.py", line 1142, in add_pack_method
    self.compile()
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\mashumaro\core\meta\code\builder.py", line 332, in compile
    exec(code, self.globals, self.__dict__)
  File "<string>", line 0, in <module>
KeyboardInterrupt

[0m09:04:21.319941 [debug] [MainThread]: Command `dbt run` failed at 09:04:21.319941 after 6.44 seconds
[0m09:04:21.319941 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A77A95A420>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A7056C9FD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A70591B290>]}
[0m09:04:21.319941 [debug] [MainThread]: Flushing usage events
[0m09:04:34.645506 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020D941A0EC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020D9387EA20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020D941A3680>]}


============================== 09:04:34.645506 | 09f71627-9d48-493b-9ef3-2c3449c7be16 ==============================
[0m09:04:34.645506 [info ] [MainThread]: Running with dbt=1.8.7
[0m09:04:34.645506 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run -s products_staging.sql', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m09:04:37.571116 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '09f71627-9d48-493b-9ef3-2c3449c7be16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020D9447F2C0>]}
[0m09:04:37.640152 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '09f71627-9d48-493b-9ef3-2c3449c7be16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020D9D689FD0>]}
[0m09:04:37.640152 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m09:04:37.655772 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m09:04:37.840656 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m09:04:37.840656 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m09:04:37.840656 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '09f71627-9d48-493b-9ef3-2c3449c7be16', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020D9EF87DA0>]}
[0m09:04:39.332861 [error] [MainThread]: Encountered an error:

[0m09:04:39.617869 [error] [MainThread]: Traceback (most recent call last):
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\cli\requires.py", line 138, in wrapper
    result, success = func(*args, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\cli\requires.py", line 101, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\cli\requires.py", line 218, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\cli\requires.py", line 247, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\cli\requires.py", line 294, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\cli\requires.py", line 320, in wrapper
    ctx.obj["manifest"] = parse_manifest(
                          ^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\parser\manifest.py", line 1898, in parse_manifest
    manifest = ManifestLoader.get_full_manifest(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\parser\manifest.py", line 330, in get_full_manifest
    manifest = loader.load()
               ^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\parser\manifest.py", line 399, in load
    self.load_and_parse_macros(project_parser_files)
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\parser\manifest.py", line 692, in load_and_parse_macros
    self.macro_depends_on()
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\parser\manifest.py", line 786, in macro_depends_on
    possible_macro_calls = statically_extract_macro_calls(
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\clients\jinja_static.py", line 22, in statically_extract_macro_calls
    parsed = env.parse(string)
             ^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\jinja2\environment.py", line 611, in parse
    return self._parse(source, name, filename)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt_common\clients\jinja.py", line 110, in _parse
    return MacroFuzzParser(self, source, name, filename).parse()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\jinja2\parser.py", line 1040, in parse
    result.set_environment(self.environment)
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\jinja2\nodes.py", line 237, in set_environment
    todo.extend(node.iter_child_nodes())
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\jinja2\nodes.py", line 169, in iter_child_nodes
    def iter_child_nodes(
    
KeyboardInterrupt

[0m09:04:39.617869 [debug] [MainThread]: Command `dbt run` failed at 09:04:39.617869 after 5.20 seconds
[0m09:04:39.617869 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020D9417F560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020D9F054FE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020D9C9A50D0>]}
[0m09:04:39.617869 [debug] [MainThread]: Flushing usage events
[0m09:05:01.145042 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001749D5F88C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001749D3FD5E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001749D3FD7C0>]}


============================== 09:05:01.160665 | b9b57838-e2e6-4e00-bc3e-30bf4e362870 ==============================
[0m09:05:01.160665 [info ] [MainThread]: Running with dbt=1.8.7
[0m09:05:01.160665 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run -s products_staging.sql', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m09:05:04.085010 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b9b57838-e2e6-4e00-bc3e-30bf4e362870', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001749D754EC0>]}
[0m09:05:04.189413 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b9b57838-e2e6-4e00-bc3e-30bf4e362870', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001749C7A4EF0>]}
[0m09:05:04.189413 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m09:05:04.204434 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m09:05:04.445637 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m09:05:04.445637 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m09:05:04.445637 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'b9b57838-e2e6-4e00-bc3e-30bf4e362870', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000174A5818740>]}
[0m09:05:06.654396 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_data_pipeline.datalake
- models.dbt_data_pipeline.dataproducts
[0m09:05:06.660407 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b9b57838-e2e6-4e00-bc3e-30bf4e362870', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000174A8578F20>]}
[0m09:05:06.876785 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b9b57838-e2e6-4e00-bc3e-30bf4e362870', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000174A860C860>]}
[0m09:05:06.876785 [info ] [MainThread]: Found 5 models, 4 data tests, 3 sources, 484 macros
[0m09:05:06.876785 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b9b57838-e2e6-4e00-bc3e-30bf4e362870', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000174A8670890>]}
[0m09:05:06.876785 [info ] [MainThread]: 
[0m09:05:06.876785 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:05:06.876785 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m09:05:06.892391 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:05:10.113564 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_hub'
[0m09:05:10.113564 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:05:10.250996 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_hub, now list_dataengineerproject-439609_dp)
[0m09:05:10.250996 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:05:10.831440 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b9b57838-e2e6-4e00-bc3e-30bf4e362870', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000174A853C260>]}
[0m09:05:10.831440 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:05:10.831440 [info ] [MainThread]: 
[0m09:05:10.846417 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.products_staging
[0m09:05:10.846417 [info ] [Thread-1 (]: 1 of 1 START sql view model dp_hub.products_staging ............................ [RUN]
[0m09:05:10.846417 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.products_staging'
[0m09:05:10.846417 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.products_staging
[0m09:05:10.852953 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.products_staging"
[0m09:05:10.852953 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.products_staging
[0m09:05:10.899903 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.products_staging"
[0m09:05:10.899903 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m09:05:10.899903 [debug] [Thread-1 (]: On model.dbt_data_pipeline.products_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.products_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_hub`.`products_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


-- Sélectionner uniquement les enregistrements ingérés au cours de la dernière heure
SELECT *
FROM `dataengineerproject-439609`.`dp_lake`.`products_normalized`
WHERE _dp_ingestion_timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR);


[0m09:05:11.755774 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:a038cf90-b4ce-429e-9de7-3c529841b4bd&page=queryresults
[0m09:05:11.972040 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b9b57838-e2e6-4e00-bc3e-30bf4e362870', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000174A667A660>]}
[0m09:05:11.972040 [info ] [Thread-1 (]: 1 of 1 OK created sql view model dp_hub.products_staging ....................... [[32mCREATE VIEW (0 processed)[0m in 1.13s]
[0m09:05:11.972040 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.products_staging
[0m09:05:11.972040 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:05:11.972040 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m09:05:11.972040 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp' was properly closed.
[0m09:05:11.972040 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.products_staging' was properly closed.
[0m09:05:11.972040 [info ] [MainThread]: 
[0m09:05:11.972040 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 5.10 seconds (5.10s).
[0m09:05:11.987660 [debug] [MainThread]: Command end result
[0m09:05:12.018911 [info ] [MainThread]: 
[0m09:05:12.018911 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:05:12.018911 [info ] [MainThread]: 
[0m09:05:12.018911 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m09:05:12.034536 [debug] [MainThread]: Command `dbt run` succeeded at 09:05:12.034536 after 11.19 seconds
[0m09:05:12.034536 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001749D754C20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001749D754980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001749D756090>]}
[0m09:05:12.034536 [debug] [MainThread]: Flushing usage events
[0m09:26:51.513269 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C49B43B350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C49DE3C3B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C49DDBFCB0>]}


============================== 09:26:51.523261 | 803dbce3-c0f2-4b00-bb50-d3102188c3ba ==============================
[0m09:26:51.523261 [info ] [MainThread]: Running with dbt=1.8.7
[0m09:26:51.527282 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run -s products_staging.sql --full-refresh', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m09:26:56.005386 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '803dbce3-c0f2-4b00-bb50-d3102188c3ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4A77FB920>]}
[0m09:26:56.132631 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '803dbce3-c0f2-4b00-bb50-d3102188c3ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C49DDE8050>]}
[0m09:26:56.135630 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m09:26:56.167910 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m09:26:56.859866 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:26:56.860866 [debug] [MainThread]: Partial parsing: updated file: dbt_data_pipeline://dbt_data_pipeline/models\datahub\products_staging.sql
[0m09:26:57.255389 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_data_pipeline.dataproducts
- models.dbt_data_pipeline.datalake
[0m09:26:57.271400 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '803dbce3-c0f2-4b00-bb50-d3102188c3ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4A8E3AE10>]}
[0m09:26:57.486971 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '803dbce3-c0f2-4b00-bb50-d3102188c3ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4A8E27FE0>]}
[0m09:26:57.487972 [info ] [MainThread]: Found 5 models, 4 data tests, 3 sources, 484 macros
[0m09:26:57.488971 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '803dbce3-c0f2-4b00-bb50-d3102188c3ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4A8A301A0>]}
[0m09:26:57.494740 [info ] [MainThread]: 
[0m09:26:57.495739 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:26:57.498737 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m09:26:57.499737 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:27:01.528107 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609, now create_dataengineerproject-439609_dp_dp_hub)
[0m09:27:01.530140 [debug] [ThreadPool]: Creating schema "database: "dataengineerproject-439609"
schema: "dp_dp_hub"
"
[0m09:27:01.540724 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:27:01.541729 [debug] [ThreadPool]: On create_dataengineerproject-439609_dp_dp_hub: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "connection_name": "create_dataengineerproject-439609_dp_dp_hub"} */
create schema if not exists `dataengineerproject-439609`.`dp_dp_hub`
  
[0m09:27:01.825233 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:d9bf7a0f-82e9-4b56-b457-6b7a6d5a5596&page=queryresults
[0m09:27:04.913259 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_hub'
[0m09:27:04.918256 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:27:05.114320 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_hub, now list_dataengineerproject-439609_dp_dp_hub)
[0m09:27:05.116321 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:27:05.298653 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_dp_hub, now list_dataengineerproject-439609_dp)
[0m09:27:05.300262 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:27:05.799212 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '803dbce3-c0f2-4b00-bb50-d3102188c3ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4A8CEBFB0>]}
[0m09:27:05.800210 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:27:05.801211 [info ] [MainThread]: 
[0m09:27:05.810116 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.products_staging
[0m09:27:05.812116 [info ] [Thread-1 (]: 1 of 1 START sql view model dp_dp_hub.products_staging ......................... [RUN]
[0m09:27:05.813117 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.products_staging'
[0m09:27:05.814117 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.products_staging
[0m09:27:05.830064 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.products_staging"
[0m09:27:05.836065 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.products_staging
[0m09:27:05.909401 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.products_staging"
[0m09:27:05.912402 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m09:27:05.914400 [debug] [Thread-1 (]: On model.dbt_data_pipeline.products_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.products_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_dp_hub`.`products_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


WITH ranked_products AS (
    SELECT
        *,
        ROW_NUMBER() OVER (
            PARTITION BY product_sku
            ORDER BY _dp_ingestion_timestamp DESC
        ) AS row_num
    FROM `dataengineerproject-439609`.`dp_lake`.`products_normalized`
)

-- Sélectionner uniquement les enregistrements uniques les plus récents
SELECT
    _dp_ingestion_timestamp,
    product_sku,
    unit_amount,
    description,
    supplier

FROM
    ranked_products
WHERE
    row_num = 1;;


[0m09:27:06.117046 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:13f18009-24d0-459b-8232-ad2eab92cf7d&page=queryresults
[0m09:27:06.117995 [debug] [Thread-1 (]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Syntax error: Unexpected ";" at [30:17]; reason: invalidQuery, location: query, message: Syntax error: Unexpected ";" at [30:17]')
[0m09:27:06.412761 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:eb5c2b82-810a-421e-ba63-84d21ab22abe&page=queryresults
[0m09:27:06.414762 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:eb5c2b82-810a-421e-ba63-84d21ab22abe&page=queryresults
[0m09:27:06.443981 [debug] [Thread-1 (]: Database Error in model products_staging (dbt_data_pipeline/models\datahub\products_staging.sql)
  Syntax error: Unexpected ";" at [30:17]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\products_staging.sql
[0m09:27:06.446981 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '803dbce3-c0f2-4b00-bb50-d3102188c3ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4A8EE7E00>]}
[0m09:27:06.447946 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model dp_dp_hub.products_staging ................ [[31mERROR[0m in 0.63s]
[0m09:27:06.449991 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.products_staging
[0m09:27:06.451946 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:27:06.456327 [debug] [MainThread]: Connection 'create_dataengineerproject-439609_dp_dp_hub' was properly closed.
[0m09:27:06.457327 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp' was properly closed.
[0m09:27:06.458329 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.products_staging' was properly closed.
[0m09:27:06.459323 [info ] [MainThread]: 
[0m09:27:06.461327 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 8.96 seconds (8.96s).
[0m09:27:06.462326 [debug] [MainThread]: Command end result
[0m09:27:06.596691 [info ] [MainThread]: 
[0m09:27:06.597692 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m09:27:06.598691 [info ] [MainThread]: 
[0m09:27:06.600691 [error] [MainThread]:   Database Error in model products_staging (dbt_data_pipeline/models\datahub\products_staging.sql)
  Syntax error: Unexpected ";" at [30:17]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\products_staging.sql
[0m09:27:06.602694 [info ] [MainThread]: 
[0m09:27:06.604946 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m09:27:06.607944 [debug] [MainThread]: Command `dbt run` failed at 09:27:06.607944 after 15.61 seconds
[0m09:27:06.609946 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C49D6C02F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C49D6C1C10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C4A69D3170>]}
[0m09:27:06.610945 [debug] [MainThread]: Flushing usage events
[0m09:27:28.252347 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020D2CEFC2F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020D2CAD9700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020D295E9880>]}


============================== 09:27:28.262867 | ec7d7b73-7734-407d-a28b-c0be0ad79cde ==============================
[0m09:27:28.262867 [info ] [MainThread]: Running with dbt=1.8.7
[0m09:27:28.263865 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run -s products_staging.sql --full-refresh', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m09:27:34.516140 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ec7d7b73-7734-407d-a28b-c0be0ad79cde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020D361C8320>]}
[0m09:27:34.602785 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ec7d7b73-7734-407d-a28b-c0be0ad79cde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020D363ACF50>]}
[0m09:27:34.602785 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m09:27:34.618403 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m09:27:35.017543 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:27:35.017543 [debug] [MainThread]: Partial parsing: updated file: dbt_data_pipeline://dbt_data_pipeline/models\datahub\products_staging.sql
[0m09:27:35.356301 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_data_pipeline.dataproducts
- models.dbt_data_pipeline.datalake
[0m09:27:35.371884 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ec7d7b73-7734-407d-a28b-c0be0ad79cde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020D37ECD700>]}
[0m09:27:35.556887 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ec7d7b73-7734-407d-a28b-c0be0ad79cde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020D37EE45F0>]}
[0m09:27:35.556887 [info ] [MainThread]: Found 5 models, 4 data tests, 3 sources, 484 macros
[0m09:27:35.556887 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ec7d7b73-7734-407d-a28b-c0be0ad79cde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020D37B89FA0>]}
[0m09:27:35.572510 [info ] [MainThread]: 
[0m09:27:35.572510 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:27:35.572510 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m09:27:35.572510 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:27:38.279653 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_hub'
[0m09:27:38.279653 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:27:38.463665 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_hub, now list_dataengineerproject-439609_dp)
[0m09:27:38.463665 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:27:38.865297 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ec7d7b73-7734-407d-a28b-c0be0ad79cde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020D37EBA690>]}
[0m09:27:38.865297 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:27:38.865297 [info ] [MainThread]: 
[0m09:27:38.880460 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.products_staging
[0m09:27:38.880460 [info ] [Thread-1 (]: 1 of 1 START sql view model dp_hub.products_staging ............................ [RUN]
[0m09:27:38.880460 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.products_staging'
[0m09:27:38.880460 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.products_staging
[0m09:27:38.896088 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.products_staging"
[0m09:27:38.896088 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.products_staging
[0m09:27:38.927376 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.products_staging"
[0m09:27:38.942960 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m09:27:38.942960 [debug] [Thread-1 (]: On model.dbt_data_pipeline.products_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.products_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_hub`.`products_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


WITH ranked_products AS (
    SELECT
        *,
        ROW_NUMBER() OVER (
            PARTITION BY product_sku
            ORDER BY _dp_ingestion_timestamp DESC
        ) AS row_num
    FROM `dataengineerproject-439609`.`dp_lake`.`products_normalized`
)

-- Sélectionner uniquement les enregistrements uniques les plus récents
SELECT
    _dp_ingestion_timestamp,
    product_sku,
    unit_amount,
    description,
    supplier

FROM
    ranked_products
WHERE
    row_num = 1;;


[0m09:27:39.181365 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:89bba1b8-5457-4239-90da-cf0d3577aa6e&page=queryresults
[0m09:27:39.181365 [debug] [Thread-1 (]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Syntax error: Unexpected ";" at [30:17]; reason: invalidQuery, location: query, message: Syntax error: Unexpected ";" at [30:17]')
[0m09:27:39.397064 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:188e4da7-1d6c-4398-b41d-017fc807ead0&page=queryresults
[0m09:27:39.397064 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:188e4da7-1d6c-4398-b41d-017fc807ead0&page=queryresults
[0m09:27:39.412624 [debug] [Thread-1 (]: Database Error in model products_staging (dbt_data_pipeline/models\datahub\products_staging.sql)
  Syntax error: Unexpected ";" at [30:17]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\products_staging.sql
[0m09:27:39.412624 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ec7d7b73-7734-407d-a28b-c0be0ad79cde', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020D2C711940>]}
[0m09:27:39.412624 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model dp_hub.products_staging ................... [[31mERROR[0m in 0.53s]
[0m09:27:39.412624 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.products_staging
[0m09:27:39.412624 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:27:39.412624 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m09:27:39.412624 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp' was properly closed.
[0m09:27:39.412624 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.products_staging' was properly closed.
[0m09:27:39.412624 [info ] [MainThread]: 
[0m09:27:39.428248 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 3.84 seconds (3.84s).
[0m09:27:39.428248 [debug] [MainThread]: Command end result
[0m09:27:39.544209 [info ] [MainThread]: 
[0m09:27:39.550718 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m09:27:39.550718 [info ] [MainThread]: 
[0m09:27:39.550718 [error] [MainThread]:   Database Error in model products_staging (dbt_data_pipeline/models\datahub\products_staging.sql)
  Syntax error: Unexpected ";" at [30:17]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\products_staging.sql
[0m09:27:39.550718 [info ] [MainThread]: 
[0m09:27:39.550718 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m09:27:39.550718 [debug] [MainThread]: Command `dbt run` failed at 09:27:39.550718 after 11.61 seconds
[0m09:27:39.550718 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020D2CB28EF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020D2CE2A930>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020D2CBAACC0>]}
[0m09:27:39.550718 [debug] [MainThread]: Flushing usage events
[0m09:28:02.335549 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173D0DC09E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173D01EB170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173CD559700>]}


============================== 09:28:02.342062 | 4f076049-f395-4291-b0f9-481cdb8e2180 ==============================
[0m09:28:02.342062 [info ] [MainThread]: Running with dbt=1.8.7
[0m09:28:02.342062 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run -s products_staging.sql --full-refresh', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m09:28:05.065542 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4f076049-f395-4291-b0f9-481cdb8e2180', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173DB90DBE0>]}
[0m09:28:05.181423 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4f076049-f395-4291-b0f9-481cdb8e2180', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173DB867380>]}
[0m09:28:05.181423 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m09:28:05.197044 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m09:28:05.598291 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m09:28:05.613916 [debug] [MainThread]: Partial parsing: updated file: dbt_data_pipeline://dbt_data_pipeline/models\datahub\products_staging.sql
[0m09:28:05.968218 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_data_pipeline.datalake
- models.dbt_data_pipeline.dataproducts
[0m09:28:05.983832 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4f076049-f395-4291-b0f9-481cdb8e2180', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173DB9AAD80>]}
[0m09:28:06.153200 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4f076049-f395-4291-b0f9-481cdb8e2180', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173DBDAC5C0>]}
[0m09:28:06.153200 [info ] [MainThread]: Found 5 models, 4 data tests, 3 sources, 484 macros
[0m09:28:06.153200 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4f076049-f395-4291-b0f9-481cdb8e2180', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173DBD68380>]}
[0m09:28:06.153200 [info ] [MainThread]: 
[0m09:28:06.153200 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m09:28:06.153200 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m09:28:06.153200 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:28:08.459016 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp'
[0m09:28:08.474685 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:28:08.875867 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp, now list_dataengineerproject-439609_dp_hub)
[0m09:28:08.875867 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m09:28:08.976213 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4f076049-f395-4291-b0f9-481cdb8e2180', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173DA1A02F0>]}
[0m09:28:08.976213 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m09:28:08.991191 [info ] [MainThread]: 
[0m09:28:08.991191 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.products_staging
[0m09:28:08.991191 [info ] [Thread-1 (]: 1 of 1 START sql view model dp_hub.products_staging ............................ [RUN]
[0m09:28:08.991191 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.products_staging'
[0m09:28:08.991191 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.products_staging
[0m09:28:09.006819 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.products_staging"
[0m09:28:09.006819 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.products_staging
[0m09:28:09.038076 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.products_staging"
[0m09:28:09.053701 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m09:28:09.053701 [debug] [Thread-1 (]: On model.dbt_data_pipeline.products_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.products_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_hub`.`products_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


WITH ranked_products AS (
    SELECT
        *,
        ROW_NUMBER() OVER (
            PARTITION BY product_sku
            ORDER BY _dp_ingestion_timestamp DESC
        ) AS row_num
    FROM `dataengineerproject-439609`.`dp_lake`.`products_normalized`
)

-- Sélectionner uniquement les enregistrements uniques les plus récents
SELECT
    _dp_ingestion_timestamp,
    product_sku,
    unit_amount,
    description,
    supplier

FROM
    ranked_products
WHERE
    row_num = 1;


[0m09:28:09.840490 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:e41696ce-042b-46d9-8c7d-c4efaf519a1b&page=queryresults
[0m09:28:10.109844 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4f076049-f395-4291-b0f9-481cdb8e2180', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173D9E79850>]}
[0m09:28:10.125482 [info ] [Thread-1 (]: 1 of 1 OK created sql view model dp_hub.products_staging ....................... [[32mCREATE VIEW (0 processed)[0m in 1.12s]
[0m09:28:10.125482 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.products_staging
[0m09:28:10.125482 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:28:10.125482 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m09:28:10.125482 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_hub' was properly closed.
[0m09:28:10.125482 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.products_staging' was properly closed.
[0m09:28:10.125482 [info ] [MainThread]: 
[0m09:28:10.125482 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 3.97 seconds (3.97s).
[0m09:28:10.125482 [debug] [MainThread]: Command end result
[0m09:28:10.241349 [info ] [MainThread]: 
[0m09:28:10.241349 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:28:10.241349 [info ] [MainThread]: 
[0m09:28:10.241349 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m09:28:10.256978 [debug] [MainThread]: Command `dbt run` succeeded at 09:28:10.256978 after 8.16 seconds
[0m09:28:10.256978 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173D0C0C710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173CE0953D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000173D0712AE0>]}
[0m09:28:10.256978 [debug] [MainThread]: Flushing usage events
[0m10:09:31.825078 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000131E228ECC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000131E228ED80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000131E228FFB0>]}


============================== 10:09:31.835159 | 7fab2a6f-efe0-4341-add9-6bf7af378d4a ==============================
[0m10:09:31.835159 [info ] [MainThread]: Running with dbt=1.8.7
[0m10:09:31.835159 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run -s customers_staging.sql --full-refresh', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:09:35.340063 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7fab2a6f-efe0-4341-add9-6bf7af378d4a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000131E29EB830>]}
[0m10:09:35.424707 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7fab2a6f-efe0-4341-add9-6bf7af378d4a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000131EBC05400>]}
[0m10:09:35.424707 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m10:09:35.440351 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m10:09:35.928468 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:09:35.928468 [debug] [MainThread]: Partial parsing: updated file: dbt_data_pipeline://dbt_data_pipeline/models\datahub\customers_staging.sql
[0m10:09:36.245031 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_data_pipeline.dataproducts
- models.dbt_data_pipeline.datalake
[0m10:09:36.260640 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7fab2a6f-efe0-4341-add9-6bf7af378d4a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000131EDAF5C40>]}
[0m10:09:36.445566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7fab2a6f-efe0-4341-add9-6bf7af378d4a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000131EDB31910>]}
[0m10:09:36.445566 [info ] [MainThread]: Found 5 models, 4 data tests, 3 sources, 484 macros
[0m10:09:36.445566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7fab2a6f-efe0-4341-add9-6bf7af378d4a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000131ED79C4A0>]}
[0m10:09:36.445566 [info ] [MainThread]: 
[0m10:09:36.445566 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:09:36.461192 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m10:09:36.461192 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:09:39.413835 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_hub'
[0m10:09:39.413835 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:09:39.552060 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_hub, now list_dataengineerproject-439609_dp)
[0m10:09:39.552060 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:09:40.024089 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7fab2a6f-efe0-4341-add9-6bf7af378d4a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000131ED79C6B0>]}
[0m10:09:40.039724 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:09:40.039724 [info ] [MainThread]: 
[0m10:09:40.039724 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.customers_staging
[0m10:09:40.039724 [info ] [Thread-1 (]: 1 of 1 START sql view model dp_hub.customers_staging ........................... [RUN]
[0m10:09:40.055353 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.customers_staging'
[0m10:09:40.055353 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.customers_staging
[0m10:09:40.055353 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.customers_staging"
[0m10:09:40.071016 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.customers_staging
[0m10:09:40.102272 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.customers_staging"
[0m10:09:40.102272 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:09:40.102272 [debug] [Thread-1 (]: On model.dbt_data_pipeline.customers_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.customers_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_hub`.`customers_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


WITH standardized_customers AS (
    SELECT
        *,
        -- Normalisation des numéros de téléphone
        ARRAY(
            SELECT REGEXP_REPLACE(phone_number, r'\D', '')  -- Supprimer tous les caractères non numériques
            FROM UNNEST(phone_numbers) AS phone_number
        ) AS standardized_phone_numbers,

        -- Normalisation des adresses e-mail (en minuscules pour consistance)
        ARRAY(
            SELECT LOWER(email)
            FROM UNNEST(emails) AS email
        ) AS standardized_emails
    FROM `dataengineerproject-439609`.`dp_lake`.`customers_normalized`
),

ranked_customers AS (
    SELECT
        *,
        ROW_NUMBER() OVER (
            PARTITION BY customer_id
            ORDER BY _dp_ingestion_timestamp DESC
        ) AS row_num
    FROM standardized_customers
)

-- Sélectionner uniquement les enregistrements uniques les plus récents
SELECT
    _dp_ingestion_timestamp,
    standardized_emails AS emails,
    standardized_phone_numbers AS phone_numbers,
    customer_id
FROM
    ranked_customers
WHERE
    row_num = 1;;


[0m10:09:40.325120 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:1362ad38-aa15-470a-be99-a6ec339fc59b&page=queryresults
[0m10:09:40.325120 [debug] [Thread-1 (]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Syntax error: Unexpected ";" at [45:17]; reason: invalidQuery, location: query, message: Syntax error: Unexpected ";" at [45:17]')
[0m10:09:40.541396 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:9141c991-45f5-47f2-937e-f8f46224a4f9&page=queryresults
[0m10:09:40.541396 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:9141c991-45f5-47f2-937e-f8f46224a4f9&page=queryresults
[0m10:09:40.556368 [debug] [Thread-1 (]: Database Error in model customers_staging (dbt_data_pipeline/models\datahub\customers_staging.sql)
  Syntax error: Unexpected ";" at [45:17]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\customers_staging.sql
[0m10:09:40.556368 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7fab2a6f-efe0-4341-add9-6bf7af378d4a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000131EDBAC770>]}
[0m10:09:40.556368 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model dp_hub.customers_staging .................. [[31mERROR[0m in 0.50s]
[0m10:09:40.556368 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.customers_staging
[0m10:09:40.556368 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:09:40.572010 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m10:09:40.572010 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp' was properly closed.
[0m10:09:40.572010 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.customers_staging' was properly closed.
[0m10:09:40.572010 [info ] [MainThread]: 
[0m10:09:40.572010 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 4.13 seconds (4.13s).
[0m10:09:40.572010 [debug] [MainThread]: Command end result
[0m10:09:40.703557 [info ] [MainThread]: 
[0m10:09:40.703557 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m10:09:40.703557 [info ] [MainThread]: 
[0m10:09:40.703557 [error] [MainThread]:   Database Error in model customers_staging (dbt_data_pipeline/models\datahub\customers_staging.sql)
  Syntax error: Unexpected ";" at [45:17]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\customers_staging.sql
[0m10:09:40.703557 [info ] [MainThread]: 
[0m10:09:40.703557 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m10:09:40.703557 [debug] [MainThread]: Command `dbt run` failed at 10:09:40.703557 after 9.49 seconds
[0m10:09:40.703557 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000131E225B710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000131DFD14710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000131EB6B00B0>]}
[0m10:09:40.703557 [debug] [MainThread]: Flushing usage events
[0m10:10:42.963305 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000199FF8CD3D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001998174EA80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001998252C9E0>]}


============================== 10:10:42.963305 | 311b7351-abeb-4926-bdf2-2961e0f55bcb ==============================
[0m10:10:42.963305 [info ] [MainThread]: Running with dbt=1.8.7
[0m10:10:42.963305 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run -s customers_staging.sql --full-refresh', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:10:45.639864 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '311b7351-abeb-4926-bdf2-2961e0f55bcb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000199826D5700>]}
[0m10:10:45.718039 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '311b7351-abeb-4926-bdf2-2961e0f55bcb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001998B9E46B0>]}
[0m10:10:45.718039 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m10:10:45.718039 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m10:10:46.103566 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:10:46.103566 [debug] [MainThread]: Partial parsing: updated file: dbt_data_pipeline://dbt_data_pipeline/models\datahub\customers_staging.sql
[0m10:10:46.404474 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_data_pipeline.dataproducts
- models.dbt_data_pipeline.datalake
[0m10:10:46.435721 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '311b7351-abeb-4926-bdf2-2961e0f55bcb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001998D4FB050>]}
[0m10:10:46.620678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '311b7351-abeb-4926-bdf2-2961e0f55bcb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001998D5286B0>]}
[0m10:10:46.620678 [info ] [MainThread]: Found 5 models, 4 data tests, 3 sources, 484 macros
[0m10:10:46.620678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '311b7351-abeb-4926-bdf2-2961e0f55bcb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001998D4F3DD0>]}
[0m10:10:46.636293 [info ] [MainThread]: 
[0m10:10:46.636293 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:10:46.642807 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m10:10:46.642807 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:10:49.080581 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp'
[0m10:10:49.080581 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:10:49.650953 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp, now list_dataengineerproject-439609_dp_hub)
[0m10:10:49.650953 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:10:49.751239 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '311b7351-abeb-4926-bdf2-2961e0f55bcb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001998D4F6B10>]}
[0m10:10:49.751239 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:10:49.766881 [info ] [MainThread]: 
[0m10:10:49.766881 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.customers_staging
[0m10:10:49.766881 [info ] [Thread-1 (]: 1 of 1 START sql view model dp_hub.customers_staging ........................... [RUN]
[0m10:10:49.766881 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.customers_staging'
[0m10:10:49.782502 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.customers_staging
[0m10:10:49.782502 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.customers_staging"
[0m10:10:49.782502 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.customers_staging
[0m10:10:49.813795 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.customers_staging"
[0m10:10:49.829387 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:10:49.829387 [debug] [Thread-1 (]: On model.dbt_data_pipeline.customers_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.customers_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_hub`.`customers_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


WITH standardized_customers AS (
    SELECT
        *,
        -- Normalisation des numéros de téléphone
        ARRAY(
            SELECT REGEXP_REPLACE(phone_number, r'\D', '')  -- Supprimer tous les caractères non numériques
            FROM UNNEST(phone_numbers) AS phone_number
        ) AS standardized_phone_numbers,

        -- Normalisation des adresses e-mail (en minuscules pour consistance)
        ARRAY(
            SELECT LOWER(email)
            FROM UNNEST(emails) AS email
        ) AS standardized_emails
    FROM `dataengineerproject-439609`.`dp_lake`.`customers_normalized`
),

ranked_customers AS (
    SELECT
        *,
        ROW_NUMBER() OVER (
            PARTITION BY customer_id
            ORDER BY _dp_ingestion_timestamp DESC
        ) AS row_num
    FROM standardized_customers
)

-- Sélectionner uniquement les enregistrements uniques les plus récents
SELECT
    _dp_ingestion_timestamp,
    standardized_emails AS emails,
    standardized_phone_numbers AS phone_numbers,
    customer_id
FROM
    ranked_customers
WHERE
    row_num = 1;


[0m10:10:50.670136 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:6df9c10e-1421-48c7-9edb-9e8bf48e6f9f&page=queryresults
[0m10:10:50.885750 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '311b7351-abeb-4926-bdf2-2961e0f55bcb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001998B5FA780>]}
[0m10:10:50.885750 [info ] [Thread-1 (]: 1 of 1 OK created sql view model dp_hub.customers_staging ...................... [[32mCREATE VIEW (0 processed)[0m in 1.12s]
[0m10:10:50.901326 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.customers_staging
[0m10:10:50.901326 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:10:50.901326 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m10:10:50.901326 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_hub' was properly closed.
[0m10:10:50.901326 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.customers_staging' was properly closed.
[0m10:10:50.901326 [info ] [MainThread]: 
[0m10:10:50.901326 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 4.27 seconds (4.27s).
[0m10:10:50.901326 [debug] [MainThread]: Command end result
[0m10:10:51.017310 [info ] [MainThread]: 
[0m10:10:51.017310 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:10:51.017310 [info ] [MainThread]: 
[0m10:10:51.017310 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m10:10:51.017310 [debug] [MainThread]: Command `dbt run` succeeded at 10:10:51.017310 after 8.32 seconds
[0m10:10:51.017310 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000199FF8CD3D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019981D4ADB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000199802945C0>]}
[0m10:10:51.017310 [debug] [MainThread]: Flushing usage events
[0m10:15:06.679910 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022856B342F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000228572FC3B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022857256BA0>]}


============================== 10:15:06.679910 | 617d388c-8800-436b-add9-8a87a804f081 ==============================
[0m10:15:06.679910 [info ] [MainThread]: Running with dbt=1.8.7
[0m10:15:06.679910 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run -s customers_staging.sql --full-refresh', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m10:15:10.310684 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '617d388c-8800-436b-add9-8a87a804f081', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022860479280>]}
[0m10:15:10.410529 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '617d388c-8800-436b-add9-8a87a804f081', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022860860E30>]}
[0m10:15:10.410529 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m10:15:10.426770 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m10:15:10.873067 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:15:10.873067 [debug] [MainThread]: Partial parsing: updated file: dbt_data_pipeline://dbt_data_pipeline/models\datahub\customers_staging.sql
[0m10:15:11.227063 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_data_pipeline.datalake
- models.dbt_data_pipeline.dataproducts
[0m10:15:11.242702 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '617d388c-8800-436b-add9-8a87a804f081', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022862371700>]}
[0m10:15:11.443296 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '617d388c-8800-436b-add9-8a87a804f081', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000228623AC4A0>]}
[0m10:15:11.443296 [info ] [MainThread]: Found 5 models, 4 data tests, 3 sources, 484 macros
[0m10:15:11.458924 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '617d388c-8800-436b-add9-8a87a804f081', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000228620683E0>]}
[0m10:15:11.458924 [info ] [MainThread]: 
[0m10:15:11.458924 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:15:11.458924 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m10:15:11.458924 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:15:14.904161 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp'
[0m10:15:14.904161 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:15:15.485326 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp, now list_dataengineerproject-439609_dp_hub)
[0m10:15:15.485326 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:15:15.623472 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '617d388c-8800-436b-add9-8a87a804f081', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002286203A720>]}
[0m10:15:15.623472 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:15:15.623472 [info ] [MainThread]: 
[0m10:15:15.639103 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.customers_staging
[0m10:15:15.639103 [info ] [Thread-1 (]: 1 of 1 START sql view model dp_hub.customers_staging ........................... [RUN]
[0m10:15:15.639103 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.customers_staging'
[0m10:15:15.639103 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.customers_staging
[0m10:15:15.654768 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.customers_staging"
[0m10:15:15.654768 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.customers_staging
[0m10:15:15.723787 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.customers_staging"
[0m10:15:15.723787 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:15:15.723787 [debug] [Thread-1 (]: On model.dbt_data_pipeline.customers_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.customers_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_hub`.`customers_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


WITH standardized_customers AS (
    SELECT
        *,
        -- Normalisation des numéros de téléphone
        ARRAY(
            SELECT
                CASE
                    WHEN REGEXP_CONTAINS(phone_number, r'^\+33') THEN REGEXP_REPLACE(phone_number, r'\D', '')  -- Garder tel quel mais supprimer les caractères non numériques si déjà avec +33
                    WHEN REGEXP_CONTAINS(phone_number, r'^0') THEN '+33' || SUBSTR(REGEXP_REPLACE(phone_number, r'\D', ''), 2)  -- Remplacer 0 par +33
                    ELSE phone_number  -- Pour tout autre format, garder tel quel (potentiellement à adapter pour d'autres cas)
                END AS standardized_phone_number
            FROM UNNEST(phone_numbers) AS phone_number
        ) AS standardized_phone_numbers,

        -- Normalisation des adresses e-mail (en minuscules pour consistance)
        ARRAY(
            SELECT LOWER(email)
            FROM UNNEST(emails) AS email
        ) AS standardized_emails
    FROM `dataengineerproject-439609`.`dp_lake`.`customers_normalized`
),

ranked_customers AS (
    SELECT
        *,
        ROW_NUMBER() OVER (
            PARTITION BY customer_id
            ORDER BY _dp_ingestion_timestamp DESC
        ) AS row_num
    FROM standardized_customers
)

-- Sélectionner uniquement les enregistrements uniques les plus récents
SELECT
    _dp_ingestion_timestamp,
    customer_id,
    standardized_emails AS emails,
    standardized_phone_numbers AS phone_numbers

FROM
    ranked_customers
WHERE
    row_num = 1;;


[0m10:15:15.993447 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:f2b65e83-4967-4265-985b-e39761f9703d&page=queryresults
[0m10:15:15.993447 [debug] [Thread-1 (]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Syntax error: Unexpected ";" at [51:17]; reason: invalidQuery, location: query, message: Syntax error: Unexpected ";" at [51:17]')
[0m10:15:16.612808 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:241284a7-1551-4b24-93e0-d5e7371d5678&page=queryresults
[0m10:15:16.612808 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:241284a7-1551-4b24-93e0-d5e7371d5678&page=queryresults
[0m10:15:16.643619 [debug] [Thread-1 (]: Database Error in model customers_staging (dbt_data_pipeline/models\datahub\customers_staging.sql)
  Syntax error: Unexpected ";" at [51:17]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\customers_staging.sql
[0m10:15:16.643619 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '617d388c-8800-436b-add9-8a87a804f081', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022862446450>]}
[0m10:15:16.643619 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model dp_hub.customers_staging .................. [[31mERROR[0m in 1.00s]
[0m10:15:16.643619 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.customers_staging
[0m10:15:16.643619 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:15:16.643619 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m10:15:16.643619 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_hub' was properly closed.
[0m10:15:16.643619 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.customers_staging' was properly closed.
[0m10:15:16.643619 [info ] [MainThread]: 
[0m10:15:16.643619 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 5.18 seconds (5.18s).
[0m10:15:16.659212 [debug] [MainThread]: Command end result
[0m10:15:16.775201 [info ] [MainThread]: 
[0m10:15:16.775201 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m10:15:16.775201 [info ] [MainThread]: 
[0m10:15:16.775201 [error] [MainThread]:   Database Error in model customers_staging (dbt_data_pipeline/models\datahub\customers_staging.sql)
  Syntax error: Unexpected ";" at [51:17]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\customers_staging.sql
[0m10:15:16.775201 [info ] [MainThread]: 
[0m10:15:16.775201 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m10:15:16.790817 [debug] [MainThread]: Command `dbt run` failed at 10:15:16.790817 after 10.66 seconds
[0m10:15:16.790817 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022856F20860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022856376570>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022856FABB30>]}
[0m10:15:16.790817 [debug] [MainThread]: Flushing usage events
[0m10:15:40.933158 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AED59BB3B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AED7C40170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AED7C41700>]}


============================== 10:15:40.933158 | 590c93b0-f3fe-44a7-a75d-e127da2f3d58 ==============================
[0m10:15:40.933158 [info ] [MainThread]: Running with dbt=1.8.7
[0m10:15:40.933158 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt run -s customers_staging.sql --full-refresh', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:15:43.823734 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '590c93b0-f3fe-44a7-a75d-e127da2f3d58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AEE2DFE2D0>]}
[0m10:15:43.908462 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '590c93b0-f3fe-44a7-a75d-e127da2f3d58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AEE2DC3470>]}
[0m10:15:43.908462 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m10:15:43.924039 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m10:15:44.409910 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:15:44.409910 [debug] [MainThread]: Partial parsing: updated file: dbt_data_pipeline://dbt_data_pipeline/models\datahub\customers_staging.sql
[0m10:15:44.741641 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_data_pipeline.datalake
- models.dbt_data_pipeline.dataproducts
[0m10:15:44.772852 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '590c93b0-f3fe-44a7-a75d-e127da2f3d58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AEE30647D0>]}
[0m10:15:44.942254 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '590c93b0-f3fe-44a7-a75d-e127da2f3d58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AEE337C380>]}
[0m10:15:44.942254 [info ] [MainThread]: Found 5 models, 4 data tests, 3 sources, 484 macros
[0m10:15:44.942254 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '590c93b0-f3fe-44a7-a75d-e127da2f3d58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AEE2FED490>]}
[0m10:15:44.942254 [info ] [MainThread]: 
[0m10:15:44.942254 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:15:44.957878 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m10:15:44.957878 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:15:47.647478 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_hub'
[0m10:15:47.647478 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:15:47.748375 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_hub, now list_dataengineerproject-439609_dp)
[0m10:15:47.763354 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:15:48.250960 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '590c93b0-f3fe-44a7-a75d-e127da2f3d58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AEE2C66090>]}
[0m10:15:48.250960 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:15:48.250960 [info ] [MainThread]: 
[0m10:15:48.265970 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.customers_staging
[0m10:15:48.265970 [info ] [Thread-1 (]: 1 of 1 START sql view model dp_hub.customers_staging ........................... [RUN]
[0m10:15:48.265970 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.customers_staging'
[0m10:15:48.265970 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.customers_staging
[0m10:15:48.265970 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.customers_staging"
[0m10:15:48.281563 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.customers_staging
[0m10:15:48.303790 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.customers_staging"
[0m10:15:48.319468 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:15:48.319468 [debug] [Thread-1 (]: On model.dbt_data_pipeline.customers_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.customers_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_hub`.`customers_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


WITH standardized_customers AS (
    SELECT
        *,
        -- Normalisation des numéros de téléphone
        ARRAY(
            SELECT
                CASE
                    WHEN REGEXP_CONTAINS(phone_number, r'^\+33') THEN REGEXP_REPLACE(phone_number, r'\D', '')  -- Garder tel quel mais supprimer les caractères non numériques si déjà avec +33
                    WHEN REGEXP_CONTAINS(phone_number, r'^0') THEN '+33' || SUBSTR(REGEXP_REPLACE(phone_number, r'\D', ''), 2)  -- Remplacer 0 par +33
                    ELSE phone_number  -- Pour tout autre format, garder tel quel (potentiellement à adapter pour d'autres cas)
                END AS standardized_phone_number
            FROM UNNEST(phone_numbers) AS phone_number
        ) AS standardized_phone_numbers,

        -- Normalisation des adresses e-mail (en minuscules pour consistance)
        ARRAY(
            SELECT LOWER(email)
            FROM UNNEST(emails) AS email
        ) AS standardized_emails
    FROM `dataengineerproject-439609`.`dp_lake`.`customers_normalized`
),

ranked_customers AS (
    SELECT
        *,
        ROW_NUMBER() OVER (
            PARTITION BY customer_id
            ORDER BY _dp_ingestion_timestamp DESC
        ) AS row_num
    FROM standardized_customers
)

-- Sélectionner uniquement les enregistrements uniques les plus récents
SELECT
    _dp_ingestion_timestamp,
    customer_id,
    standardized_emails AS emails,
    standardized_phone_numbers AS phone_numbers

FROM
    ranked_customers
WHERE
    row_num = 1;


[0m10:15:48.667386 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:a13db36e-e333-434e-98eb-acb3a678d210&page=queryresults
[0m10:15:48.883052 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '590c93b0-f3fe-44a7-a75d-e127da2f3d58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AEE1449D90>]}
[0m10:15:48.883052 [info ] [Thread-1 (]: 1 of 1 OK created sql view model dp_hub.customers_staging ...................... [[32mCREATE VIEW (0 processed)[0m in 0.62s]
[0m10:15:48.883052 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.customers_staging
[0m10:15:48.883052 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:15:48.883052 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m10:15:48.898675 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp' was properly closed.
[0m10:15:48.898675 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.customers_staging' was properly closed.
[0m10:15:48.898675 [info ] [MainThread]: 
[0m10:15:48.898675 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 3.96 seconds (3.96s).
[0m10:15:48.898675 [debug] [MainThread]: Command end result
[0m10:15:49.005547 [info ] [MainThread]: 
[0m10:15:49.021196 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:15:49.021196 [info ] [MainThread]: 
[0m10:15:49.021196 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m10:15:49.021196 [debug] [MainThread]: Command `dbt run` succeeded at 10:15:49.021196 after 8.36 seconds
[0m10:15:49.021196 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AED80430B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AED7911A30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AEE3347380>]}
[0m10:15:49.021196 [debug] [MainThread]: Flushing usage events
[0m10:19:37.645064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5BD20C2F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5BAA8B3E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5BD413920>]}


============================== 10:19:37.660688 | b8c73dde-dfaa-4bbb-be09-8364df2d033b ==============================
[0m10:19:37.660688 [info ] [MainThread]: Running with dbt=1.8.7
[0m10:19:37.660688 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run -s customers_staging.sql --full-refresh', 'send_anonymous_usage_stats': 'True'}
[0m10:19:42.878154 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b8c73dde-dfaa-4bbb-be09-8364df2d033b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5C64C9070>]}
[0m10:19:42.986120 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b8c73dde-dfaa-4bbb-be09-8364df2d033b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5C541AD80>]}
[0m10:19:42.986120 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m10:19:43.017371 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m10:19:43.627464 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:19:43.627464 [debug] [MainThread]: Partial parsing: updated file: dbt_data_pipeline://dbt_data_pipeline/models\datahub\customers_staging.sql
[0m10:19:44.152098 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_data_pipeline.datalake
- models.dbt_data_pipeline.dataproducts
[0m10:19:44.167748 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b8c73dde-dfaa-4bbb-be09-8364df2d033b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5C80389E0>]}
[0m10:19:44.437311 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b8c73dde-dfaa-4bbb-be09-8364df2d033b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5C83FC650>]}
[0m10:19:44.437311 [info ] [MainThread]: Found 5 models, 4 data tests, 3 sources, 484 macros
[0m10:19:44.437311 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b8c73dde-dfaa-4bbb-be09-8364df2d033b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5C83C1BB0>]}
[0m10:19:44.437311 [info ] [MainThread]: 
[0m10:19:44.437311 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:19:44.437311 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m10:19:44.452939 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:19:49.673416 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp'
[0m10:19:49.677320 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:19:50.243539 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp, now list_dataengineerproject-439609_dp_hub)
[0m10:19:50.244539 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:19:50.443444 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b8c73dde-dfaa-4bbb-be09-8364df2d033b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5C83C2A20>]}
[0m10:19:50.445444 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:19:50.446444 [info ] [MainThread]: 
[0m10:19:50.460408 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.customers_staging
[0m10:19:50.462404 [info ] [Thread-1 (]: 1 of 1 START sql view model dp_hub.customers_staging ........................... [RUN]
[0m10:19:50.465406 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.customers_staging'
[0m10:19:50.466404 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.customers_staging
[0m10:19:50.487210 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.customers_staging"
[0m10:19:50.497616 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.customers_staging
[0m10:19:50.649184 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.customers_staging"
[0m10:19:50.655186 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:19:50.658916 [debug] [Thread-1 (]: On model.dbt_data_pipeline.customers_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.customers_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_hub`.`customers_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


WITH standardized_customers AS (
    SELECT
        *,
        -- Normalisation des numéros de téléphone pour inclure toujours le préfixe +33
        ARRAY(
            SELECT
                CASE
                    WHEN REGEXP_CONTAINS(phone_number, r'^\+33') THEN REGEXP_REPLACE(phone_number, r'\D', '')  -- Supprimer les caractères non numériques si déjà au format international
                    WHEN REGEXP_CONTAINS(phone_number, r'^0') THEN '+33' || SUBSTR(REGEXP_REPLACE(phone_number, r'\D', ''), 2)  -- Remplacer 0 par +33
                    ELSE phone_number  -- Pour tout autre format, garder tel quel (à adapter si nécessaire)
                END AS phone_number_with_country_code
            FROM UNNEST(phone_numbers) AS phone_number
        ) AS standardized_phone_numbers,

        -- Ajouter le symbole + au début pour tous les numéros qui commencent par 33
        ARRAY(
            SELECT
                CASE
                    WHEN REGEXP_CONTAINS(phone_number_with_country_code, r'^33') THEN '+33' || SUBSTR(phone_number_with_country_code, 3)  -- Ajouter le préfixe + si absent
                    ELSE phone_number_with_country_code
                END
            FROM UNNEST(standardized_phone_numbers) AS phone_number_with_country_code
        ) AS final_phone_numbers,

        -- Normalisation des adresses e-mail (en minuscules pour consistance)
        ARRAY(
            SELECT LOWER(email)
            FROM UNNEST(emails) AS email
        ) AS standardized_emails
    FROM `dataengineerproject-439609`.`dp_lake`.`customers_normalized`
),

ranked_customers AS (
    SELECT
        *,
        ROW_NUMBER() OVER (
            PARTITION BY customer_id
            ORDER BY _dp_ingestion_timestamp DESC
        ) AS row_num
    FROM standardized_customers
)

-- Sélectionner uniquement les enregistrements uniques les plus récents
SELECT
    _dp_ingestion_timestamp,
    customer_id,
    standardized_emails AS emails,
    final_phone_numbers AS phone_numbers
FROM
    ranked_customers
WHERE
    row_num = 1;


[0m10:19:51.059871 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:170b0b8f-eb25-4bc1-bfaa-0fbb004fe950&page=queryresults
[0m10:19:51.161155 [debug] [Thread-1 (]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: standardized_phone_numbers at [30:25]; reason: invalidQuery, location: query, message: Unrecognized name: standardized_phone_numbers at [30:25]')
[0m10:19:52.182058 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:c5bdfc0c-5b89-4ce6-9df0-b88d988aa314&page=queryresults
[0m10:19:52.282856 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:c5bdfc0c-5b89-4ce6-9df0-b88d988aa314&page=queryresults
[0m10:19:52.308572 [debug] [Thread-1 (]: Database Error in model customers_staging (dbt_data_pipeline/models\datahub\customers_staging.sql)
  Unrecognized name: standardized_phone_numbers at [30:25]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\customers_staging.sql
[0m10:19:52.312567 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b8c73dde-dfaa-4bbb-be09-8364df2d033b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5C7FA57C0>]}
[0m10:19:52.314568 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model dp_hub.customers_staging .................. [[31mERROR[0m in 1.85s]
[0m10:19:52.317570 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.customers_staging
[0m10:19:52.323824 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:19:52.326826 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m10:19:52.327825 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_hub' was properly closed.
[0m10:19:52.329824 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.customers_staging' was properly closed.
[0m10:19:52.332825 [info ] [MainThread]: 
[0m10:19:52.334825 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 7.89 seconds (7.89s).
[0m10:19:52.337825 [debug] [MainThread]: Command end result
[0m10:19:52.843734 [info ] [MainThread]: 
[0m10:19:52.858557 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m10:19:52.860555 [info ] [MainThread]: 
[0m10:19:52.861558 [error] [MainThread]:   Database Error in model customers_staging (dbt_data_pipeline/models\datahub\customers_staging.sql)
  Unrecognized name: standardized_phone_numbers at [30:25]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\customers_staging.sql
[0m10:19:52.881093 [info ] [MainThread]: 
[0m10:19:52.883093 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m10:19:52.888093 [debug] [MainThread]: Command `dbt run` failed at 10:19:52.887094 after 15.61 seconds
[0m10:19:52.893838 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5BD1A8EF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5BD0692B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B5BD06BF80>]}
[0m10:19:52.898839 [debug] [MainThread]: Flushing usage events
[0m10:30:42.611335 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D96B34C770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D96DE53170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D96D33E6C0>]}


============================== 10:30:42.633517 | 20164134-9590-486e-a99a-a14479e50c04 ==============================
[0m10:30:42.633517 [info ] [MainThread]: Running with dbt=1.8.7
[0m10:30:42.633517 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run -s customers_staging.sql --full-refresh', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m10:30:51.251403 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '20164134-9590-486e-a99a-a14479e50c04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D976F55D60>]}
[0m10:30:51.338110 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '20164134-9590-486e-a99a-a14479e50c04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D978A588F0>]}
[0m10:30:51.338110 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m10:30:51.366704 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m10:30:52.206463 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:30:52.206463 [debug] [MainThread]: Partial parsing: updated file: dbt_data_pipeline://dbt_data_pipeline/models\datahub\customers_staging.sql
[0m10:30:52.544615 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_data_pipeline.datalake
- models.dbt_data_pipeline.dataproducts
[0m10:30:52.575862 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '20164134-9590-486e-a99a-a14479e50c04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D978DA4290>]}
[0m10:30:52.861397 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '20164134-9590-486e-a99a-a14479e50c04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D978EF8710>]}
[0m10:30:52.861397 [info ] [MainThread]: Found 5 models, 4 data tests, 3 sources, 484 macros
[0m10:30:52.861397 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '20164134-9590-486e-a99a-a14479e50c04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D978EA1AF0>]}
[0m10:30:52.861397 [info ] [MainThread]: 
[0m10:30:52.861397 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:30:52.861397 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m10:30:52.861397 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:30:58.192729 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp'
[0m10:30:58.192729 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:30:58.709493 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp, now list_dataengineerproject-439609_dp_hub)
[0m10:30:58.709493 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:30:58.831106 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '20164134-9590-486e-a99a-a14479e50c04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D978AA45F0>]}
[0m10:30:58.831106 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:30:58.831106 [info ] [MainThread]: 
[0m10:30:58.846979 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.customers_staging
[0m10:30:58.846979 [info ] [Thread-1 (]: 1 of 1 START sql view model dp_hub.customers_staging ........................... [RUN]
[0m10:30:58.846979 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.customers_staging'
[0m10:30:58.846979 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.customers_staging
[0m10:30:58.862422 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.customers_staging"
[0m10:30:58.862422 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.customers_staging
[0m10:30:58.893627 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.customers_staging"
[0m10:30:58.909310 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:30:58.909310 [debug] [Thread-1 (]: On model.dbt_data_pipeline.customers_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.customers_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_hub`.`customers_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


WITH standardized_customers AS (
    SELECT
        *,
        -- Normalisation des numéros de téléphone
        ARRAY(
            SELECT
                CASE
                    WHEN REGEXP_CONTAINS(phone_number, r'^\+33') THEN phone_number
                    WHEN REGEXP_CONTAINS(phone_number, r'^0') THEN '+33' || SUBSTR(REGEXP_REPLACE(phone_number, r'\D', ''), 2)  -- Remplacer 0 par +33
                    ELSE phone_number  -- Pour tout autre format, garder tel quel (potentiellement à adapter pour d'autres cas)
                END AS standardized_phone_number
            FROM UNNEST(phone_numbers) AS phone_number
        ) AS standardized_phone_numbers,

        -- Normalisation des adresses e-mail (en minuscules pour consistance)
        ARRAY(
            SELECT LOWER(email)
            FROM UNNEST(emails) AS email
        ) AS standardized_emails
    FROM `dataengineerproject-439609`.`dp_lake`.`customers_normalized`
),

ranked_customers AS (
    SELECT
        *,
        ROW_NUMBER() OVER (
            PARTITION BY customer_id
            ORDER BY _dp_ingestion_timestamp DESC
        ) AS row_num
    FROM standardized_customers
)

-- Sélectionner uniquement les enregistrements uniques les plus récents
SELECT
    _dp_ingestion_timestamp,
    customer_id,
    standardized_emails AS emails,
    standardized_phone_numbers AS phone_numbers

FROM
    ranked_customers
WHERE
    row_num = 1;


[0m10:30:59.224724 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:5043b4cb-794f-4eaf-b49a-b5f02658e56d&page=queryresults
[0m10:30:59.447919 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '20164134-9590-486e-a99a-a14479e50c04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D976FC9D00>]}
[0m10:30:59.447919 [info ] [Thread-1 (]: 1 of 1 OK created sql view model dp_hub.customers_staging ...................... [[32mCREATE VIEW (0 processed)[0m in 0.60s]
[0m10:30:59.463497 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.customers_staging
[0m10:30:59.463497 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:30:59.463497 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m10:30:59.463497 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_hub' was properly closed.
[0m10:30:59.463497 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.customers_staging' was properly closed.
[0m10:30:59.463497 [info ] [MainThread]: 
[0m10:30:59.463497 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 6.60 seconds (6.60s).
[0m10:30:59.463497 [debug] [MainThread]: Command end result
[0m10:30:59.595039 [info ] [MainThread]: 
[0m10:30:59.595039 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:30:59.595039 [info ] [MainThread]: 
[0m10:30:59.595039 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m10:30:59.595039 [debug] [MainThread]: Command `dbt run` succeeded at 10:30:59.595039 after 17.35 seconds
[0m10:30:59.595039 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D96D6B1A30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D976793050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D96EA8B350>]}
[0m10:30:59.595039 [debug] [MainThread]: Flushing usage events
[0m10:36:32.899492 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000168FBF98920>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000168FE9B00E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000168FE9B2420>]}


============================== 10:36:32.915126 | d32a663e-e465-4dd7-91f4-fff9904dd507 ==============================
[0m10:36:32.915126 [info ] [MainThread]: Running with dbt=1.8.7
[0m10:36:32.915126 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run -s sales_staging.sql --full-refresh', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m10:36:36.287894 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd32a663e-e465-4dd7-91f4-fff9904dd507', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000168FEA34D40>]}
[0m10:36:36.372560 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd32a663e-e465-4dd7-91f4-fff9904dd507', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000168FF728860>]}
[0m10:36:36.372560 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m10:36:36.388189 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m10:36:36.811491 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:36:36.811491 [debug] [MainThread]: Partial parsing: updated file: dbt_data_pipeline://dbt_data_pipeline/models\datahub\sales_staging.sql
[0m10:36:37.128014 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_data_pipeline.dataproducts
- models.dbt_data_pipeline.datalake
[0m10:36:37.143635 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd32a663e-e465-4dd7-91f4-fff9904dd507', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001688A9D5130>]}
[0m10:36:37.359678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd32a663e-e465-4dd7-91f4-fff9904dd507', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001688A9CBF80>]}
[0m10:36:37.359678 [info ] [MainThread]: Found 5 models, 4 data tests, 3 sources, 484 macros
[0m10:36:37.359678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd32a663e-e465-4dd7-91f4-fff9904dd507', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001688A45A720>]}
[0m10:36:37.359678 [info ] [MainThread]: 
[0m10:36:37.359678 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:36:37.375293 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m10:36:37.375293 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:36:40.421231 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp'
[0m10:36:40.421231 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:36:40.838301 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp, now list_dataengineerproject-439609_dp_hub)
[0m10:36:40.838301 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:36:40.970003 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd32a663e-e465-4dd7-91f4-fff9904dd507', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000168FD4CD670>]}
[0m10:36:40.970003 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:36:40.970003 [info ] [MainThread]: 
[0m10:36:40.985052 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.sales_staging
[0m10:36:40.985052 [info ] [Thread-1 (]: 1 of 1 START sql view model dp_hub.sales_staging ............................... [RUN]
[0m10:36:40.985052 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.sales_staging'
[0m10:36:40.985052 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.sales_staging
[0m10:36:40.985052 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.sales_staging"
[0m10:36:41.000707 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.sales_staging
[0m10:36:41.038475 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.sales_staging"
[0m10:36:41.038475 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:36:41.038475 [debug] [Thread-1 (]: On model.dbt_data_pipeline.sales_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.sales_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_hub`.`sales_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


WITH sales_cleaned AS (

    -- Sélectionner les ventes les plus récentes pour chaque ID, en évitant les doublons
    SELECT
        DISTINCT id,
        customer_id,
        total_amount,
        datetime,
        ARRAY(
            SELECT AS STRUCT
                SAFE_CAST(items.amount AS FLOAT64) AS amount,
                SAFE_CAST(items.quantity AS INT64) AS quantity,
                SAFE_CAST(items.product_sku AS STRING) AS product_sku
            FROM UNNEST(REGEXP_EXTRACT_ALL(sales_normalized.items, r'(\{.*?\})')) AS items
        ) AS items,
        _dp_ingestion_timestamp
    FROM `dataengineerproject-439609`.`dp_lake`.`sales_normalized`
    QUALIFY ROW_NUMBER() OVER (PARTITION BY id ORDER BY _dp_ingestion_timestamp DESC) = 1

),

sales_flat AS (
    -- Déplier les articles pour obtenir une ligne par article (flattening)
    SELECT
        sales.id AS sale_id,
        sales.customer_id,
        sales.total_amount,
        sales.datetime,
        items.amount AS item_amount,;


[0m10:36:41.239767 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:d51ec094-caa8-446a-9c5e-13e3463230ea&page=queryresults
[0m10:36:41.239767 [debug] [Thread-1 (]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Syntax error: Expected ")" but got ";" at [37:37]; reason: invalidQuery, location: query, message: Syntax error: Expected ")" but got ";" at [37:37]')
[0m10:36:42.004283 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:90607e63-165f-454a-8f29-b6f1911c13b2&page=queryresults
[0m10:36:42.004283 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:90607e63-165f-454a-8f29-b6f1911c13b2&page=queryresults
[0m10:36:42.273328 [debug] [Thread-1 (]: Database Error in model sales_staging (dbt_data_pipeline/models\datahub\sales_staging.sql)
  Syntax error: Expected ")" but got ";" at [37:37]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\sales_staging.sql
[0m10:36:42.273328 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd32a663e-e465-4dd7-91f4-fff9904dd507', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001688AAA47A0>]}
[0m10:36:42.273328 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model dp_hub.sales_staging ...................... [[31mERROR[0m in 1.29s]
[0m10:36:42.273328 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.sales_staging
[0m10:36:42.288969 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:36:42.288969 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m10:36:42.288969 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_hub' was properly closed.
[0m10:36:42.288969 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.sales_staging' was properly closed.
[0m10:36:42.288969 [info ] [MainThread]: 
[0m10:36:42.288969 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 4.93 seconds (4.93s).
[0m10:36:42.288969 [debug] [MainThread]: Command end result
[0m10:36:42.404917 [info ] [MainThread]: 
[0m10:36:42.404917 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m10:36:42.404917 [info ] [MainThread]: 
[0m10:36:42.404917 [error] [MainThread]:   Database Error in model sales_staging (dbt_data_pipeline/models\datahub\sales_staging.sql)
  Syntax error: Expected ")" but got ";" at [37:37]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\sales_staging.sql
[0m10:36:42.404917 [info ] [MainThread]: 
[0m10:36:42.404917 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m10:36:42.404917 [debug] [MainThread]: Command `dbt run` failed at 10:36:42.404917 after 10.10 seconds
[0m10:36:42.404917 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000168FF593320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000168FF593170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000168F99B28A0>]}
[0m10:36:42.404917 [debug] [MainThread]: Flushing usage events
[0m10:39:49.795724 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029F1F07B4A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029F21073320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029F21A03890>]}


============================== 10:39:49.811342 | 3424b7a0-a0a9-4ca0-b19c-f755fd454f24 ==============================
[0m10:39:49.811342 [info ] [MainThread]: Running with dbt=1.8.7
[0m10:39:49.811342 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt run -s sales_staging.sql --full-refresh', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:39:53.566817 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3424b7a0-a0a9-4ca0-b19c-f755fd454f24', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029F2C39FB00>]}
[0m10:39:53.635867 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3424b7a0-a0a9-4ca0-b19c-f755fd454f24', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029F2104C980>]}
[0m10:39:53.635867 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m10:39:53.651484 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m10:39:54.121373 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:39:54.121373 [debug] [MainThread]: Partial parsing: updated file: dbt_data_pipeline://dbt_data_pipeline/models\datahub\sales_staging.sql
[0m10:39:54.530735 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_data_pipeline.datalake
- models.dbt_data_pipeline.dataproducts
[0m10:39:54.540751 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3424b7a0-a0a9-4ca0-b19c-f755fd454f24', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029F2CA819D0>]}
[0m10:39:54.756928 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3424b7a0-a0a9-4ca0-b19c-f755fd454f24', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029F2CAB5580>]}
[0m10:39:54.756928 [info ] [MainThread]: Found 5 models, 4 data tests, 3 sources, 484 macros
[0m10:39:54.756928 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3424b7a0-a0a9-4ca0-b19c-f755fd454f24', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029F2C417EF0>]}
[0m10:39:54.756928 [info ] [MainThread]: 
[0m10:39:54.756928 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:39:54.756928 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m10:39:54.756928 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:39:57.762421 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_hub'
[0m10:39:57.762421 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:39:57.962965 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_hub, now list_dataengineerproject-439609_dp)
[0m10:39:57.962965 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:39:58.365474 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3424b7a0-a0a9-4ca0-b19c-f755fd454f24', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029F2AC29AC0>]}
[0m10:39:58.365474 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:39:58.365474 [info ] [MainThread]: 
[0m10:39:58.380456 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.sales_staging
[0m10:39:58.380456 [info ] [Thread-1 (]: 1 of 1 START sql view model dp_hub.sales_staging ............................... [RUN]
[0m10:39:58.380456 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.sales_staging'
[0m10:39:58.380456 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.sales_staging
[0m10:39:58.396079 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.sales_staging"
[0m10:39:58.396079 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.sales_staging
[0m10:39:58.449473 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.sales_staging"
[0m10:39:58.449473 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:39:58.449473 [debug] [Thread-1 (]: On model.dbt_data_pipeline.sales_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.sales_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_hub`.`sales_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


WITH deduplicated_sales AS (
    -- Sélectionner uniquement les enregistrements ingérés au cours de la dernière heure
    SELECT
        customer_id,
        total_amount,
        datetime,
        id,
        _dp_ingestion_timestamp,
        items
    FROM `dataengineerproject-439609`.`dp_lake`.`sales_normalized`
    WHERE _dp_ingestion_timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR)

    -- Dédupliquer les enregistrements basés sur l'ID de la vente
    QUALIFY ROW_NUMBER() OVER (PARTITION BY id ORDER BY _dp_ingestion_timestamp DESC) = 1
)

-- Flatten les enregistrements des items pour chaque vente
SELECT
    ds.customer_id,
    ds.total_amount,
    ds.datetime,
    ds.id,
    ds._dp_ingestion_timestamp,
    item.amount AS item_amount,
    item.quantity AS item_quantity,
    item.product_sku AS item_product_sku
FROM
    deduplicated_sales AS ds,
    UNNEST((
        SELECT ARRAY(
            SELECT AS STRUCT
                CAST(item.amount AS FLOAT64) AS amount,
                CAST(item.quantity AS INT64) AS quantity,
                item.product_sku
            FROM UNNEST(TRY_PARSE_JSON(items)['items']) AS item
        )
    )) AS item;


[0m10:39:58.782117 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:d9acfe41-7d15-4876-8c31-00a9a4895833&page=queryresults
[0m10:39:58.883098 [debug] [Thread-1 (]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Function not found: TRY_PARSE_JSON at [43:25]; reason: invalidQuery, location: query, message: Function not found: TRY_PARSE_JSON at [43:25]')
[0m10:39:59.499490 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:6021b99e-48ce-4f44-a53e-6d68cc508150&page=queryresults
[0m10:39:59.600033 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:6021b99e-48ce-4f44-a53e-6d68cc508150&page=queryresults
[0m10:39:59.615442 [debug] [Thread-1 (]: Database Error in model sales_staging (dbt_data_pipeline/models\datahub\sales_staging.sql)
  Function not found: TRY_PARSE_JSON at [43:25]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\sales_staging.sql
[0m10:39:59.615442 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3424b7a0-a0a9-4ca0-b19c-f755fd454f24', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029F2128D970>]}
[0m10:39:59.615442 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model dp_hub.sales_staging ...................... [[31mERROR[0m in 1.23s]
[0m10:39:59.615442 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.sales_staging
[0m10:39:59.631100 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:39:59.631100 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m10:39:59.631100 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp' was properly closed.
[0m10:39:59.631100 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.sales_staging' was properly closed.
[0m10:39:59.631100 [info ] [MainThread]: 
[0m10:39:59.631100 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 4.87 seconds (4.87s).
[0m10:39:59.631100 [debug] [MainThread]: Command end result
[0m10:39:59.769219 [info ] [MainThread]: 
[0m10:39:59.769219 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m10:39:59.769219 [info ] [MainThread]: 
[0m10:39:59.769219 [error] [MainThread]:   Database Error in model sales_staging (dbt_data_pipeline/models\datahub\sales_staging.sql)
  Function not found: TRY_PARSE_JSON at [43:25]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\sales_staging.sql
[0m10:39:59.769219 [info ] [MainThread]: 
[0m10:39:59.769219 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m10:39:59.784887 [debug] [MainThread]: Command `dbt run` failed at 10:39:59.784887 after 10.41 seconds
[0m10:39:59.784887 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029F20BFEA80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029F213518B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029F1E18BBF0>]}
[0m10:39:59.784887 [debug] [MainThread]: Flushing usage events
[0m10:41:22.308026 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021867E7B170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021867EB09B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218682491C0>]}


============================== 10:41:22.318265 | a5765f8d-5602-4e70-86c3-86999e21446d ==============================
[0m10:41:22.318265 [info ] [MainThread]: Running with dbt=1.8.7
[0m10:41:22.320327 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run -s sales_staging.sql --full-refresh', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:41:25.529426 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a5765f8d-5602-4e70-86c3-86999e21446d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002187019B680>]}
[0m10:41:25.598447 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a5765f8d-5602-4e70-86c3-86999e21446d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002187129ADE0>]}
[0m10:41:25.598447 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m10:41:25.614130 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m10:41:26.173071 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:41:26.181119 [debug] [MainThread]: Partial parsing: updated file: dbt_data_pipeline://dbt_data_pipeline/models\datahub\sales_staging.sql
[0m10:41:26.720007 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_data_pipeline.datalake
- models.dbt_data_pipeline.dataproducts
[0m10:41:26.730016 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a5765f8d-5602-4e70-86c3-86999e21446d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021873181760>]}
[0m10:41:26.930573 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a5765f8d-5602-4e70-86c3-86999e21446d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000218731BC2C0>]}
[0m10:41:26.930573 [info ] [MainThread]: Found 5 models, 4 data tests, 3 sources, 484 macros
[0m10:41:26.930573 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a5765f8d-5602-4e70-86c3-86999e21446d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021873182960>]}
[0m10:41:26.930573 [info ] [MainThread]: 
[0m10:41:26.930573 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:41:26.946215 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m10:41:26.946215 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:41:29.717529 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_hub'
[0m10:41:29.717529 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:41:29.833807 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_hub, now list_dataengineerproject-439609_dp)
[0m10:41:29.839825 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:41:30.422292 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a5765f8d-5602-4e70-86c3-86999e21446d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021873179730>]}
[0m10:41:30.422292 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:41:30.422292 [info ] [MainThread]: 
[0m10:41:30.444053 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.sales_staging
[0m10:41:30.444053 [info ] [Thread-1 (]: 1 of 1 START sql view model dp_hub.sales_staging ............................... [RUN]
[0m10:41:30.444053 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.sales_staging'
[0m10:41:30.444053 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.sales_staging
[0m10:41:30.459695 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.sales_staging"
[0m10:41:30.459695 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.sales_staging
[0m10:41:30.492781 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.sales_staging"
[0m10:41:30.492781 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:41:30.492781 [debug] [Thread-1 (]: On model.dbt_data_pipeline.sales_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.sales_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_hub`.`sales_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


WITH deduplicated_sales AS (
    -- Sélectionner uniquement les enregistrements ingérés au cours de la dernière heure
    SELECT
        customer_id,
        total_amount,
        datetime,
        id,
        _dp_ingestion_timestamp,
        items
    FROM `dataengineerproject-439609`.`dp_lake`.`sales_normalized`
    WHERE _dp_ingestion_timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR)

    -- Dédupliquer les enregistrements basés sur l'ID de la vente
    QUALIFY ROW_NUMBER() OVER (PARTITION BY id ORDER BY _dp_ingestion_timestamp DESC) = 1
)

-- Flatten les enregistrements des items pour chaque vente
SELECT
    ds.customer_id,
    ds.total_amount,
    ds.datetime,
    ds.id,
    ds._dp_ingestion_timestamp,
    item.amount AS item_amount,
    item.quantity AS item_quantity,
    item.product_sku AS item_product_sku
FROM
    deduplicated_sales AS ds,
    UNNEST((
        SELECT ARRAY(
            SELECT AS STRUCT
                CAST(item.amount AS FLOAT64) AS amount,
                CAST(item.quantity AS INT64) AS quantity,
                item.product_sku
            FROM UNNEST(SAFE.PARSE_JSON(items)['items']) AS item
        )
    )) AS item;


[0m10:41:30.838655 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:c8f57083-7ce2-4d60-9d13-9c088c4f28a4&page=queryresults
[0m10:41:30.945255 [debug] [Thread-1 (]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('No matching signature for function PARSE_JSON for argument types: ARRAY<STRUCT<amount FLOAT64, quantity INT64, product_sku STRING>>. Supported signature: PARSE_JSON(STRING, [wide_number_mode => STRING]) at [43:25]; reason: invalidQuery, location: query, message: No matching signature for function PARSE_JSON for argument types: ARRAY<STRUCT<amount FLOAT64, quantity INT64, product_sku STRING>>. Supported signature: PARSE_JSON(STRING, [wide_number_mode => STRING]) at [43:25]')
[0m10:41:31.864878 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:67d00430-8b35-4368-9bd8-6cf36d50c81b&page=queryresults
[0m10:41:31.965760 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:67d00430-8b35-4368-9bd8-6cf36d50c81b&page=queryresults
[0m10:41:31.980780 [debug] [Thread-1 (]: Database Error in model sales_staging (dbt_data_pipeline/models\datahub\sales_staging.sql)
  No matching signature for function PARSE_JSON for argument types: ARRAY<STRUCT<amount FLOAT64, quantity INT64, product_sku STRING>>. Supported signature: PARSE_JSON(STRING, [wide_number_mode => STRING]) at [43:25]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\sales_staging.sql
[0m10:41:31.980780 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a5765f8d-5602-4e70-86c3-86999e21446d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021867AB16A0>]}
[0m10:41:31.980780 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model dp_hub.sales_staging ...................... [[31mERROR[0m in 1.54s]
[0m10:41:31.980780 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.sales_staging
[0m10:41:31.996405 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:41:31.996405 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m10:41:31.996405 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp' was properly closed.
[0m10:41:31.996405 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.sales_staging' was properly closed.
[0m10:41:31.996405 [info ] [MainThread]: 
[0m10:41:31.996405 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 5.07 seconds (5.07s).
[0m10:41:31.996405 [debug] [MainThread]: Command end result
[0m10:41:32.112364 [info ] [MainThread]: 
[0m10:41:32.112364 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m10:41:32.112364 [info ] [MainThread]: 
[0m10:41:32.112364 [error] [MainThread]:   Database Error in model sales_staging (dbt_data_pipeline/models\datahub\sales_staging.sql)
  No matching signature for function PARSE_JSON for argument types: ARRAY<STRUCT<amount FLOAT64, quantity INT64, product_sku STRING>>. Supported signature: PARSE_JSON(STRING, [wide_number_mode => STRING]) at [43:25]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\datahub\sales_staging.sql
[0m10:41:32.112364 [info ] [MainThread]: 
[0m10:41:32.112364 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m10:41:32.127995 [debug] [MainThread]: Command `dbt run` failed at 10:41:32.127995 after 10.32 seconds
[0m10:41:32.127995 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021867E7B170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002186761F860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021867EC4E00>]}
[0m10:41:32.127995 [debug] [MainThread]: Flushing usage events
[0m10:43:00.538817 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016A381C2E70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016A381C3140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016A38694800>]}


============================== 10:43:00.540849 | 3f8c39a1-8dba-4796-a162-ac6348650153 ==============================
[0m10:43:00.540849 [info ] [MainThread]: Running with dbt=1.8.7
[0m10:43:00.551065 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run -s sales_staging.sql --full-refresh', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m10:43:03.947881 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3f8c39a1-8dba-4796-a162-ac6348650153', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016A40963140>]}
[0m10:43:04.016447 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3f8c39a1-8dba-4796-a162-ac6348650153', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016A408EEAB0>]}
[0m10:43:04.016447 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m10:43:04.032093 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m10:43:04.450509 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:43:04.450509 [debug] [MainThread]: Partial parsing: updated file: dbt_data_pipeline://dbt_data_pipeline/models\datahub\sales_staging.sql
[0m10:43:04.959312 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_data_pipeline.datalake
- models.dbt_data_pipeline.dataproducts
[0m10:43:04.989685 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3f8c39a1-8dba-4796-a162-ac6348650153', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016A43895400>]}
[0m10:43:05.174728 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3f8c39a1-8dba-4796-a162-ac6348650153', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016A4387FDD0>]}
[0m10:43:05.174728 [info ] [MainThread]: Found 5 models, 4 data tests, 3 sources, 484 macros
[0m10:43:05.174728 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3f8c39a1-8dba-4796-a162-ac6348650153', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016A437A3EC0>]}
[0m10:43:05.190306 [info ] [MainThread]: 
[0m10:43:05.190306 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:43:05.190306 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m10:43:05.190306 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:43:08.014110 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp'
[0m10:43:08.014110 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:43:08.429926 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp, now list_dataengineerproject-439609_dp_hub)
[0m10:43:08.429926 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:43:08.648649 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3f8c39a1-8dba-4796-a162-ac6348650153', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016A364AD580>]}
[0m10:43:08.648649 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:43:08.648649 [info ] [MainThread]: 
[0m10:43:08.648649 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.sales_staging
[0m10:43:08.648649 [info ] [Thread-1 (]: 1 of 1 START sql view model dp_hub.sales_staging ............................... [RUN]
[0m10:43:08.648649 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.sales_staging'
[0m10:43:08.648649 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.sales_staging
[0m10:43:08.668304 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.sales_staging"
[0m10:43:08.668304 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.sales_staging
[0m10:43:08.746451 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.sales_staging"
[0m10:43:08.746451 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:43:08.746451 [debug] [Thread-1 (]: On model.dbt_data_pipeline.sales_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.sales_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_hub`.`sales_staging`
  OPTIONS()
  as -- Tag to indicate that this model is updated every hour


WITH deduplicated_sales AS (
    -- Select only records ingested in the last hour and deduplicate by sales id
    SELECT DISTINCT
        customer_id,
        total_amount,
        datetime,
        id,
        _dp_ingestion_timestamp,
        items
    FROM `dataengineerproject-439609`.`dp_lake`.`sales_normalized`
    WHERE _dp_ingestion_timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR)
)

-- Flatten items array for each sale
SELECT
    ds.customer_id,
    ds.total_amount,
    ds.datetime,
    ds.id,
    ds._dp_ingestion_timestamp,
    item.amount AS item_amount,
    item.quantity AS item_quantity,
    item.product_sku AS item_product_sku
FROM
    deduplicated_sales AS ds,
    UNNEST(ds.items) AS item;


[0m10:43:09.146705 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:4d98f2d3-7fc9-4480-840a-38e53a8f28ed&page=queryresults
[0m10:43:09.369393 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3f8c39a1-8dba-4796-a162-ac6348650153', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016A41999850>]}
[0m10:43:09.369393 [info ] [Thread-1 (]: 1 of 1 OK created sql view model dp_hub.sales_staging .......................... [[32mCREATE VIEW (0 processed)[0m in 0.72s]
[0m10:43:09.369393 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.sales_staging
[0m10:43:09.385055 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:43:09.385055 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m10:43:09.385055 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_hub' was properly closed.
[0m10:43:09.385055 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.sales_staging' was properly closed.
[0m10:43:09.385055 [info ] [MainThread]: 
[0m10:43:09.385055 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 4.19 seconds (4.19s).
[0m10:43:09.385055 [debug] [MainThread]: Command end result
[0m10:43:09.547837 [info ] [MainThread]: 
[0m10:43:09.563461 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:43:09.563461 [info ] [MainThread]: 
[0m10:43:09.569981 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m10:43:09.569981 [debug] [MainThread]: Command `dbt run` succeeded at 10:43:09.569981 after 9.33 seconds
[0m10:43:09.569981 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016A384CB530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016A384CA3C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016A384C8440>]}
[0m10:43:09.569981 [debug] [MainThread]: Flushing usage events
[0m10:46:27.479399 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B741F9C3B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B741F483E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B7417D5580>]}


============================== 10:46:27.495024 | dab51c0e-f7c3-42e7-843d-5483681486ff ==============================
[0m10:46:27.495024 [info ] [MainThread]: Running with dbt=1.8.7
[0m10:46:27.495024 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run -s sales_staging.sql --full-refresh', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m10:46:31.136048 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dab51c0e-f7c3-42e7-843d-5483681486ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B74CA4FD40>]}
[0m10:46:31.214238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'dab51c0e-f7c3-42e7-843d-5483681486ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B74CB4D820>]}
[0m10:46:31.214238 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m10:46:31.235953 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m10:46:31.684086 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:46:31.684086 [debug] [MainThread]: Partial parsing: updated file: dbt_data_pipeline://dbt_data_pipeline/models\datahub\sales_staging.sql
[0m10:46:32.015513 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_data_pipeline.datalake
- models.dbt_data_pipeline.dataproducts
[0m10:46:32.037678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dab51c0e-f7c3-42e7-843d-5483681486ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B74D025970>]}
[0m10:46:32.216191 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dab51c0e-f7c3-42e7-843d-5483681486ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B74D0582C0>]}
[0m10:46:32.216191 [info ] [MainThread]: Found 5 models, 4 data tests, 3 sources, 484 macros
[0m10:46:32.216191 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dab51c0e-f7c3-42e7-843d-5483681486ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B74CF8FFE0>]}
[0m10:46:32.231807 [info ] [MainThread]: 
[0m10:46:32.231807 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:46:32.238322 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m10:46:32.238322 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:46:35.175970 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_hub'
[0m10:46:35.175970 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:46:35.306955 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_hub, now list_dataengineerproject-439609_dp)
[0m10:46:35.306955 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:46:35.793100 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dab51c0e-f7c3-42e7-843d-5483681486ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B73FB5D730>]}
[0m10:46:35.793100 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:46:35.793100 [info ] [MainThread]: 
[0m10:46:35.793100 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.sales_staging
[0m10:46:35.793100 [info ] [Thread-1 (]: 1 of 1 START sql view model dp_hub.sales_staging ............................... [RUN]
[0m10:46:35.808712 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.sales_staging'
[0m10:46:35.808712 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.sales_staging
[0m10:46:35.808712 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.sales_staging"
[0m10:46:35.808712 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.sales_staging
[0m10:46:35.877751 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.sales_staging"
[0m10:46:35.893381 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:46:35.893381 [debug] [Thread-1 (]: On model.dbt_data_pipeline.sales_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.sales_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_hub`.`sales_staging`
  OPTIONS()
  as -- Tag to indicate that this model is updated every hour


WITH ranked_sales AS (
    -- Assign a row number to each sale based on customer_id and timestamp, to keep the most recent entry
    SELECT
        *,
        ROW_NUMBER() OVER (
            PARTITION BY id
            ORDER BY _dp_ingestion_timestamp DESC
        ) AS row_num
    FROM `dataengineerproject-439609`.`dp_lake`.`sales_normalized`
),

-- Filter to only include the most recent entry for each sale (i.e., row_num = 1)
deduplicated_sales AS (
    SELECT *
    FROM ranked_sales
    WHERE row_num = 1
)

-- Flatten items array for each sale and select relevant fields
SELECT
    ds.customer_id,
    ds.total_amount,
    ds.datetime,
    ds.id,
    ds._dp_ingestion_timestamp,
    item.amount AS item_amount,
    item.quantity AS item_quantity,
    item.product_sku AS item_product_sku
FROM
    deduplicated_sales AS ds,
    UNNEST(ds.items) AS item;


[0m10:46:36.194018 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:c484a441-51b4-4884-8089-0ebf365c6705&page=queryresults
[0m10:46:36.526293 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dab51c0e-f7c3-42e7-843d-5483681486ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B74B12A900>]}
[0m10:46:36.526293 [info ] [Thread-1 (]: 1 of 1 OK created sql view model dp_hub.sales_staging .......................... [[32mCREATE VIEW (0 processed)[0m in 0.72s]
[0m10:46:36.526293 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.sales_staging
[0m10:46:36.526293 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:46:36.526293 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m10:46:36.526293 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp' was properly closed.
[0m10:46:36.526293 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.sales_staging' was properly closed.
[0m10:46:36.526293 [info ] [MainThread]: 
[0m10:46:36.526293 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 4.29 seconds (4.29s).
[0m10:46:36.541911 [debug] [MainThread]: Command end result
[0m10:46:36.648783 [info ] [MainThread]: 
[0m10:46:36.648783 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:46:36.648783 [info ] [MainThread]: 
[0m10:46:36.648783 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m10:46:36.648783 [debug] [MainThread]: Command `dbt run` succeeded at 10:46:36.648783 after 9.62 seconds
[0m10:46:36.664466 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B73E6ABCE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B740E37D70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B741C47F80>]}
[0m10:46:36.664466 [debug] [MainThread]: Flushing usage events
[0m10:51:10.208813 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C89C9BE270>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C899E953D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C89C8EED80>]}


============================== 10:51:10.224439 | 63d57f63-ac91-4adb-80bf-d9c21f235405 ==============================
[0m10:51:10.224439 [info ] [MainThread]: Running with dbt=1.8.7
[0m10:51:10.224439 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run -s sales_staging.sql products_staging.sql --full-refresh', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:51:13.665021 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '63d57f63-ac91-4adb-80bf-d9c21f235405', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8A4B9BF50>]}
[0m10:51:13.749284 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '63d57f63-ac91-4adb-80bf-d9c21f235405', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C89BE008C0>]}
[0m10:51:13.749284 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m10:51:13.764905 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m10:51:14.202902 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m10:51:14.202902 [debug] [MainThread]: Partial parsing: updated file: dbt_data_pipeline://dbt_data_pipeline/models\datahub\sales_staging.sql
[0m10:51:14.202902 [debug] [MainThread]: Partial parsing: updated file: dbt_data_pipeline://dbt_data_pipeline/models\datahub\products_staging.sql
[0m10:51:14.519097 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_data_pipeline.datalake
- models.dbt_data_pipeline.dataproducts
[0m10:51:14.534709 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '63d57f63-ac91-4adb-80bf-d9c21f235405', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8A56783B0>]}
[0m10:51:14.735369 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '63d57f63-ac91-4adb-80bf-d9c21f235405', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8A7B95340>]}
[0m10:51:14.735369 [info ] [MainThread]: Found 5 models, 4 data tests, 3 sources, 484 macros
[0m10:51:14.735369 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '63d57f63-ac91-4adb-80bf-d9c21f235405', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8A78542F0>]}
[0m10:51:14.751002 [info ] [MainThread]: 
[0m10:51:14.751002 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m10:51:14.751002 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m10:51:14.751002 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:51:17.642055 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_hub'
[0m10:51:17.642055 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:51:17.812082 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_hub, now list_dataengineerproject-439609_dp)
[0m10:51:17.812082 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m10:51:18.212407 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '63d57f63-ac91-4adb-80bf-d9c21f235405', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8A7B6F920>]}
[0m10:51:18.212407 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:51:18.212407 [info ] [MainThread]: 
[0m10:51:18.228032 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.products_staging
[0m10:51:18.228032 [info ] [Thread-1 (]: 1 of 2 START sql view model dp_hub.products_staging ............................ [RUN]
[0m10:51:18.228032 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.products_staging'
[0m10:51:18.228032 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.products_staging
[0m10:51:18.243655 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.products_staging"
[0m10:51:18.243655 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.products_staging
[0m10:51:18.297008 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.products_staging"
[0m10:51:18.297008 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:51:18.297008 [debug] [Thread-1 (]: On model.dbt_data_pipeline.products_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.products_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_hub`.`products_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


WITH ranked_products AS (
    SELECT
        *,
        ROW_NUMBER() OVER (
            PARTITION BY product_sku
            ORDER BY _dp_ingestion_timestamp DESC
        ) AS row_num
    FROM `dataengineerproject-439609`.`dp_lake`.`products_normalized`
)

-- Sélectionner uniquement les enregistrements uniques les plus récents
SELECT
    _dp_ingestion_timestamp,
    product_sku,
    unit_amount,
    description AS product_description,
    supplier

FROM
    ranked_products
WHERE
    row_num = 1;


[0m10:51:18.729844 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:60bf139f-8ad7-49d3-8665-7c8f27cfb862&page=queryresults
[0m10:51:18.961534 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '63d57f63-ac91-4adb-80bf-d9c21f235405', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8A5C6AB70>]}
[0m10:51:18.961534 [info ] [Thread-1 (]: 1 of 2 OK created sql view model dp_hub.products_staging ....................... [[32mCREATE VIEW (0 processed)[0m in 0.72s]
[0m10:51:18.961534 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.products_staging
[0m10:51:18.961534 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.sales_staging
[0m10:51:18.961534 [info ] [Thread-1 (]: 2 of 2 START sql view model dp_hub.sales_staging ............................... [RUN]
[0m10:51:18.961534 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_data_pipeline.products_staging, now model.dbt_data_pipeline.sales_staging)
[0m10:51:18.961534 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.sales_staging
[0m10:51:18.977190 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.sales_staging"
[0m10:51:18.977190 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.sales_staging
[0m10:51:18.977190 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.sales_staging"
[0m10:51:18.992780 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:51:18.992780 [debug] [Thread-1 (]: On model.dbt_data_pipeline.sales_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.sales_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_hub`.`sales_staging`
  OPTIONS()
  as -- Tag to indicate that this model is updated every hour


WITH ranked_sales AS (
    -- Assign a row number to each sale based on customer_id and timestamp, to keep the most recent entry
    SELECT
        *,
        ROW_NUMBER() OVER (
            PARTITION BY id
            ORDER BY _dp_ingestion_timestamp DESC
        ) AS row_num
    FROM `dataengineerproject-439609`.`dp_lake`.`sales_normalized`
),

-- Filter to only include the most recent entry for each sale (i.e., row_num = 1)
deduplicated_sales AS (
    SELECT *
    FROM ranked_sales
    WHERE row_num = 1
)

-- Flatten items array for each sale and select relevant fields
SELECT
    ds._dp_ingestion_timestamp,
    ds.id,
    ds.datetime AS sales_datetime,
    ds.customer_id,
    ds.total_amount,
    item.amount AS item_amount,
    item.quantity AS item_quantity,
    item.product_sku AS item_product_sku
FROM
    deduplicated_sales AS ds,
    UNNEST(ds.items) AS item;


[0m10:51:19.278802 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:d80994cd-8688-4ee3-abb7-a71fbeedcfeb&page=queryresults
[0m10:51:19.549425 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '63d57f63-ac91-4adb-80bf-d9c21f235405', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8A7C65880>]}
[0m10:51:19.549425 [info ] [Thread-1 (]: 2 of 2 OK created sql view model dp_hub.sales_staging .......................... [[32mCREATE VIEW (0 processed)[0m in 0.59s]
[0m10:51:19.549425 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.sales_staging
[0m10:51:19.549425 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:51:19.549425 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m10:51:19.549425 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp' was properly closed.
[0m10:51:19.549425 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.sales_staging' was properly closed.
[0m10:51:19.549425 [info ] [MainThread]: 
[0m10:51:19.549425 [info ] [MainThread]: Finished running 2 view models in 0 hours 0 minutes and 4.80 seconds (4.80s).
[0m10:51:19.549425 [debug] [MainThread]: Command end result
[0m10:51:19.664832 [info ] [MainThread]: 
[0m10:51:19.664832 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:51:19.664832 [info ] [MainThread]: 
[0m10:51:19.664832 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m10:51:19.664832 [debug] [MainThread]: Command `dbt run` succeeded at 10:51:19.664832 after 10.09 seconds
[0m10:51:19.680409 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C89C440BF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C89C8CD1C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C89C8EDB20>]}
[0m10:51:19.680409 [debug] [MainThread]: Flushing usage events
[0m11:10:18.603186 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021F32EBF4D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021F32EBE5A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021F2F759730>]}


============================== 11:10:18.618849 | f5d2f337-4135-4b1c-9a1f-c5fb80ddcdb9 ==============================
[0m11:10:18.618849 [info ] [MainThread]: Running with dbt=1.8.7
[0m11:10:18.618849 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run -s sales_staging.sql products_staging.sql --full-refresh', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:10:22.256643 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f5d2f337-4135-4b1c-9a1f-c5fb80ddcdb9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021F3DBC7E00>]}
[0m11:10:22.356962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f5d2f337-4135-4b1c-9a1f-c5fb80ddcdb9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021F33AC3F20>]}
[0m11:10:22.356962 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m11:10:22.372590 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m11:10:22.889013 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m11:10:22.889013 [debug] [MainThread]: Partial parsing: added file: dbt_data_pipeline://dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m11:10:23.190499 [error] [MainThread]: Encountered an error:
Compilation Error in model sales_items (dbt_data_pipeline/models\dataproducts\sales_items.sql)
  invalid syntax for function call expression
    line 3
      config(
[0m11:10:23.190499 [debug] [MainThread]: Command `dbt run` failed at 11:10:23.190499 after 4.92 seconds
[0m11:10:23.190499 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021F32F33080>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021F3DCB6C30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021F3DEDEED0>]}
[0m11:10:23.190499 [debug] [MainThread]: Flushing usage events
[0m11:12:15.951998 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C7FD7C3170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C7FF78B920>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C7FFB54FE0>]}


============================== 11:12:15.967619 | f0036b35-2e08-40da-a9dd-1d203b10bf53 ==============================
[0m11:12:15.967619 [info ] [MainThread]: Running with dbt=1.8.7
[0m11:12:15.967619 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run -s sales_staging.sql products_staging.sql --full-refresh', 'send_anonymous_usage_stats': 'True'}
[0m11:12:20.749290 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f0036b35-2e08-40da-a9dd-1d203b10bf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C788D12CC0>]}
[0m11:12:20.871657 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f0036b35-2e08-40da-a9dd-1d203b10bf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C7888E00E0>]}
[0m11:12:20.879721 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m11:12:20.900028 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m11:12:21.451056 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m11:12:21.451056 [debug] [MainThread]: Partial parsing: added file: dbt_data_pipeline://dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m11:12:21.836141 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_data_pipeline.datalake
[0m11:12:21.851823 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f0036b35-2e08-40da-a9dd-1d203b10bf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C78AD25AF0>]}
[0m11:12:22.036848 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f0036b35-2e08-40da-a9dd-1d203b10bf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C78AD40E60>]}
[0m11:12:22.036848 [info ] [MainThread]: Found 6 models, 4 data tests, 3 sources, 484 macros
[0m11:12:22.036848 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f0036b35-2e08-40da-a9dd-1d203b10bf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C78AD25BB0>]}
[0m11:12:22.036848 [info ] [MainThread]: 
[0m11:12:22.036848 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:12:22.036848 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m11:12:22.052412 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:12:25.446848 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_dataproducts'
[0m11:12:25.446848 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:12:25.647480 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_dataproducts, now list_dataengineerproject-439609_dp)
[0m11:12:25.647480 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:12:26.063358 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp, now list_dataengineerproject-439609_dp_hub)
[0m11:12:26.063358 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:12:26.179991 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f0036b35-2e08-40da-a9dd-1d203b10bf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C78A9CFD10>]}
[0m11:12:26.179991 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:12:26.179991 [info ] [MainThread]: 
[0m11:12:26.194991 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.products_staging
[0m11:12:26.194991 [info ] [Thread-1 (]: 1 of 2 START sql view model dp_hub.products_staging ............................ [RUN]
[0m11:12:26.194991 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.products_staging'
[0m11:12:26.194991 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.products_staging
[0m11:12:26.210590 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.products_staging"
[0m11:12:26.210590 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.products_staging
[0m11:12:26.248390 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.products_staging"
[0m11:12:26.248390 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:12:26.248390 [debug] [Thread-1 (]: On model.dbt_data_pipeline.products_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.products_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_hub`.`products_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


WITH ranked_products AS (
    SELECT
        *,
        ROW_NUMBER() OVER (
            PARTITION BY product_sku
            ORDER BY _dp_ingestion_timestamp DESC
        ) AS row_num
    FROM `dataengineerproject-439609`.`dp_lake`.`products_normalized`
)

-- Sélectionner uniquement les enregistrements uniques les plus récents
SELECT
    _dp_ingestion_timestamp,
    product_sku,
    unit_amount,
    description AS product_description,
    supplier

FROM
    ranked_products
WHERE
    row_num = 1;


[0m11:12:27.083619 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:e5468879-3cc1-4c0e-91a7-f91ec2b9bf01&page=queryresults
[0m11:12:27.298967 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0036b35-2e08-40da-a9dd-1d203b10bf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C788E2A930>]}
[0m11:12:27.298967 [info ] [Thread-1 (]: 1 of 2 OK created sql view model dp_hub.products_staging ....................... [[32mCREATE VIEW (0 processed)[0m in 1.10s]
[0m11:12:27.298967 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.products_staging
[0m11:12:27.314590 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.sales_staging
[0m11:12:27.314590 [info ] [Thread-1 (]: 2 of 2 START sql view model dp_hub.sales_staging ............................... [RUN]
[0m11:12:27.314590 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_data_pipeline.products_staging, now model.dbt_data_pipeline.sales_staging)
[0m11:12:27.314590 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.sales_staging
[0m11:12:27.314590 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.sales_staging"
[0m11:12:27.314590 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.sales_staging
[0m11:12:27.314590 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.sales_staging"
[0m11:12:27.330215 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:12:27.330215 [debug] [Thread-1 (]: On model.dbt_data_pipeline.sales_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.sales_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_hub`.`sales_staging`
  OPTIONS()
  as -- Tag to indicate that this model is updated every hour


WITH ranked_sales AS (
    -- Assign a row number to each sale based on customer_id and timestamp, to keep the most recent entry
    SELECT
        *,
        ROW_NUMBER() OVER (
            PARTITION BY id
            ORDER BY _dp_ingestion_timestamp DESC
        ) AS row_num
    FROM `dataengineerproject-439609`.`dp_lake`.`sales_normalized`
),

-- Filter to only include the most recent entry for each sale (i.e., row_num = 1)
deduplicated_sales AS (
    SELECT *
    FROM ranked_sales
    WHERE row_num = 1
)

-- Flatten items array for each sale and select relevant fields
SELECT
    ds._dp_ingestion_timestamp,
    ds.id,
    ds.datetime AS sales_datetime,
    ds.customer_id,
    ds.total_amount,
    item.amount AS item_amount,
    item.quantity AS item_quantity,
    item.product_sku AS item_product_sku
FROM
    deduplicated_sales AS ds,
    UNNEST(ds.items) AS item;


[0m11:12:27.637346 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:ba6cd47b-ec96-4346-ad16-8b6963c76314&page=queryresults
[0m11:12:27.900868 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0036b35-2e08-40da-a9dd-1d203b10bf53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C78B1C5880>]}
[0m11:12:27.900868 [info ] [Thread-1 (]: 2 of 2 OK created sql view model dp_hub.sales_staging .......................... [[32mCREATE VIEW (0 processed)[0m in 0.59s]
[0m11:12:27.900868 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.sales_staging
[0m11:12:27.900868 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:12:27.900868 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m11:12:27.900868 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_hub' was properly closed.
[0m11:12:27.900868 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.sales_staging' was properly closed.
[0m11:12:27.916185 [info ] [MainThread]: 
[0m11:12:27.916185 [info ] [MainThread]: Finished running 2 view models in 0 hours 0 minutes and 5.88 seconds (5.88s).
[0m11:12:27.916185 [debug] [MainThread]: Command end result
[0m11:12:28.038601 [info ] [MainThread]: 
[0m11:12:28.038601 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:12:28.038601 [info ] [MainThread]: 
[0m11:12:28.038601 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m11:12:28.038601 [debug] [MainThread]: Command `dbt run` succeeded at 11:12:28.038601 after 12.58 seconds
[0m11:12:28.038601 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C7FD7C3170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C78ABDBDD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C78ABDB050>]}
[0m11:12:28.038601 [debug] [MainThread]: Flushing usage events
[0m11:13:42.942424 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FB5AD53D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FB7F83170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FB86D86B0>]}


============================== 11:13:42.942424 | b34fde56-00b7-436b-b612-3e88a1681d1a ==============================
[0m11:13:42.942424 [info ] [MainThread]: Running with dbt=1.8.7
[0m11:13:42.942424 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run -s sales_items.sql --full-refresh', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m11:13:46.582650 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b34fde56-00b7-436b-b612-3e88a1681d1a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FC1AF5700>]}
[0m11:13:46.694737 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b34fde56-00b7-436b-b612-3e88a1681d1a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FB78A77D0>]}
[0m11:13:46.702772 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m11:13:46.723055 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m11:13:47.301391 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:13:47.303436 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:13:47.313694 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_data_pipeline.datalake
[0m11:13:47.405344 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b34fde56-00b7-436b-b612-3e88a1681d1a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FC31F8DD0>]}
[0m11:13:47.633164 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b34fde56-00b7-436b-b612-3e88a1681d1a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FC35353A0>]}
[0m11:13:47.633164 [info ] [MainThread]: Found 6 models, 4 data tests, 3 sources, 484 macros
[0m11:13:47.633164 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b34fde56-00b7-436b-b612-3e88a1681d1a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FC352DF70>]}
[0m11:13:47.633164 [info ] [MainThread]: 
[0m11:13:47.633164 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:13:47.633164 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m11:13:47.633164 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:13:50.547877 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_dataproducts'
[0m11:13:50.547877 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:13:50.670983 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_dataproducts, now list_dataengineerproject-439609_dp_hub)
[0m11:13:50.670983 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:13:50.856191 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_hub, now list_dataengineerproject-439609_dp)
[0m11:13:50.856191 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:13:51.357530 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b34fde56-00b7-436b-b612-3e88a1681d1a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FB630D6D0>]}
[0m11:13:51.357530 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:13:51.357530 [info ] [MainThread]: 
[0m11:13:51.373211 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.sales_items
[0m11:13:51.373211 [info ] [Thread-1 (]: 1 of 1 START sql incremental model dp_dataproducts.sales_items ................. [RUN]
[0m11:13:51.373211 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.sales_items'
[0m11:13:51.373211 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.sales_items
[0m11:13:51.388838 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.sales_items"
[0m11:13:51.388838 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.sales_items
[0m11:13:51.473600 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.sales_items"
[0m11:13:51.489190 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:13:51.489190 [debug] [Thread-1 (]: On model.dbt_data_pipeline.sales_items: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.sales_items"} */

  
    

    create or replace table `dataengineerproject-439609`.`dp_dataproducts`.`sales_items`
      
    partition by timestamp_trunc(sales_datetime, day)
    

    OPTIONS()
    as (
      -- Config for simplified incremental materialization with partitioning
-- Use insert_overwrite for simple overwrites


-- Base query for the sales items
WITH base AS (
    SELECT
        CONCAT(CAST(s.id AS STRING), '_', i.product_sku) AS pk,  -- Primary Key combining sales id and product SKU
        s.sales_datetime,                            -- Sales datetime for partitioning
        i.item_amount,                                 -- Total amount per product
        i.product_sku,                                           -- SKU of the product sold
        i.item_quantity,                             -- Quantity sold of this product
        p.product_description,                    -- Product description from product table
        ROUND(1 - (i.item_amount / p.unit_amount), 2) AS discount_perc  -- Calculating discount percentage
    FROM
        `dataengineerproject-439609`.`dp_hub`.`sales_staging` s                             -- Using sales staging as base
    LEFT JOIN
        `dataengineerproject-439609`.`dp_hub`.`products_staging` p                          -- Joining products staging for additional info
    ON
        i.product_sku = p.product_sku                            -- Join on product_sku
    UNNEST(s.items) AS i                                         -- Unnesting items array
)

-- Output the base data
SELECT *
FROM base
    );
  
[0m11:13:51.674872 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:b8b75528-dab4-4122-b5ab-30a74dc08bda&page=queryresults
[0m11:13:51.674872 [debug] [Thread-1 (]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Syntax error: Expected ")" but got keyword UNNEST at [33:5]; reason: invalidQuery, location: query, message: Syntax error: Expected ")" but got keyword UNNEST at [33:5]')
[0m11:13:52.175650 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:daf72404-af3f-4e36-bda2-e81d0718c03d&page=queryresults
[0m11:13:52.175650 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:daf72404-af3f-4e36-bda2-e81d0718c03d&page=queryresults
[0m11:13:52.190623 [debug] [Thread-1 (]: Database Error in model sales_items (dbt_data_pipeline/models\dataproducts\sales_items.sql)
  Syntax error: Expected ")" but got keyword UNNEST at [33:5]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m11:13:52.190623 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b34fde56-00b7-436b-b612-3e88a1681d1a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FC326E990>]}
[0m11:13:52.190623 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model dp_dataproducts.sales_items ........ [[31mERROR[0m in 0.82s]
[0m11:13:52.206253 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.sales_items
[0m11:13:52.206253 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:13:52.206253 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m11:13:52.206253 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp' was properly closed.
[0m11:13:52.206253 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.sales_items' was properly closed.
[0m11:13:52.206253 [info ] [MainThread]: 
[0m11:13:52.206253 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.57 seconds (4.57s).
[0m11:13:52.206253 [debug] [MainThread]: Command end result
[0m11:13:52.253165 [info ] [MainThread]: 
[0m11:13:52.253165 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m11:13:52.259676 [info ] [MainThread]: 
[0m11:13:52.259676 [error] [MainThread]:   Database Error in model sales_items (dbt_data_pipeline/models\dataproducts\sales_items.sql)
  Syntax error: Expected ")" but got keyword UNNEST at [33:5]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m11:13:52.259676 [info ] [MainThread]: 
[0m11:13:52.259676 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m11:13:52.259676 [debug] [MainThread]: Command `dbt run` failed at 11:13:52.259676 after 9.74 seconds
[0m11:13:52.259676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FC1174050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FC3503260>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016FB8420350>]}
[0m11:13:52.259676 [debug] [MainThread]: Flushing usage events
[0m11:15:23.983976 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CEF4D0B530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CEF75D3170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CEF69A0B30>]}


============================== 11:15:23.999596 | 448609fb-057c-45a9-affc-3d7bd93540e0 ==============================
[0m11:15:23.999596 [info ] [MainThread]: Running with dbt=1.8.7
[0m11:15:23.999596 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run -s sales_items.sql --full-refresh', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m11:15:27.191965 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '448609fb-057c-45a9-affc-3d7bd93540e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE82BD5580>]}
[0m11:15:27.276221 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '448609fb-057c-45a9-affc-3d7bd93540e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE813EBE00>]}
[0m11:15:27.276221 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m11:15:27.291852 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m11:15:27.661704 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:15:27.661704 [debug] [MainThread]: Partial parsing: updated file: dbt_data_pipeline://dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m11:15:27.993614 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_data_pipeline.datalake
[0m11:15:28.009186 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '448609fb-057c-45a9-affc-3d7bd93540e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CEF68672C0>]}
[0m11:15:28.194176 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '448609fb-057c-45a9-affc-3d7bd93540e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE83134770>]}
[0m11:15:28.194176 [info ] [MainThread]: Found 6 models, 4 data tests, 3 sources, 484 macros
[0m11:15:28.194176 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '448609fb-057c-45a9-affc-3d7bd93540e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE83116900>]}
[0m11:15:28.194176 [info ] [MainThread]: 
[0m11:15:28.194176 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:15:28.209799 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m11:15:28.209799 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:15:31.859155 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_dataproducts'
[0m11:15:31.859155 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:15:32.117792 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_dataproducts, now list_dataengineerproject-439609_dp)
[0m11:15:32.117792 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:15:32.541275 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp, now list_dataengineerproject-439609_dp_hub)
[0m11:15:32.541275 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:15:32.658425 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '448609fb-057c-45a9-affc-3d7bd93540e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE82DBC620>]}
[0m11:15:32.658425 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:15:32.658425 [info ] [MainThread]: 
[0m11:15:32.673425 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.sales_items
[0m11:15:32.673425 [info ] [Thread-1 (]: 1 of 1 START sql incremental model dp_dataproducts.sales_items ................. [RUN]
[0m11:15:32.673425 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.sales_items'
[0m11:15:32.673425 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.sales_items
[0m11:15:32.673425 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.sales_items"
[0m11:15:32.673425 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.sales_items
[0m11:15:32.789381 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.sales_items"
[0m11:15:32.789381 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:15:32.789381 [debug] [Thread-1 (]: On model.dbt_data_pipeline.sales_items: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.sales_items"} */

  
    

    create or replace table `dataengineerproject-439609`.`dp_dataproducts`.`sales_items`
      
    partition by timestamp_trunc(sales_datetime, day)
    

    OPTIONS()
    as (
      -- Config for simplified incremental materialization with partitioning
-- Use insert_overwrite for simple overwrites


-- Base query for the sales items
WITH base AS (
    SELECT
        CONCAT(CAST(s.id AS STRING), '_', i.product_sku) AS pk,  -- Primary Key combining sales id and product SKU
        s.sales_datetime,                            -- Sales datetime for partitioning
        i.item_amount,                                 -- Total amount per product
        i.product_sku,                                           -- SKU of the product sold
        i.item_quantity,                             -- Quantity sold of this product
        p.product_description,                    -- Product description from product table
        ROUND(1 - (i.item_amount / p.unit_amount), 2) AS discount_perc  -- Calculating discount percentage
    FROM
        `dataengineerproject-439609`.`dp_hub`.`sales_staging` s                             -- Using sales staging as base
    LEFT JOIN UNNEST(s.items) AS i                                         -- Unnesting items array
    LEFT JOIN
        `dataengineerproject-439609`.`dp_hub`.`products_staging` p                          -- Joining products staging for additional info
    ON
        i.product_sku = p.product_sku                            -- Join on product_sku

)

-- Output the base data
SELECT *
FROM base
    );
  
[0m11:15:33.460855 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:a2908147-bc93-46ad-8b0d-2be840ae868a&page=queryresults
[0m11:15:33.561685 [debug] [Thread-1 (]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Name items not found inside s at [29:24]; reason: invalidQuery, location: query, message: Name items not found inside s at [29:24]')
[0m11:15:34.163880 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:26565b1c-846d-410a-ad2f-144d26bab248&page=queryresults
[0m11:15:34.278738 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:26565b1c-846d-410a-ad2f-144d26bab248&page=queryresults
[0m11:15:34.309975 [debug] [Thread-1 (]: Database Error in model sales_items (dbt_data_pipeline/models\dataproducts\sales_items.sql)
  Name items not found inside s at [29:24]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m11:15:34.309975 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '448609fb-057c-45a9-affc-3d7bd93540e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CEF6F1D8E0>]}
[0m11:15:34.309975 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model dp_dataproducts.sales_items ........ [[31mERROR[0m in 1.64s]
[0m11:15:34.309975 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.sales_items
[0m11:15:34.309975 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:15:34.309975 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m11:15:34.309975 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_hub' was properly closed.
[0m11:15:34.309975 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.sales_items' was properly closed.
[0m11:15:34.309975 [info ] [MainThread]: 
[0m11:15:34.309975 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 6.12 seconds (6.12s).
[0m11:15:34.309975 [debug] [MainThread]: Command end result
[0m11:15:34.441599 [info ] [MainThread]: 
[0m11:15:34.441599 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m11:15:34.441599 [info ] [MainThread]: 
[0m11:15:34.448111 [error] [MainThread]:   Database Error in model sales_items (dbt_data_pipeline/models\dataproducts\sales_items.sql)
  Name items not found inside s at [29:24]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m11:15:34.448111 [info ] [MainThread]: 
[0m11:15:34.448111 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m11:15:34.448111 [debug] [MainThread]: Command `dbt run` failed at 11:15:34.448111 after 10.80 seconds
[0m11:15:34.448111 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CEF1772A80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE8311BB60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE80AE65D0>]}
[0m11:15:34.448111 [debug] [MainThread]: Flushing usage events
[0m11:27:20.367661 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000254DC7EEA20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000254DBEE57F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000254D68E28A0>]}


============================== 11:27:20.383390 | 092d25c6-74b7-44a2-9266-fcf6d43fb4fd ==============================
[0m11:27:20.383390 [info ] [MainThread]: Running with dbt=1.8.7
[0m11:27:20.383390 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run -s sales_items.sql --full-refresh', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m11:27:23.541824 [error] [MainThread]: Encountered an error:

[0m11:27:23.623477 [error] [MainThread]: Traceback (most recent call last):
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\cli\requires.py", line 138, in wrapper
    result, success = func(*args, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\cli\requires.py", line 101, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\cli\requires.py", line 215, in wrapper
    profile = load_profile(flags.PROJECT_DIR, flags.VARS, flags.PROFILE, flags.TARGET, threads)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\config\runtime.py", line 71, in load_profile
    profile = Profile.render(
              ^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\config\profile.py", line 403, in render
    return cls.from_raw_profiles(
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\config\profile.py", line 369, in from_raw_profiles
    return cls.from_raw_profile_info(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\config\profile.py", line 325, in from_raw_profile_info
    credentials: Credentials = cls._credentials_from_profile(
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\config\profile.py", line 149, in _credentials_from_profile
    cls = load_plugin(typename)
          ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\adapters\factory.py", line 239, in load_plugin
    return FACTORY.load_plugin(name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\adapters\factory.py", line 68, in load_plugin
    mod: Any = import_module("." + name, "dbt.adapters")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\AppData\Local\Programs\Python\Python312\Lib\importlib\__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\adapters\bigquery\__init__.py", line 5, in <module>
    from dbt.adapters.bigquery.impl import BigQueryAdapter, GrantTarget, PartitionConfig  # noqa
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\adapters\bigquery\impl.py", line 49, in <module>
    from dbt.adapters.bigquery.python_submissions import (
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\dbt\adapters\bigquery\python_submissions.py", line 12, in <module>
    from google.cloud import storage, dataproc_v1  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\google\cloud\dataproc_v1\__init__.py", line 43, in <module>
    from .services.workflow_template_service import (
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\google\cloud\dataproc_v1\services\workflow_template_service\__init__.py", line 16, in <module>
    from .async_client import WorkflowTemplateServiceAsyncClient
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\google\cloud\dataproc_v1\services\workflow_template_service\async_client.py", line 57, in <module>
    from .client import WorkflowTemplateServiceClient
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\google\cloud\dataproc_v1\services\workflow_template_service\client.py", line 63, in <module>
    from .transports.base import DEFAULT_CLIENT_INFO, WorkflowTemplateServiceTransport
  File "C:\Users\lenovo\data-engineer-project\.venv\Lib\site-packages\google\cloud\dataproc_v1\services\workflow_template_service\transports\__init__.py", line 20, in <module>
    from .grpc import WorkflowTemplateServiceGrpcTransport
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1087, in get_code
  File "<frozen importlib._bootstrap_external>", line 1187, in get_data
KeyboardInterrupt

[0m11:27:23.639103 [debug] [MainThread]: Command `dbt run` failed at 11:27:23.639103 after 3.68 seconds
[0m11:27:23.639103 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000254DC7EEA20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000254E5A8FB30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000254E713CCE0>]}
[0m11:27:23.639103 [debug] [MainThread]: Flushing usage events
[0m11:27:33.296163 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024212C648C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024215768EC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024215813C80>]}


============================== 11:27:33.311793 | d51fd181-8c20-4c62-8eb4-90f7e1b6fb5a ==============================
[0m11:27:33.311793 [info ] [MainThread]: Running with dbt=1.8.7
[0m11:27:33.311793 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run -s sales_items.sql --full-refresh', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m11:27:35.948677 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd51fd181-8c20-4c62-8eb4-90f7e1b6fb5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002422046A8A0>]}
[0m11:27:36.017789 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd51fd181-8c20-4c62-8eb4-90f7e1b6fb5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000242159B8230>]}
[0m11:27:36.017789 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m11:27:36.033381 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m11:27:36.503077 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:27:36.518694 [debug] [MainThread]: Partial parsing: updated file: dbt_data_pipeline://dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m11:27:36.750125 [error] [MainThread]: Encountered an error:
Compilation Error in model sales_items (dbt_data_pipeline/models\dataproducts\sales_items.sql)
  invalid syntax for function call expression
    line 3
      config(
[0m11:27:36.765748 [debug] [MainThread]: Command `dbt run` failed at 11:27:36.765748 after 3.70 seconds
[0m11:27:36.765748 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024212C648C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000242159B9370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024220750890>]}
[0m11:27:36.765748 [debug] [MainThread]: Flushing usage events
[0m11:28:58.129494 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000243B07DFFB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000243B07DC8C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000243B07DC9E0>]}


============================== 11:28:58.129494 | a3e22463-d31e-4ac7-8d34-9ea820c60301 ==============================
[0m11:28:58.129494 [info ] [MainThread]: Running with dbt=1.8.7
[0m11:28:58.129494 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run -s sales_items.sql --full-refresh', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m11:29:01.206404 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a3e22463-d31e-4ac7-8d34-9ea820c60301', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000243BB0EACC0>]}
[0m11:29:01.339995 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a3e22463-d31e-4ac7-8d34-9ea820c60301', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000243AE41D5B0>]}
[0m11:29:01.339995 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m11:29:01.355622 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m11:29:02.008718 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:29:02.008718 [debug] [MainThread]: Partial parsing: updated file: dbt_data_pipeline://dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m11:29:02.581697 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_data_pipeline.datalake
[0m11:29:02.610343 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a3e22463-d31e-4ac7-8d34-9ea820c60301', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000243B98BF2C0>]}
[0m11:29:02.810910 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a3e22463-d31e-4ac7-8d34-9ea820c60301', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000243BB7FE0C0>]}
[0m11:29:02.810910 [info ] [MainThread]: Found 6 models, 4 data tests, 3 sources, 484 macros
[0m11:29:02.826551 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a3e22463-d31e-4ac7-8d34-9ea820c60301', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000243B0073650>]}
[0m11:29:02.826551 [info ] [MainThread]: 
[0m11:29:02.826551 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:29:02.826551 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m11:29:02.826551 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:29:05.966088 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_hub'
[0m11:29:05.966088 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:29:06.151586 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_hub, now list_dataengineerproject-439609_dp_dataproducts)
[0m11:29:06.151586 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:29:06.335967 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_dataproducts, now list_dataengineerproject-439609_dp)
[0m11:29:06.335967 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:29:06.837731 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a3e22463-d31e-4ac7-8d34-9ea820c60301', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000243BB6C56A0>]}
[0m11:29:06.837731 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:29:06.837731 [info ] [MainThread]: 
[0m11:29:06.853055 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.sales_items
[0m11:29:06.853055 [info ] [Thread-1 (]: 1 of 1 START sql incremental model dp_dataproducts.sales_items ................. [RUN]
[0m11:29:06.853055 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.sales_items'
[0m11:29:06.853055 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.sales_items
[0m11:29:06.853055 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.sales_items"
[0m11:29:06.868671 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.sales_items
[0m11:29:06.953375 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.sales_items"
[0m11:29:06.969056 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:29:06.969056 [debug] [Thread-1 (]: On model.dbt_data_pipeline.sales_items: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.sales_items"} */

  
    

    create or replace table `dataengineerproject-439609`.`dp_dataproducts`.`sales_items`
      
    partition by timestamp_trunc(sales_datetime, day)
    

    OPTIONS()
    as (
      -- Config pour indiquer le modèle incrémental


-- Extraction des informations nécessaires pour chaque vente et chaque produit
WITH expanded_sales AS (
    SELECT
        CONCAT(CAST(s.id AS STRING), '_', i.product_sku) AS pk,  -- Clé primaire unique pour chaque vente
        s.datetime AS sales_datetime,  -- Date de la vente
        i.amount AS item_amount,  -- Montant total par produit et par vente
        i.product_sku AS product_sku,  -- SKU du produit vendu
        i.quantity AS item_quantity,  -- Quantité d'items vendus
        p.description AS product_description,  -- Description du produit
        ((p.unit_amount - i.amount) / p.unit_amount) * 100 AS discount_perc  -- Pourcentage de réduction
    FROM `dataengineerproject-439609`.`dp_hub`.`sales_staging` AS s,
    UNNEST(s.items) AS i  -- Déballer les items
    LEFT JOIN `dataengineerproject-439609`.`dp_hub`.`products_staging` AS p
    ON i.product_sku = p.product_sku  -- Associer la description des produits
)

-- Insertions et mises à jour
SELECT *
FROM expanded_sales
    );
  
[0m11:29:07.655448 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:d181905b-a8a3-4313-8ed8-2d0fb81836d9&page=queryresults
[0m11:29:07.756076 [debug] [Thread-1 (]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Name items not found inside s at [27:14]; reason: invalidQuery, location: query, message: Name items not found inside s at [27:14]')
[0m11:29:08.890740 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:aa32fc50-9585-4824-bdfe-5796e0d14c99&page=queryresults
[0m11:29:08.990303 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:aa32fc50-9585-4824-bdfe-5796e0d14c99&page=queryresults
[0m11:29:09.005875 [debug] [Thread-1 (]: Database Error in model sales_items (dbt_data_pipeline/models\dataproducts\sales_items.sql)
  Name items not found inside s at [27:14]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m11:29:09.005875 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3e22463-d31e-4ac7-8d34-9ea820c60301', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000243B0071970>]}
[0m11:29:09.005875 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model dp_dataproducts.sales_items ........ [[31mERROR[0m in 2.15s]
[0m11:29:09.005875 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.sales_items
[0m11:29:09.021502 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:29:09.021502 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m11:29:09.021502 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp' was properly closed.
[0m11:29:09.021502 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.sales_items' was properly closed.
[0m11:29:09.028015 [info ] [MainThread]: 
[0m11:29:09.028015 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 6.20 seconds (6.20s).
[0m11:29:09.028015 [debug] [MainThread]: Command end result
[0m11:29:09.143947 [info ] [MainThread]: 
[0m11:29:09.143947 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m11:29:09.143947 [info ] [MainThread]: 
[0m11:29:09.159576 [error] [MainThread]:   Database Error in model sales_items (dbt_data_pipeline/models\dataproducts\sales_items.sql)
  Name items not found inside s at [27:14]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m11:29:09.159576 [info ] [MainThread]: 
[0m11:29:09.159576 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m11:29:09.159576 [debug] [MainThread]: Command `dbt run` failed at 11:29:09.159576 after 11.27 seconds
[0m11:29:09.159576 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000243B06AA840>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000243ACDEF2F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000243B8A19B80>]}
[0m11:29:09.159576 [debug] [MainThread]: Flushing usage events
[0m11:31:35.554995 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E72F62B5C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E7317557F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E72E7199D0>]}


============================== 11:31:35.554995 | 0d50d982-7b8d-4ca5-a7fb-a518c14042f4 ==============================
[0m11:31:35.554995 [info ] [MainThread]: Running with dbt=1.8.7
[0m11:31:35.554995 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt run -s sales_items.sql --full-refresh', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:31:39.003314 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0d50d982-7b8d-4ca5-a7fb-a518c14042f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E73B4FCAD0>]}
[0m11:31:39.072363 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0d50d982-7b8d-4ca5-a7fb-a518c14042f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E731FDBBC0>]}
[0m11:31:39.072363 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m11:31:39.088011 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m11:31:39.536016 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:31:39.536016 [debug] [MainThread]: Partial parsing: updated file: dbt_data_pipeline://dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m11:31:39.874698 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_data_pipeline.datalake
[0m11:31:39.905971 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0d50d982-7b8d-4ca5-a7fb-a518c14042f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E73D016120>]}
[0m11:31:40.075316 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0d50d982-7b8d-4ca5-a7fb-a518c14042f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E73D038440>]}
[0m11:31:40.075316 [info ] [MainThread]: Found 6 models, 4 data tests, 3 sources, 484 macros
[0m11:31:40.075316 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0d50d982-7b8d-4ca5-a7fb-a518c14042f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E73CD2E000>]}
[0m11:31:40.075316 [info ] [MainThread]: 
[0m11:31:40.075316 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:31:40.090956 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m11:31:40.090956 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:31:42.793534 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_dataproducts'
[0m11:31:42.793534 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:31:42.909521 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_dataproducts, now list_dataengineerproject-439609_dp)
[0m11:31:42.909521 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:31:43.511552 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp, now list_dataengineerproject-439609_dp_hub)
[0m11:31:43.511552 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:31:43.626918 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0d50d982-7b8d-4ca5-a7fb-a518c14042f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E72FBED6A0>]}
[0m11:31:43.626918 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:31:43.626918 [info ] [MainThread]: 
[0m11:31:43.626918 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.sales_items
[0m11:31:43.626918 [info ] [Thread-1 (]: 1 of 1 START sql incremental model dp_dataproducts.sales_items ................. [RUN]
[0m11:31:43.626918 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.sales_items'
[0m11:31:43.642486 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.sales_items
[0m11:31:43.642486 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.sales_items"
[0m11:31:43.642486 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.sales_items
[0m11:31:43.742825 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.sales_items"
[0m11:31:43.758490 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:31:43.758490 [debug] [Thread-1 (]: On model.dbt_data_pipeline.sales_items: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.sales_items"} */

  
    

    create or replace table `dataengineerproject-439609`.`dp_dataproducts`.`sales_items`
      
    partition by timestamp_trunc(sales_datetime, day)
    

    OPTIONS()
    as (
      -- Config pour indiquer le modèle incrémental


-- Extraction des informations nécessaires pour chaque vente et chaque produit
    SELECT
        CONCAT(CAST(s.id AS STRING), '_', s.product_sku) AS pk,  -- Clé primaire unique pour chaque vente
        s.sales_datetime,  -- Date de la vente
        s.item_amount,  -- Montant total par produit et par vente
        s.product_sku,  -- SKU du produit vendu
        s.item_quantity,  -- Quantité d'items vendus
        p.product_description,  -- Description du produit
        ((p.unit_amount - s.item_amount) / p.unit_amount) * 100 AS discount_perc  -- Pourcentage de réduction
    FROM `dataengineerproject-439609`.`dp_hub`.`sales_staging` AS s,
    LEFT JOIN `dataengineerproject-439609`.`dp_hub`.`products_staging` AS p
    ON i.product_sku = p.product_sku  -- Associer la description des produits
    );
  
[0m11:31:44.013198 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:af00de56-b5e9-47e8-9837-6cce5a78cad9&page=queryresults
[0m11:31:44.028838 [debug] [Thread-1 (]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Syntax error: Unexpected keyword LEFT at [26:5]; reason: invalidQuery, location: query, message: Syntax error: Unexpected keyword LEFT at [26:5]')
[0m11:31:44.530299 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:acd353c9-0ee4-42e3-b689-4dffc6adfb03&page=queryresults
[0m11:31:44.530299 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:acd353c9-0ee4-42e3-b689-4dffc6adfb03&page=queryresults
[0m11:31:44.561499 [debug] [Thread-1 (]: Database Error in model sales_items (dbt_data_pipeline/models\dataproducts\sales_items.sql)
  Syntax error: Unexpected keyword LEFT at [26:5]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m11:31:44.561499 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0d50d982-7b8d-4ca5-a7fb-a518c14042f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E73CF4A930>]}
[0m11:31:44.561499 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model dp_dataproducts.sales_items ........ [[31mERROR[0m in 0.93s]
[0m11:31:44.561499 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.sales_items
[0m11:31:44.561499 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:31:44.577117 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m11:31:44.577117 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_hub' was properly closed.
[0m11:31:44.577117 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.sales_items' was properly closed.
[0m11:31:44.577117 [info ] [MainThread]: 
[0m11:31:44.583632 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.50 seconds (4.50s).
[0m11:31:44.583632 [debug] [MainThread]: Command end result
[0m11:31:44.762065 [info ] [MainThread]: 
[0m11:31:44.762065 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m11:31:44.762065 [info ] [MainThread]: 
[0m11:31:44.762065 [error] [MainThread]:   Database Error in model sales_items (dbt_data_pipeline/models\dataproducts\sales_items.sql)
  Syntax error: Unexpected keyword LEFT at [26:5]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m11:31:44.762065 [info ] [MainThread]: 
[0m11:31:44.762065 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m11:31:44.777993 [debug] [MainThread]: Command `dbt run` failed at 11:31:44.777993 after 9.57 seconds
[0m11:31:44.777993 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E731C411F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E731C42C60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E731DFCE00>]}
[0m11:31:44.784002 [debug] [MainThread]: Flushing usage events
[0m11:33:00.268653 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A8C674D3D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A8C5AD9820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A8C93191C0>]}


============================== 11:33:00.280751 | a5910ae9-2af5-4e90-a746-437b1f1adcc6 ==============================
[0m11:33:00.280751 [info ] [MainThread]: Running with dbt=1.8.7
[0m11:33:00.280751 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run -s sales_items.sql --full-refresh', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:33:03.906148 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a5910ae9-2af5-4e90-a746-437b1f1adcc6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A8C9447B00>]}
[0m11:33:03.996994 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a5910ae9-2af5-4e90-a746-437b1f1adcc6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A8C6ECDA90>]}
[0m11:33:03.996994 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m11:33:04.012612 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m11:33:04.460596 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:33:04.476227 [debug] [MainThread]: Partial parsing: updated file: dbt_data_pipeline://dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m11:33:04.808429 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_data_pipeline.datalake
[0m11:33:04.824101 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a5910ae9-2af5-4e90-a746-437b1f1adcc6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A8D4397620>]}
[0m11:33:05.024661 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a5910ae9-2af5-4e90-a746-437b1f1adcc6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A8D43B1070>]}
[0m11:33:05.031174 [info ] [MainThread]: Found 6 models, 4 data tests, 3 sources, 484 macros
[0m11:33:05.031174 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a5910ae9-2af5-4e90-a746-437b1f1adcc6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A8D43743E0>]}
[0m11:33:05.031174 [info ] [MainThread]: 
[0m11:33:05.031174 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:33:05.031174 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m11:33:05.031174 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:33:07.817648 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp'
[0m11:33:07.817648 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:33:08.403696 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp, now list_dataengineerproject-439609_dp_hub)
[0m11:33:08.403696 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:33:08.604241 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_hub, now list_dataengineerproject-439609_dp_dataproducts)
[0m11:33:08.604241 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:33:08.704878 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a5910ae9-2af5-4e90-a746-437b1f1adcc6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A8C6F2D910>]}
[0m11:33:08.704878 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:33:08.704878 [info ] [MainThread]: 
[0m11:33:08.720188 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.sales_items
[0m11:33:08.720188 [info ] [Thread-1 (]: 1 of 1 START sql incremental model dp_dataproducts.sales_items ................. [RUN]
[0m11:33:08.720188 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.sales_items'
[0m11:33:08.720188 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.sales_items
[0m11:33:08.735821 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.sales_items"
[0m11:33:08.742367 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.sales_items
[0m11:33:08.820514 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.sales_items"
[0m11:33:08.836145 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:33:08.836145 [debug] [Thread-1 (]: On model.dbt_data_pipeline.sales_items: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.sales_items"} */

  
    

    create or replace table `dataengineerproject-439609`.`dp_dataproducts`.`sales_items`
      
    partition by timestamp_trunc(sales_datetime, day)
    

    OPTIONS()
    as (
      -- Config pour indiquer le modèle incrémental


-- Extraction des informations nécessaires pour chaque vente et chaque produit
    SELECT
        CONCAT(CAST(s.id AS STRING), '_', s.product_sku) AS pk,  -- Clé primaire unique pour chaque vente
        s.sales_datetime,  -- Date de la vente
        s.item_amount,  -- Montant total par produit et par vente
        s.product_sku,  -- SKU du produit vendu
        s.item_quantity,  -- Quantité d'items vendus
        p.product_description,  -- Description du produit
        ((p.unit_amount - s.item_amount) / p.unit_amount) * 100 AS discount_perc  -- Pourcentage de réduction
    FROM `dataengineerproject-439609`.`dp_hub`.`sales_staging` AS s
    LEFT JOIN `dataengineerproject-439609`.`dp_hub`.`products_staging` AS p
    ON s.product_sku = p.product_sku  -- Associer la description des produits
    );
  
[0m11:33:09.444853 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:12553d16-5009-4b4b-bba6-f82a9f37f70a&page=queryresults
[0m11:33:09.523644 [debug] [Thread-1 (]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Name product_sku not found inside s at [27:10]; reason: invalidQuery, location: query, message: Name product_sku not found inside s at [27:10]')
[0m11:33:10.850408 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:b8613550-5f93-40cb-8733-56cedd3f00bf&page=queryresults
[0m11:33:10.982004 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:b8613550-5f93-40cb-8733-56cedd3f00bf&page=queryresults
[0m11:33:10.997627 [debug] [Thread-1 (]: Database Error in model sales_items (dbt_data_pipeline/models\dataproducts\sales_items.sql)
  Name product_sku not found inside s at [27:10]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m11:33:11.013286 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a5910ae9-2af5-4e90-a746-437b1f1adcc6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A8C8B7D9D0>]}
[0m11:33:11.013286 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model dp_dataproducts.sales_items ........ [[31mERROR[0m in 2.28s]
[0m11:33:11.013286 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.sales_items
[0m11:33:11.013286 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:33:11.013286 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m11:33:11.013286 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_dataproducts' was properly closed.
[0m11:33:11.013286 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.sales_items' was properly closed.
[0m11:33:11.013286 [info ] [MainThread]: 
[0m11:33:11.013286 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 5.98 seconds (5.98s).
[0m11:33:11.013286 [debug] [MainThread]: Command end result
[0m11:33:11.144828 [info ] [MainThread]: 
[0m11:33:11.144828 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m11:33:11.144828 [info ] [MainThread]: 
[0m11:33:11.144828 [error] [MainThread]:   Database Error in model sales_items (dbt_data_pipeline/models\dataproducts\sales_items.sql)
  Name product_sku not found inside s at [27:10]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m11:33:11.144828 [info ] [MainThread]: 
[0m11:33:11.151374 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m11:33:11.151374 [debug] [MainThread]: Command `dbt run` failed at 11:33:11.151374 after 11.33 seconds
[0m11:33:11.151374 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A8C674D3D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A8C8C0CC20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A8C8C0ED80>]}
[0m11:33:11.151374 [debug] [MainThread]: Flushing usage events
[0m11:33:51.014069 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE310FF650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE2BDD28D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE31D28EC0>]}


============================== 11:33:51.014069 | 25a72785-9541-4787-ba66-b83d986851e2 ==============================
[0m11:33:51.014069 [info ] [MainThread]: Running with dbt=1.8.7
[0m11:33:51.014069 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt run -s sales_items.sql --full-refresh', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:33:53.953401 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '25a72785-9541-4787-ba66-b83d986851e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE31D7C1A0>]}
[0m11:33:54.022442 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '25a72785-9541-4787-ba66-b83d986851e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE3C822F60>]}
[0m11:33:54.022442 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m11:33:54.038067 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m11:33:54.454624 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:33:54.454624 [debug] [MainThread]: Partial parsing: updated file: dbt_data_pipeline://dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m11:33:54.771132 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_data_pipeline.datalake
[0m11:33:54.786769 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '25a72785-9541-4787-ba66-b83d986851e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE3CC755E0>]}
[0m11:33:55.025115 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '25a72785-9541-4787-ba66-b83d986851e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE3CC90C80>]}
[0m11:33:55.025115 [info ] [MainThread]: Found 6 models, 4 data tests, 3 sources, 484 macros
[0m11:33:55.025115 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '25a72785-9541-4787-ba66-b83d986851e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE3CC69340>]}
[0m11:33:55.025115 [info ] [MainThread]: 
[0m11:33:55.025115 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:33:55.040742 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m11:33:55.040742 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:33:57.664478 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_hub'
[0m11:33:57.664478 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:33:57.781164 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_hub, now list_dataengineerproject-439609_dp)
[0m11:33:57.781164 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:33:58.267500 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp, now list_dataengineerproject-439609_dp_dataproducts)
[0m11:33:58.267500 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:33:58.369103 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '25a72785-9541-4787-ba66-b83d986851e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE3C867080>]}
[0m11:33:58.369103 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:33:58.369103 [info ] [MainThread]: 
[0m11:33:58.384065 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.sales_items
[0m11:33:58.384065 [info ] [Thread-1 (]: 1 of 1 START sql incremental model dp_dataproducts.sales_items ................. [RUN]
[0m11:33:58.384065 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.sales_items'
[0m11:33:58.384065 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.sales_items
[0m11:33:58.399687 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.sales_items"
[0m11:33:58.399687 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.sales_items
[0m11:33:58.515588 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.sales_items"
[0m11:33:58.515588 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:33:58.522098 [debug] [Thread-1 (]: On model.dbt_data_pipeline.sales_items: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.sales_items"} */

  
    

    create or replace table `dataengineerproject-439609`.`dp_dataproducts`.`sales_items`
      
    partition by timestamp_trunc(sales_datetime, day)
    

    OPTIONS()
    as (
      -- Config pour indiquer le modèle incrémental


-- Extraction des informations nécessaires pour chaque vente et chaque produit
    SELECT
        CONCAT(CAST(s.id AS STRING), '_', s.item_product_sku) AS pk,  -- Clé primaire unique pour chaque vente
        s.sales_datetime,  -- Date de la vente
        s.item_amount,  -- Montant total par produit et par vente
        s.item_product_sku,  -- SKU du produit vendu
        s.item_quantity,  -- Quantité d'items vendus
        p.product_description,  -- Description du produit
        ((p.unit_amount - s.item_amount) / p.unit_amount) * 100 AS discount_perc  -- Pourcentage de réduction
    FROM `dataengineerproject-439609`.`dp_hub`.`sales_staging` AS s
    LEFT JOIN `dataengineerproject-439609`.`dp_hub`.`products_staging` AS p
    ON s.item_product_sku = p.product_sku  -- Associer la description des produits
    );
  
[0m11:33:59.201304 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:8645f1e6-7c6f-48e1-90fe-8de5aad64f53&page=queryresults
[0m11:34:00.959337 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '25a72785-9541-4787-ba66-b83d986851e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE3AD7A870>]}
[0m11:34:00.959337 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model dp_dataproducts.sales_items ............ [[32mCREATE TABLE (2.0 rows, 1.5 KiB processed)[0m in 2.58s]
[0m11:34:00.959337 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.sales_items
[0m11:34:00.959337 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:34:00.974962 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m11:34:00.974962 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_dataproducts' was properly closed.
[0m11:34:00.974962 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.sales_items' was properly closed.
[0m11:34:00.974962 [info ] [MainThread]: 
[0m11:34:00.974962 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 5.95 seconds (5.95s).
[0m11:34:00.974962 [debug] [MainThread]: Command end result
[0m11:34:01.159901 [info ] [MainThread]: 
[0m11:34:01.159901 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:34:01.159901 [info ] [MainThread]: 
[0m11:34:01.175526 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m11:34:01.175526 [debug] [MainThread]: Command `dbt run` succeeded at 11:34:01.175526 after 10.44 seconds
[0m11:34:01.175526 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE315DD0A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE30FC30B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002DE2BDD28D0>]}
[0m11:34:01.175526 [debug] [MainThread]: Flushing usage events
[0m11:39:53.246387 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002EEB979B170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002EEB9F3CBC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002EEB9F3CCB0>]}


============================== 11:39:53.262013 | d4f3f5fa-6590-453f-87d2-8b5e20ae0e63 ==============================
[0m11:39:53.262013 [info ] [MainThread]: Running with dbt=1.8.7
[0m11:39:53.262013 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run -s sales_items.sql --full-refresh', 'send_anonymous_usage_stats': 'True'}
[0m11:39:56.788238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd4f3f5fa-6590-453f-87d2-8b5e20ae0e63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002EEC1FC1E20>]}
[0m11:39:56.872943 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd4f3f5fa-6590-453f-87d2-8b5e20ae0e63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002EEB9F3CBC0>]}
[0m11:39:56.888536 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m11:39:56.904164 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m11:39:57.481272 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:39:57.527669 [debug] [MainThread]: Partial parsing: updated file: dbt_data_pipeline://dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m11:39:58.652859 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_data_pipeline.datalake
[0m11:39:58.697863 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd4f3f5fa-6590-453f-87d2-8b5e20ae0e63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002EEC4F3A1B0>]}
[0m11:39:59.203848 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd4f3f5fa-6590-453f-87d2-8b5e20ae0e63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002EEC4F61A00>]}
[0m11:39:59.206849 [info ] [MainThread]: Found 6 models, 4 data tests, 3 sources, 484 macros
[0m11:39:59.208848 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd4f3f5fa-6590-453f-87d2-8b5e20ae0e63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002EEC4BDC050>]}
[0m11:39:59.222847 [info ] [MainThread]: 
[0m11:39:59.224848 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m11:39:59.236846 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m11:39:59.238849 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:40:04.511307 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp'
[0m11:40:04.512305 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:40:04.996024 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp, now list_dataengineerproject-439609_dp_dataproducts)
[0m11:40:04.997993 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:40:05.184972 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_dataproducts, now list_dataengineerproject-439609_dp_hub)
[0m11:40:05.186971 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:40:05.327985 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd4f3f5fa-6590-453f-87d2-8b5e20ae0e63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002EEB7AFD910>]}
[0m11:40:05.328983 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:40:05.329984 [info ] [MainThread]: 
[0m11:40:05.337217 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.sales_items
[0m11:40:05.339221 [info ] [Thread-1 (]: 1 of 1 START sql incremental model dp_dataproducts.sales_items ................. [RUN]
[0m11:40:05.340226 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.sales_items'
[0m11:40:05.341230 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.sales_items
[0m11:40:05.361303 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.sales_items"
[0m11:40:05.367292 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.sales_items
[0m11:40:05.450420 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:40:05.704523 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.sales_items"
[0m11:40:05.709521 [debug] [Thread-1 (]: On model.dbt_data_pipeline.sales_items: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.sales_items"} */

  
    

    create or replace table `dataengineerproject-439609`.`dp_dataproducts`.`sales_items`
      
    partition by timestamp_trunc(sales_datetime, day)
    

    OPTIONS()
    as (
      -- Config pour indiquer le modèle incrémental


-- Extraction des informations nécessaires pour chaque vente et chaque produit
    SELECT
        CONCAT(CAST(s.id AS STRING), '_', s.item_product_sku) AS pk,  -- Clé primaire unique pour chaque vente
        safe_cast(s.sales_datetime AS datetime) AS sales_datetime,  -- Date de la vente
        s.item_amount,  -- Montant total par produit et par vente
        s.item_product_sku AS product_sku,  -- SKU du produit vendu
        s.item_quantity,  -- Quantité d'items vendus
        p.product_description,  -- Description du produit
        ((p.unit_amount - s.item_amount) / p.unit_amount) * 100 AS discount_perc  -- Pourcentage de réduction
    FROM `dataengineerproject-439609`.`dp_hub`.`sales_staging` AS s
    LEFT JOIN `dataengineerproject-439609`.`dp_hub`.`products_staging` AS p
    ON s.item_product_sku = p.product_sku  -- Associer la description des produits
    );
  
[0m11:40:06.224172 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:06633d39-bf6b-4e5c-9d0c-6cdfdc5a44e8&page=queryresults
[0m11:40:07.910220 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd4f3f5fa-6590-453f-87d2-8b5e20ae0e63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002EEC303AA80>]}
[0m11:40:07.912230 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model dp_dataproducts.sales_items ............ [[32mCREATE TABLE (2.0 rows, 1.5 KiB processed)[0m in 2.57s]
[0m11:40:07.914236 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.sales_items
[0m11:40:07.917363 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:40:07.918368 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m11:40:07.920368 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_hub' was properly closed.
[0m11:40:07.921366 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.sales_items' was properly closed.
[0m11:40:07.922366 [info ] [MainThread]: 
[0m11:40:07.923364 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 8.70 seconds (8.70s).
[0m11:40:07.929196 [debug] [MainThread]: Command end result
[0m11:40:08.186852 [info ] [MainThread]: 
[0m11:40:08.196095 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:40:08.198092 [info ] [MainThread]: 
[0m11:40:08.200121 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m11:40:08.212813 [debug] [MainThread]: Command `dbt run` succeeded at 11:40:08.212813 after 15.45 seconds
[0m11:40:08.212813 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002EEB9300B30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002EEC3149A60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002EEB9717AA0>]}
[0m11:40:08.212813 [debug] [MainThread]: Flushing usage events
[0m19:06:52.514223 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001405A73D7F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014057F8EE70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001405A8BB1A0>]}


============================== 19:06:52.529846 | 874b9ba9-772b-485e-a897-b98163f437a6 ==============================
[0m19:06:52.529846 [info ] [MainThread]: Running with dbt=1.8.7
[0m19:06:52.529846 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': 'C:/Users/lenovo/.dbt', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --profiles-dir C:/Users/lenovo/.dbt', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m19:06:58.762298 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '874b9ba9-772b-485e-a897-b98163f437a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001405A6AE570>]}
[0m19:06:59.281652 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '874b9ba9-772b-485e-a897-b98163f437a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014062CC53A0>]}
[0m19:06:59.291743 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m19:06:59.352762 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m19:07:01.401170 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:07:01.401170 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:07:01.416802 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_data_pipeline.datalake
[0m19:07:01.501487 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '874b9ba9-772b-485e-a897-b98163f437a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014065794D40>]}
[0m19:07:01.887005 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '874b9ba9-772b-485e-a897-b98163f437a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014065DA44A0>]}
[0m19:07:01.887005 [info ] [MainThread]: Found 6 models, 4 data tests, 3 sources, 484 macros
[0m19:07:01.887005 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '874b9ba9-772b-485e-a897-b98163f437a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001405A9E7EC0>]}
[0m19:07:01.887005 [info ] [MainThread]: 
[0m19:07:01.887005 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m19:07:01.887005 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m19:07:01.902646 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:07:04.810512 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:07:04.995262 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:07:05.142461 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609, now create_dataengineerproject-439609_dp)
[0m19:07:05.142461 [debug] [ThreadPool]: Creating schema "database: "dataengineerproject-439609"
schema: "dp"
"
[0m19:07:05.157691 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:07:05.157691 [debug] [ThreadPool]: On create_dataengineerproject-439609_dp: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "connection_name": "create_dataengineerproject-439609_dp"} */
create schema if not exists `dataengineerproject-439609`.`dp`
  
[0m19:07:05.396128 [debug] [ThreadPool]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:938bc9b8-4293-4133-83cd-d5a050377ede&page=queryresults
[0m19:07:06.877681 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp'
[0m19:07:06.877681 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:07:07.031699 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp, now list_dataengineerproject-439609_dp_dataproducts)
[0m19:07:07.031699 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:07:07.147241 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_dataproducts, now list_dataengineerproject-439609_dp_hub)
[0m19:07:07.147241 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:07:07.263618 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '874b9ba9-772b-485e-a897-b98163f437a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014065D7EA80>]}
[0m19:07:07.263618 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:07:07.263618 [info ] [MainThread]: 
[0m19:07:07.278593 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.customers_staging
[0m19:07:07.278593 [info ] [Thread-1 (]: 1 of 6 START sql view model dp_hub.customers_staging ........................... [RUN]
[0m19:07:07.278593 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.customers_staging'
[0m19:07:07.278593 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.customers_staging
[0m19:07:07.294236 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.customers_staging"
[0m19:07:07.294236 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.customers_staging
[0m19:07:07.316401 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.customers_staging"
[0m19:07:07.332023 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m19:07:07.332023 [debug] [Thread-1 (]: On model.dbt_data_pipeline.customers_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.customers_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_hub`.`customers_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


WITH standardized_customers AS (
    SELECT
        *,
        -- Normalisation des numéros de téléphone
        ARRAY(
            SELECT
                CASE
                    WHEN REGEXP_CONTAINS(phone_number, r'^\+33') THEN phone_number
                    WHEN REGEXP_CONTAINS(phone_number, r'^0') THEN '+33' || SUBSTR(REGEXP_REPLACE(phone_number, r'\D', ''), 2)  -- Remplacer 0 par +33
                    ELSE phone_number  -- Pour tout autre format, garder tel quel (potentiellement à adapter pour d'autres cas)
                END AS standardized_phone_number
            FROM UNNEST(phone_numbers) AS phone_number
        ) AS standardized_phone_numbers,

        -- Normalisation des adresses e-mail (en minuscules pour consistance)
        ARRAY(
            SELECT LOWER(email)
            FROM UNNEST(emails) AS email
        ) AS standardized_emails
    FROM `dataengineerproject-439609`.`dp_lake`.`customers_normalized`
),

ranked_customers AS (
    SELECT
        *,
        ROW_NUMBER() OVER (
            PARTITION BY customer_id
            ORDER BY _dp_ingestion_timestamp DESC
        ) AS row_num
    FROM standardized_customers
)

-- Sélectionner uniquement les enregistrements uniques les plus récents
SELECT
    _dp_ingestion_timestamp,
    customer_id,
    standardized_emails AS emails,
    standardized_phone_numbers AS phone_numbers

FROM
    ranked_customers
WHERE
    row_num = 1;


[0m19:07:07.564272 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:fc4dab61-65d8-4331-a5aa-5f5b6f71a33a&page=queryresults
[0m19:07:07.817239 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '874b9ba9-772b-485e-a897-b98163f437a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014065E43F50>]}
[0m19:07:07.817239 [info ] [Thread-1 (]: 1 of 6 OK created sql view model dp_hub.customers_staging ...................... [[32mCREATE VIEW (0 processed)[0m in 0.54s]
[0m19:07:07.817239 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.customers_staging
[0m19:07:07.817239 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.my_first_dbt_model
[0m19:07:07.817239 [info ] [Thread-1 (]: 2 of 6 START sql table model dp.my_first_dbt_model ............................. [RUN]
[0m19:07:07.817239 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_data_pipeline.customers_staging, now model.dbt_data_pipeline.my_first_dbt_model)
[0m19:07:07.817239 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.my_first_dbt_model
[0m19:07:07.832864 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.my_first_dbt_model"
[0m19:07:07.832864 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.my_first_dbt_model
[0m19:07:07.864175 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.my_first_dbt_model"
[0m19:07:07.864175 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:07:07.864175 [debug] [Thread-1 (]: On model.dbt_data_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.my_first_dbt_model"} */

  
    

    create or replace table `dataengineerproject-439609`.`dp`.`my_first_dbt_model`
      
    
    

    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m19:07:08.166234 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:2c9d96d0-1fbe-4547-99e2-e8887236d21f&page=queryresults
[0m19:07:10.571377 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '874b9ba9-772b-485e-a897-b98163f437a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014065B5FA70>]}
[0m19:07:10.571377 [info ] [Thread-1 (]: 2 of 6 OK created sql table model dp.my_first_dbt_model ........................ [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 2.75s]
[0m19:07:10.586346 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.my_first_dbt_model
[0m19:07:10.586346 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.products_staging
[0m19:07:10.586346 [info ] [Thread-1 (]: 3 of 6 START sql view model dp_hub.products_staging ............................ [RUN]
[0m19:07:10.586346 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_data_pipeline.my_first_dbt_model, now model.dbt_data_pipeline.products_staging)
[0m19:07:10.586346 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.products_staging
[0m19:07:10.586346 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.products_staging"
[0m19:07:10.586346 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.products_staging
[0m19:07:10.586346 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.products_staging"
[0m19:07:10.586346 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:07:10.602001 [debug] [Thread-1 (]: On model.dbt_data_pipeline.products_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.products_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_hub`.`products_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


WITH ranked_products AS (
    SELECT
        *,
        ROW_NUMBER() OVER (
            PARTITION BY product_sku
            ORDER BY _dp_ingestion_timestamp DESC
        ) AS row_num
    FROM `dataengineerproject-439609`.`dp_lake`.`products_normalized`
)

-- Sélectionner uniquement les enregistrements uniques les plus récents
SELECT
    _dp_ingestion_timestamp,
    product_sku,
    unit_amount,
    description AS product_description,
    supplier

FROM
    ranked_products
WHERE
    row_num = 1;


[0m19:07:10.856214 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:ca398cbe-75c2-4aab-8fd6-f27bdb6a51b3&page=queryresults
[0m19:07:11.040513 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '874b9ba9-772b-485e-a897-b98163f437a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014065ED8260>]}
[0m19:07:11.040513 [info ] [Thread-1 (]: 3 of 6 OK created sql view model dp_hub.products_staging ....................... [[32mCREATE VIEW (0 processed)[0m in 0.45s]
[0m19:07:11.040513 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.products_staging
[0m19:07:11.040513 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.sales_staging
[0m19:07:11.040513 [info ] [Thread-1 (]: 4 of 6 START sql view model dp_hub.sales_staging ............................... [RUN]
[0m19:07:11.040513 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_data_pipeline.products_staging, now model.dbt_data_pipeline.sales_staging)
[0m19:07:11.040513 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.sales_staging
[0m19:07:11.056098 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.sales_staging"
[0m19:07:11.056098 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.sales_staging
[0m19:07:11.056098 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.sales_staging"
[0m19:07:11.071721 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:07:11.071721 [debug] [Thread-1 (]: On model.dbt_data_pipeline.sales_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.sales_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_hub`.`sales_staging`
  OPTIONS()
  as -- Tag to indicate that this model is updated every hour


WITH ranked_sales AS (
    -- Assign a row number to each sale based on customer_id and timestamp, to keep the most recent entry
    SELECT
        *,
        ROW_NUMBER() OVER (
            PARTITION BY id
            ORDER BY _dp_ingestion_timestamp DESC
        ) AS row_num
    FROM `dataengineerproject-439609`.`dp_lake`.`sales_normalized`
),

-- Filter to only include the most recent entry for each sale (i.e., row_num = 1)
deduplicated_sales AS (
    SELECT *
    FROM ranked_sales
    WHERE row_num = 1
)

-- Flatten items array for each sale and select relevant fields
SELECT
    ds._dp_ingestion_timestamp,
    ds.id,
    ds.datetime AS sales_datetime,
    ds.customer_id,
    ds.total_amount,
    item.amount AS item_amount,
    item.quantity AS item_quantity,
    item.product_sku AS item_product_sku
FROM
    deduplicated_sales AS ds,
    UNNEST(ds.items) AS item;


[0m19:07:11.326005 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:20ff7f10-84d3-42d6-a5b2-1c4fcefaef63&page=queryresults
[0m19:07:11.488721 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '874b9ba9-772b-485e-a897-b98163f437a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014065EEDA30>]}
[0m19:07:11.488721 [info ] [Thread-1 (]: 4 of 6 OK created sql view model dp_hub.sales_staging .......................... [[32mCREATE VIEW (0 processed)[0m in 0.45s]
[0m19:07:11.488721 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.sales_staging
[0m19:07:11.488721 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.my_second_dbt_model
[0m19:07:11.488721 [info ] [Thread-1 (]: 5 of 6 START sql view model dp.my_second_dbt_model ............................. [RUN]
[0m19:07:11.488721 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_data_pipeline.sales_staging, now model.dbt_data_pipeline.my_second_dbt_model)
[0m19:07:11.488721 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.my_second_dbt_model
[0m19:07:11.503736 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.my_second_dbt_model"
[0m19:07:11.503736 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.my_second_dbt_model
[0m19:07:11.588479 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.my_second_dbt_model"
[0m19:07:11.588479 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:07:11.588479 [debug] [Thread-1 (]: On model.dbt_data_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.my_second_dbt_model"} */


  create or replace view `dataengineerproject-439609`.`dp`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `dataengineerproject-439609`.`dp`.`my_first_dbt_model`
where id = 1;


[0m19:07:11.842775 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:d98de578-775a-4d82-ac31-ca74ca81213f&page=queryresults
[0m19:07:12.058354 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '874b9ba9-772b-485e-a897-b98163f437a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014065D76870>]}
[0m19:07:12.058354 [info ] [Thread-1 (]: 5 of 6 OK created sql view model dp.my_second_dbt_model ........................ [[32mCREATE VIEW (0 processed)[0m in 0.57s]
[0m19:07:12.058354 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.my_second_dbt_model
[0m19:07:12.058354 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.sales_items
[0m19:07:12.058354 [info ] [Thread-1 (]: 6 of 6 START sql incremental model dp_dataproducts.sales_items ................. [RUN]
[0m19:07:12.058354 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_data_pipeline.my_second_dbt_model, now model.dbt_data_pipeline.sales_items)
[0m19:07:12.058354 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.sales_items
[0m19:07:12.058354 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.sales_items"
[0m19:07:12.074011 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.sales_items
[0m19:07:12.111765 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:07:12.290200 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.sales_items"
[0m19:07:12.290200 [debug] [Thread-1 (]: On model.dbt_data_pipeline.sales_items: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.sales_items"} */

   
      -- generated script to merge partitions into `dataengineerproject-439609`.`dp_dataproducts`.`sales_items`
      declare dbt_partitions_for_replacement array<timestamp>;

      
      
       -- 1. create a temp table with model data
        
  
    

    create or replace table `dataengineerproject-439609`.`dp_dataproducts`.`sales_items__dbt_tmp`
      
    partition by timestamp_trunc(sales_datetime, day)
    

    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      -- Config pour indiquer le modèle incrémental


-- Extraction des informations nécessaires pour chaque vente et chaque produit
    SELECT
        CONCAT(CAST(s.id AS STRING), '_', s.item_product_sku) AS pk,  -- Clé primaire unique pour chaque vente
        safe_cast(s.sales_datetime AS datetime) AS sales_datetime,  -- Date de la vente
        s.item_amount,  -- Montant total par produit et par vente
        s.item_product_sku AS product_sku,  -- SKU du produit vendu
        s.item_quantity,  -- Quantité d'items vendus
        p.product_description,  -- Description du produit
        ((p.unit_amount - s.item_amount) / p.unit_amount) * 100 AS discount_perc  -- Pourcentage de réduction
    FROM `dataengineerproject-439609`.`dp_hub`.`sales_staging` AS s
    LEFT JOIN `dataengineerproject-439609`.`dp_hub`.`products_staging` AS p
    ON s.item_product_sku = p.product_sku  -- Associer la description des produits
    );
  
      -- 2. define partitions to update
      set (dbt_partitions_for_replacement) = (
          select as struct
              -- IGNORE NULLS: this needs to be aligned to _dbt_max_partition, which ignores null
              array_agg(distinct timestamp_trunc(sales_datetime, day) IGNORE NULLS)
          from `dataengineerproject-439609`.`dp_dataproducts`.`sales_items__dbt_tmp`
      );

      -- 3. run the merge statement
      

    merge into `dataengineerproject-439609`.`dp_dataproducts`.`sales_items` as DBT_INTERNAL_DEST
        using (
        select
        * from `dataengineerproject-439609`.`dp_dataproducts`.`sales_items__dbt_tmp`
      ) as DBT_INTERNAL_SOURCE
        on FALSE

    when not matched by source
         and timestamp_trunc(DBT_INTERNAL_DEST.sales_datetime, day) in unnest(dbt_partitions_for_replacement) 
        then delete

    when not matched then insert
        (`pk`, `sales_datetime`, `item_amount`, `product_sku`, `item_quantity`, `product_description`, `discount_perc`)
    values
        (`pk`, `sales_datetime`, `item_amount`, `product_sku`, `item_quantity`, `product_description`, `discount_perc`)

;

      -- 4. clean up the temp table
      drop table if exists `dataengineerproject-439609`.`dp_dataproducts`.`sales_items__dbt_tmp`

  


  

    
[0m19:07:12.359838 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:8ab9e53d-3beb-4c67-aded-0988f8f6df13&page=queryresults
[0m19:07:16.168286 [debug] [Thread-1 (]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/dataengineerproject-439609/queries/8ab9e53d-3beb-4c67-aded-0988f8f6df13?maxResults=0&location=europe-west9&prettyPrint=false: Query error: Cannot coerce expression (\n          select as struct\n              -- IGNORE NULLS: this needs to be aligned to _dbt_max_partition, which ignores null\n              array_agg(distinct timestamp_trunc(sales_datetime, day) IGNORE NULLS)\n          from `dataengineerproject-439609`.`dp_dataproducts`.`sales_items__dbt_tmp`\n      ) to type STRUCT<ARRAY<TIMESTAMP>> at [41:46]')
[0m19:07:16.899904 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:afe523d5-b0f3-4e68-b199-eb33d4c1cd28&page=queryresults
[0m19:07:20.078452 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:afe523d5-b0f3-4e68-b199-eb33d4c1cd28&page=queryresults
[0m19:07:20.293908 [debug] [Thread-1 (]: Database Error in model sales_items (dbt_data_pipeline/models\dataproducts\sales_items.sql)
  Query error: Cannot coerce expression (
            select as struct
                -- IGNORE NULLS: this needs to be aligned to _dbt_max_partition, which ignores null
                array_agg(distinct timestamp_trunc(sales_datetime, day) IGNORE NULLS)
            from `dataengineerproject-439609`.`dp_dataproducts`.`sales_items__dbt_tmp`
        ) to type STRUCT<ARRAY<TIMESTAMP>> at [41:46]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m19:07:20.293908 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '874b9ba9-772b-485e-a897-b98163f437a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014065E5F140>]}
[0m19:07:20.293908 [error] [Thread-1 (]: 6 of 6 ERROR creating sql incremental model dp_dataproducts.sales_items ........ [[31mERROR[0m in 8.24s]
[0m19:07:20.293908 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.sales_items
[0m19:07:20.293908 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:07:20.309427 [debug] [MainThread]: Connection 'create_dataengineerproject-439609_dp' was properly closed.
[0m19:07:20.309427 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_hub' was properly closed.
[0m19:07:20.309427 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.sales_items' was properly closed.
[0m19:07:20.309427 [info ] [MainThread]: 
[0m19:07:20.309427 [info ] [MainThread]: Finished running 4 view models, 1 table model, 1 incremental model in 0 hours 0 minutes and 18.42 seconds (18.42s).
[0m19:07:20.309427 [debug] [MainThread]: Command end result
[0m19:07:20.362829 [info ] [MainThread]: 
[0m19:07:20.378484 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m19:07:20.378484 [info ] [MainThread]: 
[0m19:07:20.378484 [error] [MainThread]:   Database Error in model sales_items (dbt_data_pipeline/models\dataproducts\sales_items.sql)
  Query error: Cannot coerce expression (
            select as struct
                -- IGNORE NULLS: this needs to be aligned to _dbt_max_partition, which ignores null
                array_agg(distinct timestamp_trunc(sales_datetime, day) IGNORE NULLS)
            from `dataengineerproject-439609`.`dp_dataproducts`.`sales_items__dbt_tmp`
        ) to type STRUCT<ARRAY<TIMESTAMP>> at [41:46]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m19:07:20.378484 [info ] [MainThread]: 
[0m19:07:20.378484 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
[0m19:07:20.378484 [debug] [MainThread]: Command `dbt run` failed at 19:07:20.378484 after 28.35 seconds
[0m19:07:20.394072 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001405A8FB0B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001405A0550D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014065BF2240>]}
[0m19:07:20.394072 [debug] [MainThread]: Flushing usage events
[0m19:08:48.977977 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019AD7874440>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019AD77291F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019AD772ABA0>]}


============================== 19:08:48.993660 | da54ed53-bd48-4cee-9b55-377324a621f7 ==============================
[0m19:08:48.993660 [info ] [MainThread]: Running with dbt=1.8.7
[0m19:08:48.993660 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run -s sales_items.sql', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m19:08:53.462631 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'da54ed53-bd48-4cee-9b55-377324a621f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019AE0A47800>]}
[0m19:08:53.562929 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'da54ed53-bd48-4cee-9b55-377324a621f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019AE24F1D90>]}
[0m19:08:53.562929 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m19:08:53.578573 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m19:08:54.041938 [debug] [MainThread]: Partial parsing enabled: 3 files deleted, 0 files added, 0 files changed.
[0m19:08:54.041938 [debug] [MainThread]: Partial parsing: deleted file: dbt_data_pipeline://dbt_data_pipeline/models\example\my_first_dbt_model.sql
[0m19:08:54.041938 [debug] [MainThread]: Partial parsing: deleted file: dbt_data_pipeline://dbt_data_pipeline/models\example\my_second_dbt_model.sql
[0m19:08:54.142194 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_data_pipeline.datalake
[0m19:08:54.164338 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'da54ed53-bd48-4cee-9b55-377324a621f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019AD79FE120>]}
[0m19:08:54.429182 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'da54ed53-bd48-4cee-9b55-377324a621f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019AE2557890>]}
[0m19:08:54.439430 [info ] [MainThread]: Found 4 models, 3 sources, 484 macros
[0m19:08:54.439430 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'da54ed53-bd48-4cee-9b55-377324a621f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019AE25840E0>]}
[0m19:08:54.447485 [info ] [MainThread]: 
[0m19:08:54.449522 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m19:08:54.449522 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m19:08:54.449522 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:08:57.807354 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_dataproducts'
[0m19:08:57.807354 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:08:57.961505 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_dataproducts, now list_dataengineerproject-439609_dp_hub)
[0m19:08:57.961505 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:08:58.076797 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'da54ed53-bd48-4cee-9b55-377324a621f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019AE2619610>]}
[0m19:08:58.076797 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:08:58.076797 [info ] [MainThread]: 
[0m19:08:58.092425 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.sales_items
[0m19:08:58.092425 [info ] [Thread-1 (]: 1 of 1 START sql incremental model dp_dataproducts.sales_items ................. [RUN]
[0m19:08:58.092425 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.sales_items'
[0m19:08:58.092425 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.sales_items
[0m19:08:58.114568 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.sales_items"
[0m19:08:58.114568 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.sales_items
[0m19:08:58.230503 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m19:08:58.576721 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.sales_items"
[0m19:08:58.599128 [debug] [Thread-1 (]: On model.dbt_data_pipeline.sales_items: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.sales_items"} */

   
      -- generated script to merge partitions into `dataengineerproject-439609`.`dp_dataproducts`.`sales_items`
      declare dbt_partitions_for_replacement array<timestamp>;

      
      
       -- 1. create a temp table with model data
        
  
    

    create or replace table `dataengineerproject-439609`.`dp_dataproducts`.`sales_items__dbt_tmp`
      
    partition by timestamp_trunc(sales_datetime, day)
    

    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      -- Config pour indiquer le modèle incrémental


-- Extraction des informations nécessaires pour chaque vente et chaque produit
    SELECT
        CONCAT(CAST(s.id AS STRING), '_', s.item_product_sku) AS pk,  -- Clé primaire unique pour chaque vente
        safe_cast(s.sales_datetime AS datetime) AS sales_datetime,  -- Date de la vente
        s.item_amount,  -- Montant total par produit et par vente
        s.item_product_sku AS product_sku,  -- SKU du produit vendu
        s.item_quantity,  -- Quantité d'items vendus
        p.product_description,  -- Description du produit
        ((p.unit_amount - s.item_amount) / p.unit_amount) * 100 AS discount_perc  -- Pourcentage de réduction
    FROM `dataengineerproject-439609`.`dp_hub`.`sales_staging` AS s
    LEFT JOIN `dataengineerproject-439609`.`dp_hub`.`products_staging` AS p
    ON s.item_product_sku = p.product_sku  -- Associer la description des produits
    );
  
      -- 2. define partitions to update
      set (dbt_partitions_for_replacement) = (
          select as struct
              -- IGNORE NULLS: this needs to be aligned to _dbt_max_partition, which ignores null
              array_agg(distinct timestamp_trunc(sales_datetime, day) IGNORE NULLS)
          from `dataengineerproject-439609`.`dp_dataproducts`.`sales_items__dbt_tmp`
      );

      -- 3. run the merge statement
      

    merge into `dataengineerproject-439609`.`dp_dataproducts`.`sales_items` as DBT_INTERNAL_DEST
        using (
        select
        * from `dataengineerproject-439609`.`dp_dataproducts`.`sales_items__dbt_tmp`
      ) as DBT_INTERNAL_SOURCE
        on FALSE

    when not matched by source
         and timestamp_trunc(DBT_INTERNAL_DEST.sales_datetime, day) in unnest(dbt_partitions_for_replacement) 
        then delete

    when not matched then insert
        (`pk`, `sales_datetime`, `item_amount`, `product_sku`, `item_quantity`, `product_description`, `discount_perc`)
    values
        (`pk`, `sales_datetime`, `item_amount`, `product_sku`, `item_quantity`, `product_description`, `discount_perc`)

;

      -- 4. clean up the temp table
      drop table if exists `dataengineerproject-439609`.`dp_dataproducts`.`sales_items__dbt_tmp`

  


  

    
[0m19:08:58.737214 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:e5c28523-90af-4ccd-9aba-f97ee99cafc8&page=queryresults
[0m19:09:01.127087 [debug] [Thread-1 (]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/dataengineerproject-439609/queries/e5c28523-90af-4ccd-9aba-f97ee99cafc8?maxResults=0&location=europe-west9&prettyPrint=false: Query error: Cannot coerce expression (\n          select as struct\n              -- IGNORE NULLS: this needs to be aligned to _dbt_max_partition, which ignores null\n              array_agg(distinct timestamp_trunc(sales_datetime, day) IGNORE NULLS)\n          from `dataengineerproject-439609`.`dp_dataproducts`.`sales_items__dbt_tmp`\n      ) to type STRUCT<ARRAY<TIMESTAMP>> at [41:46]')
[0m19:09:02.041863 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:30ae89b0-d66b-4dff-bd50-56aba3bf5ac4&page=queryresults
[0m19:09:04.962114 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:30ae89b0-d66b-4dff-bd50-56aba3bf5ac4&page=queryresults
[0m19:09:05.034875 [debug] [Thread-1 (]: Database Error in model sales_items (dbt_data_pipeline/models\dataproducts\sales_items.sql)
  Query error: Cannot coerce expression (
            select as struct
                -- IGNORE NULLS: this needs to be aligned to _dbt_max_partition, which ignores null
                array_agg(distinct timestamp_trunc(sales_datetime, day) IGNORE NULLS)
            from `dataengineerproject-439609`.`dp_dataproducts`.`sales_items__dbt_tmp`
        ) to type STRUCT<ARRAY<TIMESTAMP>> at [41:46]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m19:09:05.041872 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da54ed53-bd48-4cee-9b55-377324a621f7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019AE2845100>]}
[0m19:09:05.045876 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model dp_dataproducts.sales_items ........ [[31mERROR[0m in 6.94s]
[0m19:09:05.048881 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.sales_items
[0m19:09:05.054901 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:09:05.054901 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m19:09:05.054901 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_hub' was properly closed.
[0m19:09:05.054901 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.sales_items' was properly closed.
[0m19:09:05.054901 [info ] [MainThread]: 
[0m19:09:05.054901 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 10.61 seconds (10.61s).
[0m19:09:05.054901 [debug] [MainThread]: Command end result
[0m19:09:05.327790 [info ] [MainThread]: 
[0m19:09:05.327790 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m19:09:05.327790 [info ] [MainThread]: 
[0m19:09:05.327790 [error] [MainThread]:   Database Error in model sales_items (dbt_data_pipeline/models\dataproducts\sales_items.sql)
  Query error: Cannot coerce expression (
            select as struct
                -- IGNORE NULLS: this needs to be aligned to _dbt_max_partition, which ignores null
                array_agg(distinct timestamp_trunc(sales_datetime, day) IGNORE NULLS)
            from `dataengineerproject-439609`.`dp_dataproducts`.`sales_items__dbt_tmp`
        ) to type STRUCT<ARRAY<TIMESTAMP>> at [41:46]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m19:09:05.327790 [info ] [MainThread]: 
[0m19:09:05.338010 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m19:09:05.348076 [debug] [MainThread]: Command `dbt run` failed at 19:09:05.348076 after 16.80 seconds
[0m19:09:05.348076 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019AD40C05C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019AD6EC7500>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019AD6EC6C60>]}
[0m19:09:05.348076 [debug] [MainThread]: Flushing usage events
[0m19:09:49.386913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002268FF83920>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002269010A840>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002269010A930>]}


============================== 19:09:49.386913 | 6e0c6b12-78b6-44d5-9b30-3236a582db13 ==============================
[0m19:09:49.386913 [info ] [MainThread]: Running with dbt=1.8.7
[0m19:09:49.386913 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run -s sales_items.sql', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m19:09:53.228639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6e0c6b12-78b6-44d5-9b30-3236a582db13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000226900033E0>]}
[0m19:09:53.297696 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6e0c6b12-78b6-44d5-9b30-3236a582db13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002268DC35BE0>]}
[0m19:09:53.297696 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m19:09:53.313320 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m19:09:53.752306 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m19:09:53.767931 [debug] [MainThread]: Partial parsing: updated file: dbt_data_pipeline://dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m19:09:54.099709 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_data_pipeline.datalake
[0m19:09:54.115333 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6e0c6b12-78b6-44d5-9b30-3236a582db13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002269AD172F0>]}
[0m19:09:54.300315 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6e0c6b12-78b6-44d5-9b30-3236a582db13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002269B0003B0>]}
[0m19:09:54.300315 [info ] [MainThread]: Found 4 models, 3 sources, 484 macros
[0m19:09:54.300315 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6e0c6b12-78b6-44d5-9b30-3236a582db13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002269AC83FE0>]}
[0m19:09:54.300315 [info ] [MainThread]: 
[0m19:09:54.300315 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m19:09:54.300315 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m19:09:54.300315 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:09:57.145780 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_dataproducts'
[0m19:09:57.145780 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:09:57.262482 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_dataproducts, now list_dataengineerproject-439609_dp_hub)
[0m19:09:57.262482 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:09:57.362394 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6e0c6b12-78b6-44d5-9b30-3236a582db13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002269ADF91C0>]}
[0m19:09:57.377405 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:09:57.377405 [info ] [MainThread]: 
[0m19:09:57.377405 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.sales_items
[0m19:09:57.377405 [info ] [Thread-1 (]: 1 of 1 START sql incremental model dp_dataproducts.sales_items ................. [RUN]
[0m19:09:57.377405 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.sales_items'
[0m19:09:57.377405 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.sales_items
[0m19:09:57.393059 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.sales_items"
[0m19:09:57.393059 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.sales_items
[0m19:09:57.540232 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m19:09:57.762650 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.sales_items"
[0m19:09:57.762650 [debug] [Thread-1 (]: On model.dbt_data_pipeline.sales_items: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.sales_items"} */

   
      -- generated script to merge partitions into `dataengineerproject-439609`.`dp_dataproducts`.`sales_items`
      declare dbt_partitions_for_replacement array<timestamp>;

      
      
       -- 1. create a temp table with model data
        
  
    

    create or replace table `dataengineerproject-439609`.`dp_dataproducts`.`sales_items__dbt_tmp`
      
    partition by timestamp_trunc(sales_datetime, day)
    

    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      -- Config pour indiquer le modèle incrémental


-- Extraction des informations nécessaires pour chaque vente et chaque produit
    SELECT
        CONCAT(CAST(s.id AS STRING), '_', s.item_product_sku) AS pk,  -- Clé primaire unique pour chaque vente
        cast(s.sales_datetime AS datetime) AS sales_datetime,  -- Date de la vente
        s.item_amount,  -- Montant total par produit et par vente
        s.item_product_sku AS product_sku,  -- SKU du produit vendu
        s.item_quantity,  -- Quantité d'items vendus
        p.product_description,  -- Description du produit
        ((p.unit_amount - s.item_amount) / p.unit_amount) * 100 AS discount_perc  -- Pourcentage de réduction
    FROM `dataengineerproject-439609`.`dp_hub`.`sales_staging` AS s
    LEFT JOIN `dataengineerproject-439609`.`dp_hub`.`products_staging` AS p
    ON s.item_product_sku = p.product_sku  -- Associer la description des produits
    );
  
      -- 2. define partitions to update
      set (dbt_partitions_for_replacement) = (
          select as struct
              -- IGNORE NULLS: this needs to be aligned to _dbt_max_partition, which ignores null
              array_agg(distinct timestamp_trunc(sales_datetime, day) IGNORE NULLS)
          from `dataengineerproject-439609`.`dp_dataproducts`.`sales_items__dbt_tmp`
      );

      -- 3. run the merge statement
      

    merge into `dataengineerproject-439609`.`dp_dataproducts`.`sales_items` as DBT_INTERNAL_DEST
        using (
        select
        * from `dataengineerproject-439609`.`dp_dataproducts`.`sales_items__dbt_tmp`
      ) as DBT_INTERNAL_SOURCE
        on FALSE

    when not matched by source
         and timestamp_trunc(DBT_INTERNAL_DEST.sales_datetime, day) in unnest(dbt_partitions_for_replacement) 
        then delete

    when not matched then insert
        (`pk`, `sales_datetime`, `item_amount`, `product_sku`, `item_quantity`, `product_description`, `discount_perc`)
    values
        (`pk`, `sales_datetime`, `item_amount`, `product_sku`, `item_quantity`, `product_description`, `discount_perc`)

;

      -- 4. clean up the temp table
      drop table if exists `dataengineerproject-439609`.`dp_dataproducts`.`sales_items__dbt_tmp`

  


  

    
[0m19:09:57.894866 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:8eeed7a0-e417-48f4-9855-2f94d5371596&page=queryresults
[0m19:10:00.486250 [debug] [Thread-1 (]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/dataengineerproject-439609/queries/8eeed7a0-e417-48f4-9855-2f94d5371596?maxResults=0&location=europe-west9&prettyPrint=false: Query error: Cannot coerce expression (\n          select as struct\n              -- IGNORE NULLS: this needs to be aligned to _dbt_max_partition, which ignores null\n              array_agg(distinct timestamp_trunc(sales_datetime, day) IGNORE NULLS)\n          from `dataengineerproject-439609`.`dp_dataproducts`.`sales_items__dbt_tmp`\n      ) to type STRUCT<ARRAY<TIMESTAMP>> at [41:46]')
[0m19:10:01.134983 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:c646f348-5afe-4a67-9605-24e6a83e5306&page=queryresults
[0m19:10:04.013375 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:c646f348-5afe-4a67-9605-24e6a83e5306&page=queryresults
[0m19:10:04.035475 [debug] [Thread-1 (]: Database Error in model sales_items (dbt_data_pipeline/models\dataproducts\sales_items.sql)
  Query error: Cannot coerce expression (
            select as struct
                -- IGNORE NULLS: this needs to be aligned to _dbt_max_partition, which ignores null
                array_agg(distinct timestamp_trunc(sales_datetime, day) IGNORE NULLS)
            from `dataengineerproject-439609`.`dp_dataproducts`.`sales_items__dbt_tmp`
        ) to type STRUCT<ARRAY<TIMESTAMP>> at [41:46]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m19:10:04.035475 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e0c6b12-78b6-44d5-9b30-3236a582db13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002268F843C20>]}
[0m19:10:04.051165 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model dp_dataproducts.sales_items ........ [[31mERROR[0m in 6.66s]
[0m19:10:04.051165 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.sales_items
[0m19:10:04.051165 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:10:04.051165 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m19:10:04.051165 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_hub' was properly closed.
[0m19:10:04.051165 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.sales_items' was properly closed.
[0m19:10:04.051165 [info ] [MainThread]: 
[0m19:10:04.051165 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 9.75 seconds (9.75s).
[0m19:10:04.066746 [debug] [MainThread]: Command end result
[0m19:10:04.113628 [info ] [MainThread]: 
[0m19:10:04.129260 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m19:10:04.129260 [info ] [MainThread]: 
[0m19:10:04.129260 [error] [MainThread]:   Database Error in model sales_items (dbt_data_pipeline/models\dataproducts\sales_items.sql)
  Query error: Cannot coerce expression (
            select as struct
                -- IGNORE NULLS: this needs to be aligned to _dbt_max_partition, which ignores null
                array_agg(distinct timestamp_trunc(sales_datetime, day) IGNORE NULLS)
            from `dataengineerproject-439609`.`dp_dataproducts`.`sales_items__dbt_tmp`
        ) to type STRUCT<ARRAY<TIMESTAMP>> at [41:46]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m19:10:04.135794 [info ] [MainThread]: 
[0m19:10:04.135794 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m19:10:04.135794 [debug] [MainThread]: Command `dbt run` failed at 19:10:04.135794 after 15.14 seconds
[0m19:10:04.135794 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002268FE94140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002268FE05DC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002268FF00AA0>]}
[0m19:10:04.135794 [debug] [MainThread]: Flushing usage events
[0m19:15:44.873644 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013C2AF33C50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013C2A0B0500>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013C2D864BC0>]}


============================== 19:15:44.889527 | 1e350ca1-8493-4ffd-a4c6-e41ee846253e ==============================
[0m19:15:44.889527 [info ] [MainThread]: Running with dbt=1.8.7
[0m19:15:44.889527 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run -s sales_items.sql', 'send_anonymous_usage_stats': 'True'}
[0m19:15:49.068468 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1e350ca1-8493-4ffd-a4c6-e41ee846253e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013C3837AC30>]}
[0m19:15:49.168329 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1e350ca1-8493-4ffd-a4c6-e41ee846253e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013C37B24C20>]}
[0m19:15:49.168329 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m19:15:49.183992 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m19:15:49.553631 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m19:15:49.553631 [debug] [MainThread]: Partial parsing: updated file: dbt_data_pipeline://dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m19:15:49.870209 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_data_pipeline.datalake
[0m19:15:49.892340 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1e350ca1-8493-4ffd-a4c6-e41ee846253e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013C3883EF30>]}
[0m19:15:50.070480 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1e350ca1-8493-4ffd-a4c6-e41ee846253e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013C387E81D0>]}
[0m19:15:50.070480 [info ] [MainThread]: Found 4 models, 3 sources, 484 macros
[0m19:15:50.070480 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1e350ca1-8493-4ffd-a4c6-e41ee846253e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013C38479640>]}
[0m19:15:50.070480 [info ] [MainThread]: 
[0m19:15:50.070480 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m19:15:50.070480 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m19:15:50.070480 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:15:53.235313 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_dataproducts'
[0m19:15:53.235313 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:15:53.366903 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_dataproducts, now list_dataengineerproject-439609_dp_hub)
[0m19:15:53.366903 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:15:53.536208 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1e350ca1-8493-4ffd-a4c6-e41ee846253e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013C388394C0>]}
[0m19:15:53.536208 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:15:53.536208 [info ] [MainThread]: 
[0m19:15:53.536208 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.sales_items
[0m19:15:53.551848 [info ] [Thread-1 (]: 1 of 1 START sql incremental model dp_dataproducts.sales_items ................. [RUN]
[0m19:15:53.551848 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.sales_items'
[0m19:15:53.551848 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.sales_items
[0m19:15:53.567477 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.sales_items"
[0m19:15:53.583101 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.sales_items
[0m19:15:53.768088 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m19:15:53.984291 [debug] [Thread-1 (]: Compilation Error in model sales_items (dbt_data_pipeline/models\dataproducts\sales_items.sql)
  The 'insert_overwrite' strategy requires the `partition_by` config.
  
  > in macro bq_generate_incremental_insert_overwrite_build_sql (macros\materializations\incremental_strategy\insert_overwrite.sql)
  > called by macro bq_generate_incremental_build_sql (macros\materializations\incremental.sql)
  > called by macro materialization_incremental_bigquery (macros\materializations\incremental.sql)
  > called by model sales_items (dbt_data_pipeline/models\dataproducts\sales_items.sql)
[0m19:15:53.984291 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1e350ca1-8493-4ffd-a4c6-e41ee846253e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013C2D103BC0>]}
[0m19:15:53.984291 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model dp_dataproducts.sales_items ........ [[31mERROR[0m in 0.43s]
[0m19:15:53.984291 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.sales_items
[0m19:15:53.999913 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:15:53.999913 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m19:15:53.999913 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_hub' was properly closed.
[0m19:15:53.999913 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.sales_items' was properly closed.
[0m19:15:53.999913 [info ] [MainThread]: 
[0m19:15:53.999913 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 3.93 seconds (3.93s).
[0m19:15:53.999913 [debug] [MainThread]: Command end result
[0m19:15:54.053331 [info ] [MainThread]: 
[0m19:15:54.053331 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m19:15:54.053331 [info ] [MainThread]: 
[0m19:15:54.053331 [error] [MainThread]:   Compilation Error in model sales_items (dbt_data_pipeline/models\dataproducts\sales_items.sql)
  The 'insert_overwrite' strategy requires the `partition_by` config.
  
  > in macro bq_generate_incremental_insert_overwrite_build_sql (macros\materializations\incremental_strategy\insert_overwrite.sql)
  > called by macro bq_generate_incremental_build_sql (macros\materializations\incremental.sql)
  > called by macro materialization_incremental_bigquery (macros\materializations\incremental.sql)
  > called by model sales_items (dbt_data_pipeline/models\dataproducts\sales_items.sql)
[0m19:15:54.053331 [info ] [MainThread]: 
[0m19:15:54.068955 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m19:15:54.068955 [debug] [MainThread]: Command `dbt run` failed at 19:15:54.068955 after 9.54 seconds
[0m19:15:54.068955 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013C2C79E570>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013C2C79FDA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013C2D59CCB0>]}
[0m19:15:54.068955 [debug] [MainThread]: Flushing usage events
[0m19:19:23.505982 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027E6CA4D310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027E6C349130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027E6C460770>]}


============================== 19:19:23.505982 | 8a592f7a-63b5-4321-b892-f6937dd6d5e5 ==============================
[0m19:19:23.505982 [info ] [MainThread]: Running with dbt=1.8.7
[0m19:19:23.505982 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run -s sales_items.sql', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m19:19:27.720035 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8a592f7a-63b5-4321-b892-f6937dd6d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027E75664950>]}
[0m19:19:27.802201 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8a592f7a-63b5-4321-b892-f6937dd6d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027E693A4740>]}
[0m19:19:27.802201 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m19:19:27.817852 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m19:19:28.250319 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m19:19:28.250319 [debug] [MainThread]: Partial parsing: updated file: dbt_data_pipeline://dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m19:19:28.604609 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_data_pipeline.datalake
[0m19:19:28.635877 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8a592f7a-63b5-4321-b892-f6937dd6d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027E77C17170>]}
[0m19:19:28.805203 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8a592f7a-63b5-4321-b892-f6937dd6d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027E778D6300>]}
[0m19:19:28.820846 [info ] [MainThread]: Found 4 models, 3 sources, 484 macros
[0m19:19:28.820846 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8a592f7a-63b5-4321-b892-f6937dd6d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027E77AA24E0>]}
[0m19:19:28.820846 [info ] [MainThread]: 
[0m19:19:28.820846 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m19:19:28.820846 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m19:19:28.820846 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:19:31.729208 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_hub'
[0m19:19:31.729208 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:19:31.891415 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_hub, now list_dataengineerproject-439609_dp_dataproducts)
[0m19:19:31.891415 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:19:32.013639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8a592f7a-63b5-4321-b892-f6937dd6d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027E77B5AA20>]}
[0m19:19:32.013639 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:19:32.013639 [info ] [MainThread]: 
[0m19:19:32.013639 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.sales_items
[0m19:19:32.013639 [info ] [Thread-1 (]: 1 of 1 START sql incremental model dp_dataproducts.sales_items ................. [RUN]
[0m19:19:32.013639 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.sales_items'
[0m19:19:32.013639 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.sales_items
[0m19:19:32.129617 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.sales_items"
[0m19:19:32.129617 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.sales_items
[0m19:19:32.192125 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m19:19:32.392369 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.sales_items"
[0m19:19:32.392369 [debug] [Thread-1 (]: On model.dbt_data_pipeline.sales_items: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.sales_items"} */

   
      -- generated script to merge partitions into `dataengineerproject-439609`.`dp_dataproducts`.`sales_items`
      declare dbt_partitions_for_replacement array<timestamp>;

      
      
       -- 1. create a temp table with model data
        
  
    

    create or replace table `dataengineerproject-439609`.`dp_dataproducts`.`sales_items__dbt_tmp`
      
    partition by timestamp_trunc(sales_datetime, day)
    

    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      -- Config pour indiquer le modèle incrémental


-- Extraction des informations nécessaires pour chaque vente et chaque produit
    SELECT
        CONCAT(CAST(s.id AS STRING), '_', s.item_product_sku) AS pk,  -- Clé primaire unique pour chaque vente
        safe_cast(s.sales_datetime AS datetime) AS sales_datetime,  -- Date de la vente
        s.item_amount,  -- Montant total par produit et par vente
        s.item_product_sku AS product_sku,  -- SKU du produit vendu
        s.item_quantity,  -- Quantité d'items vendus
        p.product_description,  -- Description du produit
        ((p.unit_amount - s.item_amount) / p.unit_amount) * 100 AS discount_perc  -- Pourcentage de réduction
    FROM `dataengineerproject-439609`.`dp_hub`.`sales_staging` AS s
    LEFT JOIN `dataengineerproject-439609`.`dp_hub`.`products_staging` AS p
    ON s.item_product_sku = p.product_sku  -- Associer la description des produits


-- Condition pour ne traiter que les nouvelles lignes ou celles qui ont changé
WHERE s.sales_datetime > (SELECT MAX(sales_datetime) FROM `dataengineerproject-439609`.`dp_dataproducts`.`sales_items`)

    );
  
      -- 2. define partitions to update
      set (dbt_partitions_for_replacement) = (
          select as struct
              -- IGNORE NULLS: this needs to be aligned to _dbt_max_partition, which ignores null
              array_agg(distinct timestamp_trunc(sales_datetime, day) IGNORE NULLS)
          from `dataengineerproject-439609`.`dp_dataproducts`.`sales_items__dbt_tmp`
      );

      -- 3. run the merge statement
      

    merge into `dataengineerproject-439609`.`dp_dataproducts`.`sales_items` as DBT_INTERNAL_DEST
        using (
        select
        * from `dataengineerproject-439609`.`dp_dataproducts`.`sales_items__dbt_tmp`
      ) as DBT_INTERNAL_SOURCE
        on FALSE

    when not matched by source
         and timestamp_trunc(DBT_INTERNAL_DEST.sales_datetime, day) in unnest(dbt_partitions_for_replacement) 
        then delete

    when not matched then insert
        (`pk`, `sales_datetime`, `item_amount`, `product_sku`, `item_quantity`, `product_description`, `discount_perc`)
    values
        (`pk`, `sales_datetime`, `item_amount`, `product_sku`, `item_quantity`, `product_description`, `discount_perc`)

;

      -- 4. clean up the temp table
      drop table if exists `dataengineerproject-439609`.`dp_dataproducts`.`sales_items__dbt_tmp`

  


  

    
[0m19:19:32.546191 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:d33d0d63-9e78-417e-aae6-c521971c10a9&page=queryresults
[0m19:19:33.232920 [debug] [Thread-1 (]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/dataengineerproject-439609/queries/d33d0d63-9e78-417e-aae6-c521971c10a9?maxResults=0&location=europe-west9&prettyPrint=false: Query error: No matching signature for operator > for argument types: TIMESTAMP, DATETIME. Supported signature: ANY > ANY at [41:7]')
[0m19:19:33.665759 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:fabf5286-20ee-482b-9863-680b3dfa8a44&page=queryresults
[0m19:19:34.337324 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:fabf5286-20ee-482b-9863-680b3dfa8a44&page=queryresults
[0m19:19:34.368194 [debug] [Thread-1 (]: Database Error in model sales_items (dbt_data_pipeline/models\dataproducts\sales_items.sql)
  Query error: No matching signature for operator > for argument types: TIMESTAMP, DATETIME. Supported signature: ANY > ANY at [41:7]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m19:19:34.368194 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8a592f7a-63b5-4321-b892-f6937dd6d5e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027E77AA2ED0>]}
[0m19:19:34.368194 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model dp_dataproducts.sales_items ........ [[31mERROR[0m in 2.35s]
[0m19:19:34.368194 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.sales_items
[0m19:19:34.368194 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:19:34.368194 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m19:19:34.368194 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_dataproducts' was properly closed.
[0m19:19:34.368194 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.sales_items' was properly closed.
[0m19:19:34.368194 [info ] [MainThread]: 
[0m19:19:34.368194 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 5.55 seconds (5.55s).
[0m19:19:34.383823 [debug] [MainThread]: Command end result
[0m19:19:34.421593 [info ] [MainThread]: 
[0m19:19:34.421593 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m19:19:34.421593 [info ] [MainThread]: 
[0m19:19:34.421593 [error] [MainThread]:   Database Error in model sales_items (dbt_data_pipeline/models\dataproducts\sales_items.sql)
  Query error: No matching signature for operator > for argument types: TIMESTAMP, DATETIME. Supported signature: ANY > ANY at [41:7]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m19:19:34.421593 [info ] [MainThread]: 
[0m19:19:34.421593 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m19:19:34.437238 [debug] [MainThread]: Command `dbt run` failed at 19:19:34.437238 after 11.23 seconds
[0m19:19:34.437238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027E6BAE1670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027E7791DA30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000027E77782690>]}
[0m19:19:34.437238 [debug] [MainThread]: Flushing usage events
[0m19:20:43.415278 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F908397830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F90A32EB40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F90A563E30>]}


============================== 19:20:43.415278 | 36fa513e-3b21-43f2-b45f-ea7ff0480102 ==============================
[0m19:20:43.415278 [info ] [MainThread]: Running with dbt=1.8.7
[0m19:20:43.415278 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run -s sales_items.sql', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m19:20:46.930463 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '36fa513e-3b21-43f2-b45f-ea7ff0480102', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F913F17800>]}
[0m19:20:47.024295 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '36fa513e-3b21-43f2-b45f-ea7ff0480102', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F91560C080>]}
[0m19:20:47.024295 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m19:20:47.030312 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m19:20:47.478550 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m19:20:47.478550 [debug] [MainThread]: Partial parsing: updated file: dbt_data_pipeline://dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m19:20:47.832011 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_data_pipeline.datalake
[0m19:20:47.847660 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '36fa513e-3b21-43f2-b45f-ea7ff0480102', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F9140630E0>]}
[0m19:20:48.010234 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '36fa513e-3b21-43f2-b45f-ea7ff0480102', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F915A68FB0>]}
[0m19:20:48.010234 [info ] [MainThread]: Found 4 models, 3 sources, 484 macros
[0m19:20:48.010234 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '36fa513e-3b21-43f2-b45f-ea7ff0480102', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F90AE24F20>]}
[0m19:20:48.010234 [info ] [MainThread]: 
[0m19:20:48.010234 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m19:20:48.025798 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m19:20:48.025798 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:20:50.571530 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_hub'
[0m19:20:50.571530 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:20:50.740690 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_hub, now list_dataengineerproject-439609_dp_dataproducts)
[0m19:20:50.740690 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:20:50.856852 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '36fa513e-3b21-43f2-b45f-ea7ff0480102', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F915A94D70>]}
[0m19:20:50.856852 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:20:50.856852 [info ] [MainThread]: 
[0m19:20:50.871861 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.sales_items
[0m19:20:50.871861 [info ] [Thread-1 (]: 1 of 1 START sql incremental model dp_dataproducts.sales_items ................. [RUN]
[0m19:20:50.871861 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.sales_items'
[0m19:20:50.871861 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.sales_items
[0m19:20:50.956602 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.sales_items"
[0m19:20:50.956602 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.sales_items
[0m19:20:51.019125 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m19:20:51.219433 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.sales_items"
[0m19:20:51.219433 [debug] [Thread-1 (]: On model.dbt_data_pipeline.sales_items: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.sales_items"} */

   
      -- generated script to merge partitions into `dataengineerproject-439609`.`dp_dataproducts`.`sales_items`
      declare dbt_partitions_for_replacement array<datetime>;

      
      
       -- 1. create a temp table with model data
        
  
    

    create or replace table `dataengineerproject-439609`.`dp_dataproducts`.`sales_items__dbt_tmp`
      
    partition by datetime_trunc(sales_datetime, day)
    

    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      -- Config pour indiquer le modèle incrémental


-- Extraction des informations nécessaires pour chaque vente et chaque produit
    SELECT
        CONCAT(CAST(s.id AS STRING), '_', s.item_product_sku) AS pk,  -- Clé primaire unique pour chaque vente
        safe_cast(s.sales_datetime AS datetime) AS sales_datetime,  -- Date de la vente
        s.item_amount,  -- Montant total par produit et par vente
        s.item_product_sku AS product_sku,  -- SKU du produit vendu
        s.item_quantity,  -- Quantité d'items vendus
        p.product_description,  -- Description du produit
        ((p.unit_amount - s.item_amount) / p.unit_amount) * 100 AS discount_perc  -- Pourcentage de réduction
    FROM `dataengineerproject-439609`.`dp_hub`.`sales_staging` AS s
    LEFT JOIN `dataengineerproject-439609`.`dp_hub`.`products_staging` AS p
    ON s.item_product_sku = p.product_sku  -- Associer la description des produits


-- Condition pour ne traiter que les nouvelles lignes ou celles qui ont changé
WHERE s.sales_datetime > (SELECT MAX(sales_datetime) FROM `dataengineerproject-439609`.`dp_dataproducts`.`sales_items`)

    );
  
      -- 2. define partitions to update
      set (dbt_partitions_for_replacement) = (
          select as struct
              -- IGNORE NULLS: this needs to be aligned to _dbt_max_partition, which ignores null
              array_agg(distinct datetime_trunc(sales_datetime, day) IGNORE NULLS)
          from `dataengineerproject-439609`.`dp_dataproducts`.`sales_items__dbt_tmp`
      );

      -- 3. run the merge statement
      

    merge into `dataengineerproject-439609`.`dp_dataproducts`.`sales_items` as DBT_INTERNAL_DEST
        using (
        select
        * from `dataengineerproject-439609`.`dp_dataproducts`.`sales_items__dbt_tmp`
      ) as DBT_INTERNAL_SOURCE
        on FALSE

    when not matched by source
         and datetime_trunc(DBT_INTERNAL_DEST.sales_datetime, day) in unnest(dbt_partitions_for_replacement) 
        then delete

    when not matched then insert
        (`pk`, `sales_datetime`, `item_amount`, `product_sku`, `item_quantity`, `product_description`, `discount_perc`)
    values
        (`pk`, `sales_datetime`, `item_amount`, `product_sku`, `item_quantity`, `product_description`, `discount_perc`)

;

      -- 4. clean up the temp table
      drop table if exists `dataengineerproject-439609`.`dp_dataproducts`.`sales_items__dbt_tmp`

  


  

    
[0m19:20:51.389458 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:0e8f724e-a402-4585-825d-af748dcaab71&page=queryresults
[0m19:20:52.061380 [debug] [Thread-1 (]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/dataengineerproject-439609/queries/0e8f724e-a402-4585-825d-af748dcaab71?maxResults=0&location=europe-west9&prettyPrint=false: Query error: No matching signature for operator > for argument types: TIMESTAMP, DATETIME. Supported signature: ANY > ANY at [41:7]')
[0m19:20:53.149417 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:fcf54578-329c-4dbe-bd00-17ba94b33114&page=queryresults
[0m19:20:53.798637 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:fcf54578-329c-4dbe-bd00-17ba94b33114&page=queryresults
[0m19:20:53.829924 [debug] [Thread-1 (]: Database Error in model sales_items (dbt_data_pipeline/models\dataproducts\sales_items.sql)
  Query error: No matching signature for operator > for argument types: TIMESTAMP, DATETIME. Supported signature: ANY > ANY at [41:7]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m19:20:53.829924 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '36fa513e-3b21-43f2-b45f-ea7ff0480102', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F90A563950>]}
[0m19:20:53.829924 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model dp_dataproducts.sales_items ........ [[31mERROR[0m in 2.96s]
[0m19:20:53.845522 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.sales_items
[0m19:20:53.845522 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:20:53.845522 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m19:20:53.845522 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_dataproducts' was properly closed.
[0m19:20:53.852036 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.sales_items' was properly closed.
[0m19:20:53.852036 [info ] [MainThread]: 
[0m19:20:53.852036 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 5.84 seconds (5.84s).
[0m19:20:53.852036 [debug] [MainThread]: Command end result
[0m19:20:53.898971 [info ] [MainThread]: 
[0m19:20:53.898971 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m19:20:53.898971 [info ] [MainThread]: 
[0m19:20:53.898971 [error] [MainThread]:   Database Error in model sales_items (dbt_data_pipeline/models\dataproducts\sales_items.sql)
  Query error: No matching signature for operator > for argument types: TIMESTAMP, DATETIME. Supported signature: ANY > ANY at [41:7]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m19:20:53.898971 [info ] [MainThread]: 
[0m19:20:53.898971 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m19:20:53.914561 [debug] [MainThread]: Command `dbt run` failed at 19:20:53.914561 after 10.86 seconds
[0m19:20:53.914561 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F90AB4F2C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F90A98CE30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F915AB1100>]}
[0m19:20:53.914561 [debug] [MainThread]: Flushing usage events
[0m19:22:53.067979 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AB018A1C40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AB7EE57920>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AB7F462330>]}


============================== 19:22:53.083609 | 4fb1edbc-3da1-44c7-a0b7-6f6d93b3db3a ==============================
[0m19:22:53.083609 [info ] [MainThread]: Running with dbt=1.8.7
[0m19:22:53.083609 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run -s sales_items.sql', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m19:22:56.931593 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4fb1edbc-3da1-44c7-a0b7-6f6d93b3db3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AB0ACFC4A0>]}
[0m19:22:57.021133 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4fb1edbc-3da1-44c7-a0b7-6f6d93b3db3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AB0C2AFA10>]}
[0m19:22:57.023210 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m19:22:57.031406 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m19:22:57.404798 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m19:22:57.404798 [debug] [MainThread]: Partial parsing: updated file: dbt_data_pipeline://dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m19:22:57.745054 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_data_pipeline.datalake
[0m19:22:57.755095 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4fb1edbc-3da1-44c7-a0b7-6f6d93b3db3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AB0C8E7260>]}
[0m19:22:57.917910 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4fb1edbc-3da1-44c7-a0b7-6f6d93b3db3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AB0C5FB830>]}
[0m19:22:57.917910 [info ] [MainThread]: Found 4 models, 3 sources, 484 macros
[0m19:22:57.917910 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4fb1edbc-3da1-44c7-a0b7-6f6d93b3db3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AB0C81CE60>]}
[0m19:22:57.933539 [info ] [MainThread]: 
[0m19:22:57.933539 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m19:22:57.933539 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m19:22:57.933539 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:23:00.903167 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_dataproducts'
[0m19:23:00.903167 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:23:01.025605 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_dataproducts, now list_dataengineerproject-439609_dp_hub)
[0m19:23:01.025605 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:23:01.205128 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4fb1edbc-3da1-44c7-a0b7-6f6d93b3db3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AB0C65AC90>]}
[0m19:23:01.210639 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:23:01.210639 [info ] [MainThread]: 
[0m19:23:01.210639 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.sales_items
[0m19:23:01.210639 [info ] [Thread-1 (]: 1 of 1 START sql incremental model dp_dataproducts.sales_items ................. [RUN]
[0m19:23:01.210639 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.sales_items'
[0m19:23:01.210639 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.sales_items
[0m19:23:01.310940 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.sales_items"
[0m19:23:01.310940 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.sales_items
[0m19:23:01.373478 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m19:23:01.612081 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.sales_items"
[0m19:23:01.612081 [debug] [Thread-1 (]: On model.dbt_data_pipeline.sales_items: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.sales_items"} */

   
      -- generated script to merge partitions into `dataengineerproject-439609`.`dp_dataproducts`.`sales_items`
      declare dbt_partitions_for_replacement array<timestamp>;

      
      
       -- 1. create a temp table with model data
        
  
    

    create or replace table `dataengineerproject-439609`.`dp_dataproducts`.`sales_items__dbt_tmp`
      
    partition by timestamp_trunc(sales_datetime, day)
    

    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      -- Config pour indiquer le modèle incrémental


-- Extraction des informations nécessaires pour chaque vente et chaque produit
    SELECT
        CONCAT(CAST(s.id AS STRING), '_', s.item_product_sku) AS pk,  -- Clé primaire unique pour chaque vente
        safe_cast(s.sales_datetime AS datetime) AS sales_datetime,  -- Date de la vente
        s.item_amount,  -- Montant total par produit et par vente
        s.item_product_sku AS product_sku,  -- SKU du produit vendu
        s.item_quantity,  -- Quantité d'items vendus
        p.product_description,  -- Description du produit
        ((p.unit_amount - s.item_amount) / p.unit_amount) * 100 AS discount_perc  -- Pourcentage de réduction
    FROM `dataengineerproject-439609`.`dp_hub`.`sales_staging` AS s
    LEFT JOIN `dataengineerproject-439609`.`dp_hub`.`products_staging` AS p
    ON s.item_product_sku = p.product_sku  -- Associer la description des produits


-- Condition pour ne traiter que les nouvelles lignes ou celles qui ont changé
WHERE s.sales_datetime > CAST((SELECT MAX(sales_datetime) FROM `dataengineerproject-439609`.`dp_dataproducts`.`sales_items`) AS TIMESTAMP)

    );
  
      -- 2. define partitions to update
      set (dbt_partitions_for_replacement) = (
          select as struct
              -- IGNORE NULLS: this needs to be aligned to _dbt_max_partition, which ignores null
              array_agg(distinct timestamp_trunc(sales_datetime, day) IGNORE NULLS)
          from `dataengineerproject-439609`.`dp_dataproducts`.`sales_items__dbt_tmp`
      );

      -- 3. run the merge statement
      

    merge into `dataengineerproject-439609`.`dp_dataproducts`.`sales_items` as DBT_INTERNAL_DEST
        using (
        select
        * from `dataengineerproject-439609`.`dp_dataproducts`.`sales_items__dbt_tmp`
      ) as DBT_INTERNAL_SOURCE
        on FALSE

    when not matched by source
         and timestamp_trunc(DBT_INTERNAL_DEST.sales_datetime, day) in unnest(dbt_partitions_for_replacement) 
        then delete

    when not matched then insert
        (`pk`, `sales_datetime`, `item_amount`, `product_sku`, `item_quantity`, `product_description`, `discount_perc`)
    values
        (`pk`, `sales_datetime`, `item_amount`, `product_sku`, `item_quantity`, `product_description`, `discount_perc`)

;

      -- 4. clean up the temp table
      drop table if exists `dataengineerproject-439609`.`dp_dataproducts`.`sales_items__dbt_tmp`

  


  

    
[0m19:23:01.760542 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:77fd7b5f-dee3-48a0-8ee5-7d618f2a7a07&page=queryresults
[0m19:23:04.678122 [debug] [Thread-1 (]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/dataengineerproject-439609/queries/77fd7b5f-dee3-48a0-8ee5-7d618f2a7a07?maxResults=0&location=europe-west9&prettyPrint=false: Query error: Cannot coerce expression (\n          select as struct\n              -- IGNORE NULLS: this needs to be aligned to _dbt_max_partition, which ignores null\n              array_agg(distinct timestamp_trunc(sales_datetime, day) IGNORE NULLS)\n          from `dataengineerproject-439609`.`dp_dataproducts`.`sales_items__dbt_tmp`\n      ) to type STRUCT<ARRAY<TIMESTAMP>> at [46:46]')
[0m19:23:05.602039 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:7ad8af28-1db6-48f9-b64c-e2291cf87c3e&page=queryresults
[0m19:23:08.784892 [error] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:7ad8af28-1db6-48f9-b64c-e2291cf87c3e&page=queryresults
[0m19:23:08.831716 [debug] [Thread-1 (]: Database Error in model sales_items (dbt_data_pipeline/models\dataproducts\sales_items.sql)
  Query error: Cannot coerce expression (
            select as struct
                -- IGNORE NULLS: this needs to be aligned to _dbt_max_partition, which ignores null
                array_agg(distinct timestamp_trunc(sales_datetime, day) IGNORE NULLS)
            from `dataengineerproject-439609`.`dp_dataproducts`.`sales_items__dbt_tmp`
        ) to type STRUCT<ARRAY<TIMESTAMP>> at [46:46]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m19:23:08.831716 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4fb1edbc-3da1-44c7-a0b7-6f6d93b3db3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AB010F3AA0>]}
[0m19:23:08.838271 [error] [Thread-1 (]: 1 of 1 ERROR creating sql incremental model dp_dataproducts.sales_items ........ [[31mERROR[0m in 7.62s]
[0m19:23:08.840294 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.sales_items
[0m19:23:08.840294 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:23:08.840294 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m19:23:08.840294 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_hub' was properly closed.
[0m19:23:08.840294 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.sales_items' was properly closed.
[0m19:23:08.840294 [info ] [MainThread]: 
[0m19:23:08.848487 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 10.91 seconds (10.91s).
[0m19:23:08.850526 [debug] [MainThread]: Command end result
[0m19:23:08.901549 [info ] [MainThread]: 
[0m19:23:08.901549 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m19:23:08.901549 [info ] [MainThread]: 
[0m19:23:08.901549 [error] [MainThread]:   Database Error in model sales_items (dbt_data_pipeline/models\dataproducts\sales_items.sql)
  Query error: Cannot coerce expression (
            select as struct
                -- IGNORE NULLS: this needs to be aligned to _dbt_max_partition, which ignores null
                array_agg(distinct timestamp_trunc(sales_datetime, day) IGNORE NULLS)
            from `dataengineerproject-439609`.`dp_dataproducts`.`sales_items__dbt_tmp`
        ) to type STRUCT<ARRAY<TIMESTAMP>> at [46:46]
  compiled code at target\run\dbt_data_pipeline\dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m19:23:08.901549 [info ] [MainThread]: 
[0m19:23:08.909685 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m19:23:08.911714 [debug] [MainThread]: Command `dbt run` failed at 19:23:08.911714 after 16.11 seconds
[0m19:23:08.911714 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AB0155B0B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AB0155BE30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AB0C3AB9B0>]}
[0m19:23:08.911714 [debug] [MainThread]: Flushing usage events
[0m19:26:35.325674 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BAF27659A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BAF2A102F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BAF3070F20>]}


============================== 19:26:35.325674 | aedc885c-5b2e-42b5-9a4b-7355717d668c ==============================
[0m19:26:35.325674 [info ] [MainThread]: Running with dbt=1.8.7
[0m19:26:35.341358 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run -s sales_items.sql', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m19:26:39.393731 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'aedc885c-5b2e-42b5-9a4b-7355717d668c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BAFDE31DC0>]}
[0m19:26:39.472543 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'aedc885c-5b2e-42b5-9a4b-7355717d668c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BAF27659A0>]}
[0m19:26:39.478076 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m19:26:39.478076 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m19:26:39.910676 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m19:26:39.910676 [debug] [MainThread]: Partial parsing: updated file: dbt_data_pipeline://dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m19:26:40.211583 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_data_pipeline.datalake
[0m19:26:40.227212 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'aedc885c-5b2e-42b5-9a4b-7355717d668c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BAFE297050>]}
[0m19:26:40.427899 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'aedc885c-5b2e-42b5-9a4b-7355717d668c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BAFDFAB500>]}
[0m19:26:40.427899 [info ] [MainThread]: Found 4 models, 3 sources, 484 macros
[0m19:26:40.427899 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'aedc885c-5b2e-42b5-9a4b-7355717d668c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BAFE1C94F0>]}
[0m19:26:40.443481 [info ] [MainThread]: 
[0m19:26:40.443481 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m19:26:40.443481 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m19:26:40.443481 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:26:43.671436 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_hub'
[0m19:26:43.671436 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:26:43.834352 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_hub, now list_dataengineerproject-439609_dp_dataproducts)
[0m19:26:43.849981 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:26:43.957455 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'aedc885c-5b2e-42b5-9a4b-7355717d668c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BAFE00A090>]}
[0m19:26:43.957455 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:26:43.957455 [info ] [MainThread]: 
[0m19:26:43.973092 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.sales_items
[0m19:26:43.973092 [info ] [Thread-1 (]: 1 of 1 START sql incremental model dp_dataproducts.sales_items ................. [RUN]
[0m19:26:43.973092 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.sales_items'
[0m19:26:43.973092 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.sales_items
[0m19:26:44.073537 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.sales_items"
[0m19:26:44.073537 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.sales_items
[0m19:26:44.136046 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m19:26:44.305034 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.sales_items"
[0m19:26:44.305034 [debug] [Thread-1 (]: On model.dbt_data_pipeline.sales_items: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.sales_items"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `dataengineerproject-439609`.`dp_dataproducts`.`sales_items` as DBT_INTERNAL_DEST
        using (-- Config pour indiquer le modèle incrémental


-- Extraction des informations nécessaires pour chaque vente et chaque produit
    SELECT
        CONCAT(CAST(s.id AS STRING), '_', s.item_product_sku) AS pk,  -- Clé primaire unique pour chaque vente
        safe_cast(s.sales_datetime AS datetime) AS sales_datetime,  -- Date de la vente
        s.item_amount,  -- Montant total par produit et par vente
        s.item_product_sku AS product_sku,  -- SKU du produit vendu
        s.item_quantity,  -- Quantité d'items vendus
        p.product_description,  -- Description du produit
        ((p.unit_amount - s.item_amount) / p.unit_amount) * 100 AS discount_perc  -- Pourcentage de réduction
    FROM `dataengineerproject-439609`.`dp_hub`.`sales_staging` AS s
    LEFT JOIN `dataengineerproject-439609`.`dp_hub`.`products_staging` AS p
    ON s.item_product_sku = p.product_sku  -- Associer la description des produits

--
---- Condition pour ne traiter que les nouvelles lignes ou celles qui ont changé
--WHERE s.sales_datetime > CAST((SELECT MAX(sales_datetime) FROM `dataengineerproject-439609`.`dp_dataproducts`.`sales_items`) AS TIMESTAMP)
--
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.pk = DBT_INTERNAL_DEST.pk
            )

    
    when matched then update set
        `pk` = DBT_INTERNAL_SOURCE.`pk`,`sales_datetime` = DBT_INTERNAL_SOURCE.`sales_datetime`,`item_amount` = DBT_INTERNAL_SOURCE.`item_amount`,`product_sku` = DBT_INTERNAL_SOURCE.`product_sku`,`item_quantity` = DBT_INTERNAL_SOURCE.`item_quantity`,`product_description` = DBT_INTERNAL_SOURCE.`product_description`,`discount_perc` = DBT_INTERNAL_SOURCE.`discount_perc`
    

    when not matched then insert
        (`pk`, `sales_datetime`, `item_amount`, `product_sku`, `item_quantity`, `product_description`, `discount_perc`)
    values
        (`pk`, `sales_datetime`, `item_amount`, `product_sku`, `item_quantity`, `product_description`, `discount_perc`)


    
[0m19:26:44.893548 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:4e5f2b0c-8f18-4838-8ff0-a1d77703ba72&page=queryresults
[0m19:26:46.779182 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aedc885c-5b2e-42b5-9a4b-7355717d668c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BAFE28D580>]}
[0m19:26:46.779182 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model dp_dataproducts.sales_items ............ [[32mMERGE (2.0 rows, 2.3 KiB processed)[0m in 2.81s]
[0m19:26:46.779182 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.sales_items
[0m19:26:46.794769 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:26:46.794769 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m19:26:46.794769 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_dataproducts' was properly closed.
[0m19:26:46.794769 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.sales_items' was properly closed.
[0m19:26:46.794769 [info ] [MainThread]: 
[0m19:26:46.794769 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 6.35 seconds (6.35s).
[0m19:26:46.794769 [debug] [MainThread]: Command end result
[0m19:26:46.857277 [info ] [MainThread]: 
[0m19:26:46.857277 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:26:46.857277 [info ] [MainThread]: 
[0m19:26:46.863793 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:26:46.863793 [debug] [MainThread]: Command `dbt run` succeeded at 19:26:46.863793 after 12.01 seconds
[0m19:26:46.863793 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BAF2559B20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BAF25590D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BAFD794DA0>]}
[0m19:26:46.863793 [debug] [MainThread]: Flushing usage events
[0m19:29:49.077757 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B975F96060>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B97857B0E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B975D50EC0>]}


============================== 19:29:49.091753 | 1006b1f0-c731-45be-8b39-b3e7d6c86770 ==============================
[0m19:29:49.091753 [info ] [MainThread]: Running with dbt=1.8.7
[0m19:29:49.094756 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': 'C:/Users/lenovo/.dbt', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --profiles-dir C:/Users/lenovo/.dbt', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m19:29:55.112755 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1006b1f0-c731-45be-8b39-b3e7d6c86770', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B977D8D0D0>]}
[0m19:29:55.233755 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1006b1f0-c731-45be-8b39-b3e7d6c86770', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9043213D0>]}
[0m19:29:55.235753 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m19:29:55.259756 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m19:29:55.844754 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m19:29:55.845755 [debug] [MainThread]: Partial parsing: updated file: dbt_data_pipeline://dbt_data_pipeline/models\dataproducts\sales_items.sql
[0m19:29:56.401759 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_data_pipeline.datalake
[0m19:29:56.428758 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1006b1f0-c731-45be-8b39-b3e7d6c86770', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B90476EB10>]}
[0m19:29:56.708756 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1006b1f0-c731-45be-8b39-b3e7d6c86770', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9047481A0>]}
[0m19:29:56.710760 [info ] [MainThread]: Found 4 models, 3 sources, 484 macros
[0m19:29:56.712758 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1006b1f0-c731-45be-8b39-b3e7d6c86770', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9045E9B50>]}
[0m19:29:56.728756 [info ] [MainThread]: 
[0m19:29:56.731755 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m19:29:56.739802 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m19:29:56.741755 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:30:00.623755 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:30:00.840756 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_hub'
[0m19:30:00.842755 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:30:01.016777 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_hub, now list_dataengineerproject-439609_dp_dataproducts)
[0m19:30:01.018756 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:30:01.192756 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1006b1f0-c731-45be-8b39-b3e7d6c86770', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B976315D60>]}
[0m19:30:01.193755 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:30:01.197756 [info ] [MainThread]: 
[0m19:30:01.208757 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.customers_staging
[0m19:30:01.210757 [info ] [Thread-1 (]: 1 of 4 START sql view model dp_hub.customers_staging ........................... [RUN]
[0m19:30:01.212756 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.customers_staging'
[0m19:30:01.214756 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.customers_staging
[0m19:30:01.238756 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.customers_staging"
[0m19:30:01.243758 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.customers_staging
[0m19:30:01.460756 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.customers_staging"
[0m19:30:01.465755 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m19:30:01.467755 [debug] [Thread-1 (]: On model.dbt_data_pipeline.customers_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.customers_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_hub`.`customers_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


WITH standardized_customers AS (
    SELECT
        *,
        -- Normalisation des numéros de téléphone
        ARRAY(
            SELECT
                CASE
                    WHEN REGEXP_CONTAINS(phone_number, r'^\+33') THEN phone_number
                    WHEN REGEXP_CONTAINS(phone_number, r'^0') THEN '+33' || SUBSTR(REGEXP_REPLACE(phone_number, r'\D', ''), 2)  -- Remplacer 0 par +33
                    ELSE phone_number  -- Pour tout autre format, garder tel quel (potentiellement à adapter pour d'autres cas)
                END AS standardized_phone_number
            FROM UNNEST(phone_numbers) AS phone_number
        ) AS standardized_phone_numbers,

        -- Normalisation des adresses e-mail (en minuscules pour consistance)
        ARRAY(
            SELECT LOWER(email)
            FROM UNNEST(emails) AS email
        ) AS standardized_emails
    FROM `dataengineerproject-439609`.`dp_lake`.`customers_normalized`
),

ranked_customers AS (
    SELECT
        *,
        ROW_NUMBER() OVER (
            PARTITION BY customer_id
            ORDER BY _dp_ingestion_timestamp DESC
        ) AS row_num
    FROM standardized_customers
)

-- Sélectionner uniquement les enregistrements uniques les plus récents
SELECT
    _dp_ingestion_timestamp,
    customer_id,
    standardized_emails AS emails,
    standardized_phone_numbers AS phone_numbers

FROM
    ranked_customers
WHERE
    row_num = 1;


[0m19:30:01.731756 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:5e31cf42-2f8c-4d87-8a3b-bd07f93b8506&page=queryresults
[0m19:30:02.003760 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1006b1f0-c731-45be-8b39-b3e7d6c86770', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B978666CC0>]}
[0m19:30:02.006759 [info ] [Thread-1 (]: 1 of 4 OK created sql view model dp_hub.customers_staging ...................... [[32mCREATE VIEW (0 processed)[0m in 0.79s]
[0m19:30:02.009757 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.customers_staging
[0m19:30:02.011757 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.products_staging
[0m19:30:02.013757 [info ] [Thread-1 (]: 2 of 4 START sql view model dp_hub.products_staging ............................ [RUN]
[0m19:30:02.017757 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_data_pipeline.customers_staging, now model.dbt_data_pipeline.products_staging)
[0m19:30:02.021758 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.products_staging
[0m19:30:02.031755 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.products_staging"
[0m19:30:02.039757 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.products_staging
[0m19:30:02.046753 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.products_staging"
[0m19:30:02.049756 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:30:02.054756 [debug] [Thread-1 (]: On model.dbt_data_pipeline.products_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.products_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_hub`.`products_staging`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


WITH ranked_products AS (
    SELECT
        *,
        ROW_NUMBER() OVER (
            PARTITION BY product_sku
            ORDER BY _dp_ingestion_timestamp DESC
        ) AS row_num
    FROM `dataengineerproject-439609`.`dp_lake`.`products_normalized`
)

-- Sélectionner uniquement les enregistrements uniques les plus récents
SELECT
    _dp_ingestion_timestamp,
    product_sku,
    unit_amount,
    description AS product_description,
    supplier

FROM
    ranked_products
WHERE
    row_num = 1;


[0m19:30:02.319760 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:24fd4c51-2077-4bf1-bba5-fa9d763f3694&page=queryresults
[0m19:30:02.436760 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1006b1f0-c731-45be-8b39-b3e7d6c86770', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9045E9790>]}
[0m19:30:02.439757 [info ] [Thread-1 (]: 2 of 4 OK created sql view model dp_hub.products_staging ....................... [[32mCREATE VIEW (0 processed)[0m in 0.42s]
[0m19:30:02.446756 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.products_staging
[0m19:30:02.448760 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.sales_staging
[0m19:30:02.450756 [info ] [Thread-1 (]: 3 of 4 START sql view model dp_hub.sales_staging ............................... [RUN]
[0m19:30:02.463757 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_data_pipeline.products_staging, now model.dbt_data_pipeline.sales_staging)
[0m19:30:02.466760 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.sales_staging
[0m19:30:02.476760 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.sales_staging"
[0m19:30:02.481759 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.sales_staging
[0m19:30:02.490756 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.sales_staging"
[0m19:30:02.494756 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:30:02.496760 [debug] [Thread-1 (]: On model.dbt_data_pipeline.sales_staging: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.sales_staging"} */


  create or replace view `dataengineerproject-439609`.`dp_hub`.`sales_staging`
  OPTIONS()
  as -- Tag to indicate that this model is updated every hour


WITH ranked_sales AS (
    -- Assign a row number to each sale based on customer_id and timestamp, to keep the most recent entry
    SELECT
        *,
        ROW_NUMBER() OVER (
            PARTITION BY id
            ORDER BY _dp_ingestion_timestamp DESC
        ) AS row_num
    FROM `dataengineerproject-439609`.`dp_lake`.`sales_normalized`
),

-- Filter to only include the most recent entry for each sale (i.e., row_num = 1)
deduplicated_sales AS (
    SELECT *
    FROM ranked_sales
    WHERE row_num = 1
)

-- Flatten items array for each sale and select relevant fields
SELECT
    ds._dp_ingestion_timestamp,
    ds.id,
    ds.datetime AS sales_datetime,
    ds.customer_id,
    ds.total_amount,
    item.amount AS item_amount,
    item.quantity AS item_quantity,
    item.product_sku AS item_product_sku
FROM
    deduplicated_sales AS ds,
    UNNEST(ds.items) AS item;


[0m19:30:02.746754 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:aff1d91b-c087-45b0-9cce-b5b770cd1da2&page=queryresults
[0m19:30:02.997757 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1006b1f0-c731-45be-8b39-b3e7d6c86770', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9043FC080>]}
[0m19:30:02.999755 [info ] [Thread-1 (]: 3 of 4 OK created sql view model dp_hub.sales_staging .......................... [[32mCREATE VIEW (0 processed)[0m in 0.53s]
[0m19:30:03.028758 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.sales_staging
[0m19:30:03.035757 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.sales_items
[0m19:30:03.038757 [info ] [Thread-1 (]: 4 of 4 START sql incremental model dp_dataproducts.sales_items ................. [RUN]
[0m19:30:03.045758 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_data_pipeline.sales_staging, now model.dbt_data_pipeline.sales_items)
[0m19:30:03.047756 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.sales_items
[0m19:30:03.153756 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.sales_items"
[0m19:30:03.175772 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.sales_items
[0m19:30:03.954757 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:30:04.404756 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.sales_items"
[0m19:30:04.410756 [debug] [Thread-1 (]: On model.dbt_data_pipeline.sales_items: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.sales_items"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `dataengineerproject-439609`.`dp_dataproducts`.`sales_items` as DBT_INTERNAL_DEST
        using (-- Config pour indiquer le modèle incrémental


-- Extraction des informations nécessaires pour chaque vente et chaque produit
    SELECT
        CONCAT(CAST(s.id AS STRING), '_', s.item_product_sku) AS pk,  -- Clé primaire unique pour chaque vente
        safe_cast(s.sales_datetime AS datetime) AS sales_datetime,  -- Date de la vente
        s.item_amount,  -- Montant total par produit et par vente
        s.item_product_sku AS product_sku,  -- SKU du produit vendu
        s.item_quantity,  -- Quantité d'items vendus
        p.product_description,  -- Description du produit
        ((p.unit_amount - s.item_amount) / p.unit_amount) * 100 AS discount_perc  -- Pourcentage de réduction
    FROM `dataengineerproject-439609`.`dp_hub`.`sales_staging` AS s
    LEFT JOIN `dataengineerproject-439609`.`dp_hub`.`products_staging` AS p
    ON s.item_product_sku = p.product_sku  -- Associer la description des produits
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.pk = DBT_INTERNAL_DEST.pk
            )

    
    when matched then update set
        `pk` = DBT_INTERNAL_SOURCE.`pk`,`sales_datetime` = DBT_INTERNAL_SOURCE.`sales_datetime`,`item_amount` = DBT_INTERNAL_SOURCE.`item_amount`,`product_sku` = DBT_INTERNAL_SOURCE.`product_sku`,`item_quantity` = DBT_INTERNAL_SOURCE.`item_quantity`,`product_description` = DBT_INTERNAL_SOURCE.`product_description`,`discount_perc` = DBT_INTERNAL_SOURCE.`discount_perc`
    

    when not matched then insert
        (`pk`, `sales_datetime`, `item_amount`, `product_sku`, `item_quantity`, `product_description`, `discount_perc`)
    values
        (`pk`, `sales_datetime`, `item_amount`, `product_sku`, `item_quantity`, `product_description`, `discount_perc`)


    
[0m19:30:05.425765 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:2f30a800-6dbf-4ea6-8805-35c09cc866ee&page=queryresults
[0m19:30:07.545950 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1006b1f0-c731-45be-8b39-b3e7d6c86770', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9787BF980>]}
[0m19:30:07.547953 [info ] [Thread-1 (]: 4 of 4 OK created sql incremental model dp_dataproducts.sales_items ............ [[32mMERGE (2.0 rows, 3.2 KiB processed)[0m in 4.50s]
[0m19:30:07.549952 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.sales_items
[0m19:30:07.551947 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:30:07.552951 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m19:30:07.553950 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_dataproducts' was properly closed.
[0m19:30:07.554951 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.sales_items' was properly closed.
[0m19:30:07.555950 [info ] [MainThread]: 
[0m19:30:07.557949 [info ] [MainThread]: Finished running 3 view models, 1 incremental model in 0 hours 0 minutes and 10.83 seconds (10.83s).
[0m19:30:07.561949 [debug] [MainThread]: Command end result
[0m19:30:07.619955 [info ] [MainThread]: 
[0m19:30:07.621956 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:30:07.624956 [info ] [MainThread]: 
[0m19:30:07.626958 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m19:30:07.630955 [debug] [MainThread]: Command `dbt run` succeeded at 19:30:07.629954 after 19.02 seconds
[0m19:30:07.631953 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B975F96060>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B97788C560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B9040343B0>]}
[0m19:30:07.633957 [debug] [MainThread]: Flushing usage events
[0m00:13:52.183079 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0B7A77800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0BB1E4EC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0BB1E7A70>]}


============================== 00:13:52.202078 | 81bbbbd1-7cbd-40e0-aed2-0d242e0ac156 ==============================
[0m00:13:52.202078 [info ] [MainThread]: Running with dbt=1.8.7
[0m00:13:52.208080 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt ls -s dataprocessing', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m00:13:57.034205 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '81bbbbd1-7cbd-40e0-aed2-0d242e0ac156', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0C3DFBB30>]}
[0m00:13:57.132207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '81bbbbd1-7cbd-40e0-aed2-0d242e0ac156', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0C41ED4F0>]}
[0m00:13:57.134210 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m00:13:57.150208 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m00:13:57.263212 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m00:13:57.266215 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '81bbbbd1-7cbd-40e0-aed2-0d242e0ac156', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0BAA865D0>]}
[0m00:13:59.533255 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_data_pipeline.datalake
[0m00:13:59.547255 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '81bbbbd1-7cbd-40e0-aed2-0d242e0ac156', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0C60D5A00>]}
[0m00:14:00.204614 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '81bbbbd1-7cbd-40e0-aed2-0d242e0ac156', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0C62DF410>]}
[0m00:14:00.206613 [info ] [MainThread]: Found 4 models, 3 sources, 484 macros
[0m00:14:00.209616 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '81bbbbd1-7cbd-40e0-aed2-0d242e0ac156', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0C60C4620>]}
[0m00:14:00.213616 [debug] [MainThread]: Command `dbt ls` succeeded at 00:14:00.212614 after 8.61 seconds
[0m00:14:00.214614 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0BB1A0C50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0BB1A0170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E0BB09B560>]}
[0m00:14:00.215616 [debug] [MainThread]: Flushing usage events
[0m00:14:42.675502 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000184D88FE570>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000184D7BC4290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000184DA95F4A0>]}


============================== 00:14:42.684460 | f49b908d-a0f4-4a78-bd2b-d8d4232062ff ==============================
[0m00:14:42.684460 [info ] [MainThread]: Running with dbt=1.8.7
[0m00:14:42.686463 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt ls -s models', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m00:14:46.311812 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f49b908d-a0f4-4a78-bd2b-d8d4232062ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000184DB355340>]}
[0m00:14:46.381811 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f49b908d-a0f4-4a78-bd2b-d8d4232062ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000184E62D05F0>]}
[0m00:14:46.383849 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m00:14:46.397505 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m00:14:46.803639 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:14:46.804639 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:14:46.811644 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_data_pipeline.datalake
[0m00:14:46.853641 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f49b908d-a0f4-4a78-bd2b-d8d4232062ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000184E646B3B0>]}
[0m00:14:47.045647 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f49b908d-a0f4-4a78-bd2b-d8d4232062ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000184E66BF710>]}
[0m00:14:47.046646 [info ] [MainThread]: Found 4 models, 3 sources, 484 macros
[0m00:14:47.048647 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f49b908d-a0f4-4a78-bd2b-d8d4232062ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000184E6391190>]}
[0m00:14:47.050644 [warn ] [MainThread]: The selection criterion 'models' does not match any enabled nodes
[0m00:14:47.051646 [warn ] [MainThread]: No nodes selected!
[0m00:14:47.054644 [debug] [MainThread]: Command `dbt ls` succeeded at 00:14:47.053645 after 4.63 seconds
[0m00:14:47.054644 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000184DAA238F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000184DAC70920>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000184DA984620>]}
[0m00:14:47.055644 [debug] [MainThread]: Flushing usage events
[0m00:15:21.408217 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E5020A1D30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E502044410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E5020479E0>]}


============================== 00:15:21.417215 | 3a79510c-5132-4be0-ab88-69a17fcd0a67 ==============================
[0m00:15:21.417215 [info ] [MainThread]: Running with dbt=1.8.7
[0m00:15:21.418220 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run -s dataprocessing --full-refresh', 'send_anonymous_usage_stats': 'True'}
[0m00:15:25.645045 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3a79510c-5132-4be0-ab88-69a17fcd0a67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E50B0FD700>]}
[0m00:15:25.720051 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3a79510c-5132-4be0-ab88-69a17fcd0a67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E57F655940>]}
[0m00:15:25.722053 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m00:15:25.737094 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m00:15:26.195097 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:15:26.196093 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:15:26.202094 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_data_pipeline.datalake
[0m00:15:26.240093 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3a79510c-5132-4be0-ab88-69a17fcd0a67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E50CCE4F20>]}
[0m00:15:26.418760 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3a79510c-5132-4be0-ab88-69a17fcd0a67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E50CFDDE50>]}
[0m00:15:26.419761 [info ] [MainThread]: Found 4 models, 3 sources, 484 macros
[0m00:15:26.420761 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3a79510c-5132-4be0-ab88-69a17fcd0a67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E50CFD1B20>]}
[0m00:15:26.423761 [info ] [MainThread]: 
[0m00:15:26.424761 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m00:15:26.430761 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m00:15:26.431764 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:15:29.736833 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_dataproducts'
[0m00:15:29.737834 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:15:29.856738 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_dataproducts, now list_dataengineerproject-439609_dp_hub)
[0m00:15:29.859739 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:15:29.987164 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3a79510c-5132-4be0-ab88-69a17fcd0a67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E50CDD5280>]}
[0m00:15:29.988166 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:15:29.990167 [info ] [MainThread]: 
[0m00:15:30.000167 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.customers_processed
[0m00:15:30.002167 [info ] [Thread-1 (]: 1 of 3 START sql view model dp_hub.customers_processed ......................... [RUN]
[0m00:15:30.005168 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.customers_processed'
[0m00:15:30.006166 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.customers_processed
[0m00:15:30.032167 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.customers_processed"
[0m00:15:30.038165 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.customers_processed
[0m00:15:30.096167 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.customers_processed"
[0m00:15:30.102166 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m00:15:30.103167 [debug] [Thread-1 (]: On model.dbt_data_pipeline.customers_processed: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.customers_processed"} */


  create or replace view `dataengineerproject-439609`.`dp_hub`.`customers_processed`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


WITH standardized_customers AS (
    SELECT
        *,
        -- Normalisation des numéros de téléphone
        ARRAY(
            SELECT
                CASE
                    WHEN REGEXP_CONTAINS(phone_number, r'^\+33') THEN phone_number
                    WHEN REGEXP_CONTAINS(phone_number, r'^0') THEN '+33' || SUBSTR(REGEXP_REPLACE(phone_number, r'\D', ''), 2)  -- Remplacer 0 par +33
                    ELSE phone_number  -- Pour tout autre format, garder tel quel (potentiellement à adapter pour d'autres cas)
                END AS standardized_phone_number
            FROM UNNEST(phone_numbers) AS phone_number
        ) AS standardized_phone_numbers,

        -- Normalisation des adresses e-mail (en minuscules pour consistance)
        ARRAY(
            SELECT LOWER(email)
            FROM UNNEST(emails) AS email
        ) AS standardized_emails
    FROM `dataengineerproject-439609`.`dp_lake`.`customers_raw`
),

ranked_customers AS (
    SELECT
        *,
        ROW_NUMBER() OVER (
            PARTITION BY customer_id
            ORDER BY _dp_ingestion_timestamp DESC
        ) AS row_num
    FROM standardized_customers
)

-- Sélectionner uniquement les enregistrements uniques les plus récents
SELECT
    _dp_ingestion_timestamp,
    customer_id,
    standardized_emails AS emails,
    standardized_phone_numbers AS phone_numbers

FROM
    ranked_customers
WHERE
    row_num = 1;


[0m00:15:30.971488 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:62f40cea-0f29-4c67-bc86-f71f745a057e&page=queryresults
[0m00:15:31.230843 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a79510c-5132-4be0-ab88-69a17fcd0a67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E50B066AB0>]}
[0m00:15:31.232843 [info ] [Thread-1 (]: 1 of 3 OK created sql view model dp_hub.customers_processed .................... [[32mCREATE VIEW (0 processed)[0m in 1.22s]
[0m00:15:31.235848 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.customers_processed
[0m00:15:31.237843 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.products_processed
[0m00:15:31.239846 [info ] [Thread-1 (]: 2 of 3 START sql view model dp_hub.products_processed .......................... [RUN]
[0m00:15:31.241845 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_data_pipeline.customers_processed, now model.dbt_data_pipeline.products_processed)
[0m00:15:31.242844 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.products_processed
[0m00:15:31.251844 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.products_processed"
[0m00:15:31.256846 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.products_processed
[0m00:15:31.266844 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.products_processed"
[0m00:15:31.274847 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:15:31.276845 [debug] [Thread-1 (]: On model.dbt_data_pipeline.products_processed: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.products_processed"} */


  create or replace view `dataengineerproject-439609`.`dp_hub`.`products_processed`
  OPTIONS()
  as -- Tag pour indiquer que ce modèle est mis à jour toutes les heures


WITH ranked_products AS (
    SELECT
        *,
        ROW_NUMBER() OVER (
            PARTITION BY product_sku
            ORDER BY _dp_ingestion_timestamp DESC
        ) AS row_num
    FROM `dataengineerproject-439609`.`dp_lake`.`products_raw`
)

-- Sélectionner uniquement les enregistrements uniques les plus récents
SELECT
    _dp_ingestion_timestamp,
    product_sku,
    unit_amount,
    description AS product_description,
    supplier

FROM
    ranked_products
WHERE
    row_num = 1;


[0m00:15:31.575849 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:755269e9-fcd9-4720-b4c3-d0ef4fd66b91&page=queryresults
[0m00:15:31.783615 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a79510c-5132-4be0-ab88-69a17fcd0a67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E50D0F1430>]}
[0m00:15:31.784613 [info ] [Thread-1 (]: 2 of 3 OK created sql view model dp_hub.products_processed ..................... [[32mCREATE VIEW (0 processed)[0m in 0.54s]
[0m00:15:31.786614 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.products_processed
[0m00:15:31.787613 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.sales_processed
[0m00:15:31.788613 [info ] [Thread-1 (]: 3 of 3 START sql view model dp_hub.sales_processed ............................. [RUN]
[0m00:15:31.789613 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_data_pipeline.products_processed, now model.dbt_data_pipeline.sales_processed)
[0m00:15:31.790612 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.sales_processed
[0m00:15:31.796616 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.sales_processed"
[0m00:15:31.799707 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.sales_processed
[0m00:15:31.803708 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.sales_processed"
[0m00:15:31.805708 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:15:31.806734 [debug] [Thread-1 (]: On model.dbt_data_pipeline.sales_processed: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.sales_processed"} */


  create or replace view `dataengineerproject-439609`.`dp_hub`.`sales_processed`
  OPTIONS()
  as -- Tag to indicate that this model is updated every hour


WITH ranked_sales AS (
    -- Assign a row number to each sale based on customer_id and timestamp, to keep the most recent entry
    SELECT
        *,
        ROW_NUMBER() OVER (
            PARTITION BY id
            ORDER BY _dp_ingestion_timestamp DESC
        ) AS row_num
    FROM `dataengineerproject-439609`.`dp_lake`.`sales_raw`
),

-- Filter to only include the most recent entry for each sale (i.e., row_num = 1)
deduplicated_sales AS (
    SELECT *
    FROM ranked_sales
    WHERE row_num = 1
)

-- Flatten items array for each sale and select relevant fields
SELECT
    ds._dp_ingestion_timestamp,
    ds.id,
    ds.datetime AS sales_datetime,
    ds.customer_id,
    ds.total_amount,
    item.amount AS item_amount,
    item.quantity AS item_quantity,
    item.product_sku AS item_product_sku
FROM
    deduplicated_sales AS ds,
    UNNEST(ds.items) AS item;


[0m00:15:32.087758 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:7a132b17-c7a6-4bb2-be39-1b5e9b50f1ba&page=queryresults
[0m00:15:32.298766 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a79510c-5132-4be0-ab88-69a17fcd0a67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E50D05E720>]}
[0m00:15:32.299764 [info ] [Thread-1 (]: 3 of 3 OK created sql view model dp_hub.sales_processed ........................ [[32mCREATE VIEW (0 processed)[0m in 0.51s]
[0m00:15:32.301763 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.sales_processed
[0m00:15:32.304763 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:15:32.304763 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m00:15:32.305762 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_hub' was properly closed.
[0m00:15:32.306762 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.sales_processed' was properly closed.
[0m00:15:32.307764 [info ] [MainThread]: 
[0m00:15:32.308763 [info ] [MainThread]: Finished running 3 view models in 0 hours 0 minutes and 5.88 seconds (5.88s).
[0m00:15:32.311767 [debug] [MainThread]: Command end result
[0m00:15:32.356768 [info ] [MainThread]: 
[0m00:15:32.357768 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:15:32.359769 [info ] [MainThread]: 
[0m00:15:32.361764 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m00:15:32.365764 [debug] [MainThread]: Command `dbt run` succeeded at 00:15:32.364765 after 11.39 seconds
[0m00:15:32.366768 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E502000BF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E50218AAB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E50218A630>]}
[0m00:15:32.367767 [debug] [MainThread]: Flushing usage events
[0m00:15:58.409056 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014042F81C70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000140453D5130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000140453D5220>]}


============================== 00:15:58.419052 | 4298da34-6576-40d2-b532-819c48307362 ==============================
[0m00:15:58.419052 [info ] [MainThread]: Running with dbt=1.8.7
[0m00:15:58.421054 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\lenovo\\.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': 'C:\\Users\\lenovo\\data-engineer-project\\logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt run -s sales_items.sql --full-refresh', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m00:16:03.486152 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4298da34-6576-40d2-b532-819c48307362', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001404D1E53A0>]}
[0m00:16:03.565148 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4298da34-6576-40d2-b532-819c48307362', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001404E39C590>]}
[0m00:16:03.568158 [info ] [MainThread]: Registered adapter: bigquery=1.8.3
[0m00:16:03.591171 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m00:16:04.056158 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:16:04.057158 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:16:04.068164 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_data_pipeline.datalake
[0m00:16:04.111171 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4298da34-6576-40d2-b532-819c48307362', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000140500D7020>]}
[0m00:16:04.322164 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4298da34-6576-40d2-b532-819c48307362', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001404F7EAD50>]}
[0m00:16:04.324166 [info ] [MainThread]: Found 4 models, 3 sources, 484 macros
[0m00:16:04.325201 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4298da34-6576-40d2-b532-819c48307362', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000140502607A0>]}
[0m00:16:04.330170 [info ] [MainThread]: 
[0m00:16:04.335168 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m00:16:04.337164 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609'
[0m00:16:04.338166 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:16:07.553262 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dataengineerproject-439609_dp_hub'
[0m00:16:07.554235 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:16:07.728102 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dataengineerproject-439609_dp_hub, now list_dataengineerproject-439609_dp_dataproducts)
[0m00:16:07.730607 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:16:07.830860 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4298da34-6576-40d2-b532-819c48307362', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001404F7EAD50>]}
[0m00:16:07.834121 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:16:07.836090 [info ] [MainThread]: 
[0m00:16:07.847089 [debug] [Thread-1 (]: Began running node model.dbt_data_pipeline.sales_items
[0m00:16:07.848091 [info ] [Thread-1 (]: 1 of 1 START sql incremental model dp_dataproducts.sales_items ................. [RUN]
[0m00:16:07.849087 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.dbt_data_pipeline.sales_items'
[0m00:16:07.850112 [debug] [Thread-1 (]: Began compiling node model.dbt_data_pipeline.sales_items
[0m00:16:07.863165 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_data_pipeline.sales_items"
[0m00:16:07.869120 [debug] [Thread-1 (]: Began executing node model.dbt_data_pipeline.sales_items
[0m00:16:07.933121 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m00:16:08.116754 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_data_pipeline.sales_items"
[0m00:16:08.121769 [debug] [Thread-1 (]: On model.dbt_data_pipeline.sales_items: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "dbt_data_pipeline", "target_name": "dev", "node_id": "model.dbt_data_pipeline.sales_items"} */

  
    

    create or replace table `dataengineerproject-439609`.`dp_dataproducts`.`sales_items`
      
    partition by timestamp_trunc(sales_datetime, day)
    

    OPTIONS()
    as (
      -- Config pour indiquer le modèle incrémental


-- Extraction des informations nécessaires pour chaque vente et chaque produit
    SELECT
        CONCAT(CAST(s.id AS STRING), '_', s.item_product_sku) AS pk,  -- Clé primaire unique pour chaque vente
        safe_cast(s.sales_datetime AS datetime) AS sales_datetime,  -- Date de la vente
        s.item_amount,  -- Montant total par produit et par vente
        s.item_product_sku AS product_sku,  -- SKU du produit vendu
        s.item_quantity,  -- Quantité d'items vendus
        p.product_description,  -- Description du produit
        ((p.unit_amount - s.item_amount) / p.unit_amount) * 100 AS discount_perc  -- Pourcentage de réduction
    FROM `dataengineerproject-439609`.`dp_hub`.`sales_processed` AS s
    LEFT JOIN `dataengineerproject-439609`.`dp_hub`.`products_processed` AS p
    ON s.item_product_sku = p.product_sku  -- Associer la description des produits
    );
  
[0m00:16:08.668818 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dataengineerproject-439609&j=bq:europe-west9:0881591d-6292-4ad4-8f64-0c532dda9efa&page=queryresults
[0m00:16:10.407337 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4298da34-6576-40d2-b532-819c48307362', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014044C97770>]}
[0m00:16:10.408341 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model dp_dataproducts.sales_items ............ [[32mCREATE TABLE (2.0 rows, 222.0 Bytes processed)[0m in 2.56s]
[0m00:16:10.410337 [debug] [Thread-1 (]: Finished running node model.dbt_data_pipeline.sales_items
[0m00:16:10.412334 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:16:10.413335 [debug] [MainThread]: Connection 'list_dataengineerproject-439609' was properly closed.
[0m00:16:10.414334 [debug] [MainThread]: Connection 'list_dataengineerproject-439609_dp_dataproducts' was properly closed.
[0m00:16:10.415335 [debug] [MainThread]: Connection 'model.dbt_data_pipeline.sales_items' was properly closed.
[0m00:16:10.416334 [info ] [MainThread]: 
[0m00:16:10.417217 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 6.08 seconds (6.08s).
[0m00:16:10.419207 [debug] [MainThread]: Command end result
[0m00:16:10.457109 [info ] [MainThread]: 
[0m00:16:10.459110 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:16:10.461110 [info ] [MainThread]: 
[0m00:16:10.463110 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m00:16:10.465110 [debug] [MainThread]: Command `dbt run` succeeded at 00:16:10.465110 after 12.34 seconds
[0m00:16:10.466110 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014044B454F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001404FDFCCB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000140502522A0>]}
[0m00:16:10.467959 [debug] [MainThread]: Flushing usage events
